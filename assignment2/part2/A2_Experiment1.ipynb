{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "## Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = pickle.load( open( \"../imagenet-200/train_images.pkl\", \"rb\" ) )\n",
    "train_labels = pickle.load( open( \"../imagenet-200/train_labels.pkl\", \"rb\" ) )\n",
    "val_images = pickle.load( open( \"../imagenet-200/val_images.pkl\", \"rb\" ) )\n",
    "val_labels = pickle.load( open( \"../imagenet-200/val_labels.pkl\", \"rb\" ) )\n",
    "y_train = pickle.load( open( \"../imagenet-200/y_train.pkl\", \"rb\" ) )\n",
    "y_test = pickle.load( open( \"../imagenet-200/y_test.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n02119789</td>\n",
       "      <td>1</td>\n",
       "      <td>kit_fox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n02100735</td>\n",
       "      <td>2</td>\n",
       "      <td>English_setter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n02110185</td>\n",
       "      <td>3</td>\n",
       "      <td>Siberian_husky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n02096294</td>\n",
       "      <td>4</td>\n",
       "      <td>Australian_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n02102040</td>\n",
       "      <td>5</td>\n",
       "      <td>English_springer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  id         description\n",
       "0  n02119789   1             kit_fox\n",
       "1  n02100735   2      English_setter\n",
       "2  n02110185   3      Siberian_husky\n",
       "3  n02096294   4  Australian_terrier\n",
       "4  n02102040   5    English_springer"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_labels = pd.read_csv('../imagenet-200/map_clsloc.txt', sep='\\s', header=None, engine='python')\n",
    "text_labels.columns=['label', 'id', 'description']\n",
    "text_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704    barbershop\n",
      "Name: description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "plotData = train_images[0]\n",
    "plt.imshow(plotData)\n",
    "plt.show()\n",
    "print(text_labels.loc[text_labels['label']==train_labels[0], 'description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547    cash_machine\n",
      "Name: description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "plotData = val_images[0]\n",
    "plt.imshow(plotData)\n",
    "plt.show()\n",
    "print(text_labels.loc[text_labels['label']==val_labels[0], 'description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.astype('float32')\n",
    "val_images = val_images.astype('float32')\n",
    "train_images /= 255\n",
    "val_images /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = []\n",
    "y_test = []\n",
    "for row in train_labels:\n",
    "    label = text_labels.loc[text_labels['label']==row]['id'].iloc[0]\n",
    "    y_train.append(label)\n",
    "\n",
    "for row in val_labels:\n",
    "    label = text_labels.loc[text_labels['label']==row]['id'].iloc[0]\n",
    "    y_test.append(label)\n",
    "    \n",
    "y_train = np.array(y_train).reshape(-1, 1)\n",
    "y_test = np.array(y_test).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "enc = OneHotEncoder(categories='auto')\n",
    "y_train = enc.fit_transform(train_labels.reshape(-1, 1)).toarray()\n",
    "y_test = enc.transform(val_labels.reshape(-1, 1)).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['n01443537', 'n01629819', 'n01641577', 'n01644900', 'n01698640',\n",
       "        'n01742172', 'n01768244', 'n01770393', 'n01774384', 'n01774750',\n",
       "        'n01784675', 'n01855672', 'n01882714', 'n01910747', 'n01917289',\n",
       "        'n01944390', 'n01945685', 'n01950731', 'n01983481', 'n01984695',\n",
       "        'n02002724', 'n02056570', 'n02058221', 'n02074367', 'n02085620',\n",
       "        'n02094433', 'n02099601', 'n02099712', 'n02106662', 'n02113799',\n",
       "        'n02123045', 'n02123394', 'n02124075', 'n02125311', 'n02129165',\n",
       "        'n02132136', 'n02165456', 'n02190166', 'n02206856', 'n02226429',\n",
       "        'n02231487', 'n02233338', 'n02236044', 'n02268443', 'n02279972',\n",
       "        'n02281406', 'n02321529', 'n02364673', 'n02395406', 'n02403003',\n",
       "        'n02410509', 'n02415577', 'n02423022', 'n02437312', 'n02480495',\n",
       "        'n02481823', 'n02486410', 'n02504458', 'n02509815', 'n02666196',\n",
       "        'n02669723', 'n02699494', 'n02730930', 'n02769748', 'n02788148',\n",
       "        'n02791270', 'n02793495', 'n02795169', 'n02802426', 'n02808440',\n",
       "        'n02814533', 'n02814860', 'n02815834', 'n02823428', 'n02837789',\n",
       "        'n02841315', 'n02843684', 'n02883205', 'n02892201', 'n02906734',\n",
       "        'n02909870', 'n02917067', 'n02927161', 'n02948072', 'n02950826',\n",
       "        'n02963159', 'n02977058', 'n02988304', 'n02999410', 'n03014705',\n",
       "        'n03026506', 'n03042490', 'n03085013', 'n03089624', 'n03100240',\n",
       "        'n03126707', 'n03160309', 'n03179701', 'n03201208', 'n03250847',\n",
       "        'n03255030', 'n03355925', 'n03388043', 'n03393912', 'n03400231',\n",
       "        'n03404251', 'n03424325', 'n03444034', 'n03447447', 'n03544143',\n",
       "        'n03584254', 'n03599486', 'n03617480', 'n03637318', 'n03649909',\n",
       "        'n03662601', 'n03670208', 'n03706229', 'n03733131', 'n03763968',\n",
       "        'n03770439', 'n03796401', 'n03804744', 'n03814639', 'n03837869',\n",
       "        'n03838899', 'n03854065', 'n03891332', 'n03902125', 'n03930313',\n",
       "        'n03937543', 'n03970156', 'n03976657', 'n03977966', 'n03980874',\n",
       "        'n03983396', 'n03992509', 'n04008634', 'n04023962', 'n04067472',\n",
       "        'n04070727', 'n04074963', 'n04099969', 'n04118538', 'n04133789',\n",
       "        'n04146614', 'n04149813', 'n04179913', 'n04251144', 'n04254777',\n",
       "        'n04259630', 'n04265275', 'n04275548', 'n04285008', 'n04311004',\n",
       "        'n04328186', 'n04356056', 'n04366367', 'n04371430', 'n04376876',\n",
       "        'n04398044', 'n04399382', 'n04417672', 'n04456115', 'n04465501',\n",
       "        'n04486054', 'n04487081', 'n04501370', 'n04507155', 'n04532106',\n",
       "        'n04532670', 'n04540053', 'n04560804', 'n04562935', 'n04596742',\n",
       "        'n04597913', 'n06596364', 'n07579787', 'n07583066', 'n07614500',\n",
       "        'n07615774', 'n07695742', 'n07711569', 'n07715103', 'n07720875',\n",
       "        'n07734744', 'n07747607', 'n07749582', 'n07753592', 'n07768694',\n",
       "        'n07871810', 'n07873807', 'n07875152', 'n07920052', 'n09193705',\n",
       "        'n09246464', 'n09256479', 'n09332890', 'n09428293', 'n12267677'],\n",
       "       dtype='<U9')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(y_train, open( \"../imagenet-200/y_train.pkl\", \"wb\" ) )\n",
    "pickle.dump(y_test, open( \"../imagenet-200/y_test.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(enc, open( \"../imagenet-200/encoder.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels, y_train = shuffle(train_images, train_labels, y_train, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJztnXlsZNeV3r9TxSqySBb3nb2wd6ktSy0NI9uQxqOxYUcRNCMZCDx2YENAjNFgMAZiwPlDcICxg+QPTxDbcILAQTsWrEkcyx4vsDJw4nGEcWRZsqSWWupVW8u9sbk1d7JYrCrWyR9VPWhR93tNNbuLrXnfD2h08Z6679667516Vferc465O4QQ8SOx2RMQQmwOcn4hYoqcX4iYIucXIqbI+YWIKXJ+IWKKnF+ImCLnFyKmyPmFiCl1G+lsZvcC+CaAJID/5u5fjXp+trXVu3t7ycF4vwSxJaxM+5TLJWorlVaobbVUoDb31WB7piEd0YfP0Yy/aGMv+iqJGivqV54R00cymYw4ZrhjqcTPS9Q1EDn/csT8iSmRTNE+iQR/Xct5fn2USnyx6tIN1JYkczHj92ZmmxybwMLc/Lounqt2fjNLAvgvAD4G4DyAF8zsCXc/wfp09/bi3/3n/xS0JSNm0lgfbk8n87RPfnmS2qYv/o7a5mfPU1uhMBNsv3nvdtqnWFqitnSaX4Dper4gUc5qiXC/ZMQCRzlkMc8v6La2Nt5vZTnYPj19kfaB8deVSvG1KqwUqS1fCM+/pb2P9qnP8Nd14jV+fYxP5qitb8s+asu29Qfbk8km2qcunQm2/+Wff5H2WctGPvbfCeBNd3/L3QsAHgfwwAaOJ4SoIRtx/kEA5y77+3y1TQjxHuC6b/iZ2cNmdsjMDs3PzV3v4YQQ62Qjzj8CYOtlf2+ptr0Ndz/o7sPuPtzS2rqB4YQQ15KNOP8LAPaY2Q4zSwP4FIAnrs20hBDXm6ve7Xf3kpl9HsAvUJH6HnX341F9zBzp+vCObrEQ3h0GgInJqWD78iLf0S8WpqktleS7sq1tjdTWWB+Waxx8t7k+xd9fCytcCZi+uEBtuRWuciTIbr8l+DzKEXLeti1D1Lacj5jjYtiWj3jNTEoFgJkZ/poXFvgxV4rhF9dT4mP19BF5CcDQ9vDOPAC0d1ETlgtcyZiYOBtsTyT4tdje0R1sX42QuNeyIZ3f3X8O4OcbOYYQYnPQL/yEiClyfiFiipxfiJgi5xcipsj5hYgpG9rtf7eYOdJ1YUlvfm6M9rs4cSbYvrrKJZ7uDi7XtLdmqW1xfpzazpwJBwRlm3hUX2cXHyuV4stf38Dfl5ua+Y+lWIRYcZVLW0weBIBjxw9TWzbLX1u5GI5+y68s0j7NTVzaqq/n57Mhw4PYyh6Wvs6PnKJ9FnNcCs628oCgsoWDbQAAq/waaSJBSwvLPAjq3O/C/sICqkLozi9ETJHzCxFT5PxCxBQ5vxAxRc4vREyp6W7/0uIsnn3mb4O23r5O2q9/oDls4BvY8BIPOikWefBDYyM/aP9AR7B9auIdkcz/wNwsD0hBRA5CL/Md7HSa7xyvkJRWhQJ/zQ0Zvss+Nh4OOgGAhvQ2aksmw/eVlQLf7a8nQV8A0NbOd9LT9dzGgq4yGb6GS3keFLawyHNSTE7x19aQ4df33psPBNv7+ttpn+Vc+HXV1/P8g2vRnV+ImCLnFyKmyPmFiClyfiFiipxfiJgi5xciptRU6qtLGfr6wkN2clUDyURYXpmd5UE4S0vhvH8A0NrMq790dfEqKe3ZsK2rjVfsmZrmeQZnZ7kcGSVjLvO4Eyr1NdRzOS/byEtJ7RzaSm1dXfykGam+EyXnlSJKpU3PTFDbKgkiAgAnZa2WFnnJNgeXy3q7+Xpk6vm9dGqaS4Sj544E2xszPICro6snbCCBTCF05xcipsj5hYgpcn4hYoqcX4iYIucXIqbI+YWIKRuS+szsNIAFVISpkrsPRz2/KZPGHbeGpZLJSS7bnT3zVrB9eor3aW7icl4mw+sqpRK89FahEI7QWy1w2Whpnks8iTLX89JpLr/lcjxSMG3haMD2LImMBJCJyI/X2Mij33I5HsWWTITn0Zzlr6vIlxGTF7nUl4goRbZ1a/h6mxjnEuzqKo+o3DlEJDYA6TTPafi7Mxeo7fix14LtJ0d4Xsu9e28KthfyETrwGq6Fzv+H7s4zDQohbkj0sV+ImLJR53cAf2dmL5rZw9diQkKI2rDRj/13u/uImfUA+KWZveruT13+hOqbwsMA0NvPf64ohKgtG7rzu/tI9f8JAD8FcGfgOQfdfdjdh9va+O/mhRC15aqd38yazCx76TGAjwM4dq0mJoS4vmzkY38vgJ9aRVqqA/A/3f3/RHVYzi/ixPHfBm1Rck1zYzjRZTrJ5SuUuWRXLvIyX/VpHv3W3RGWCGdmZmifZMTr6mjnkmPCeb/Tp8PlywCgLhmW5rq7e2mfXER5KjiPwqur45cPURzhEdGKqRSXHDs6wslTAaCxnsuHPZ3hNd67azftMzXFE3g2ZvgcZ+f5dZCNKL+2bSAcHVnMcZl4oCf8KTqVWv/9/Kqd393fAnDb1fYXQmwukvqEiClyfiFiipxfiJgi5xcipsj5hYgptU3gmTC0k2i70ipPwsjeo1oyEVJfRB281SKXAacneYzS/MxssL2Q5+FoCa6Uoa2Zy1cLSzxi7sL5UWrr7wtHsWWbWmiffI6v/dC2HdTW08Mj3FjE35kzp2mfqGugu52PZUxXBDA9HZbfLk7w89zayhOTJklCUABYiJB865I8ynRLX3ewfWaSRzKWlsPJX73Mr/u16M4vREyR8wsRU+T8QsQUOb8QMUXOL0RMqeluf6lUxMxUeKc6aud4cjKcb62jg+/KLi7y3fLZaR64sW/fPmq7OBGex+Pff5r2+Rd/8gfUNnKe7+aORuRvSzjPq9dDyjhdOM+Pt7oakUuwOUNthw8dprbGxnCAVJTqUB+RS7Bc5mWoooJ+Xnj+uWB7VDBTX1+ERFPipby62jupzSICtV5//fVg+4Fb3kf7sPSP6dSrtM9adOcXIqbI+YWIKXJ+IWKKnF+ImCLnFyKmyPmFiCk1lfqSySTaWsK5x5aX5mm/pYWwLZXk712pFA+k6CS5+AAg08CDhTo7wgEkn/nMx2if06dOU1uqjkt2w7/3e9S2OM9zEC4uhiWsOuOnurONS1SpBi6/TY7x4JgPfOADwfYLYzwoKZfkgT27du2ituPHj1Nbe2tfsH2gP0JWLHJZ8TdPh6VDAPjAP3lH8up/oLmZX1d7du0NtpdKfB6rhXBwmr2L+7nu/ELEFDm/EDFFzi9ETJHzCxFT5PxCxBQ5vxAx5YpSn5k9CuB+ABPufku1rQPADwAMATgN4JPuzhOYVUkY0FAXjooqG4+W6mgLV/ddXs7zeZd5XrfObh5BuLrKI7qcLFd5lY+196abqW0sInLv5InXqK2vl5fe6moPR7jNzfHST8vLXDrM+zK1bekfpLaRs+eD7RGnBUsLfKyTJ8KRbwBQWOFRiZnWsMS2fRuXDk+cOEFtiws8X+Phl3ipyj+85x5qGxkPy58tTVwenJ8PR61GRWiuZT13/u8CuHdN2yMAnnT3PQCerP4thHgPcUXnd/enAKwNgH8AwGPVx48BePAaz0sIcZ252u/8ve5+6bPKGCoVe4UQ7yE2vOHn7g6AflE2s4fN7JCZHZqf5/nyhRC15Wqdf9zM+gGg+j/NR+XuB9192N2HW1r47+2FELXlap3/CQAPVR8/BOBn12Y6QohasR6p7/sA7gHQZWbnAXwZwFcB/NDMPgfgDIBPrmcwA5AkUk9bZxvtxxI0HjnOJZnCCv+K0TfAJaqoSKp0OhyF19PHtzzaWniS0UREUsfVEo9wy2bDkZEAcPJkOMJtOiJp6Yd//25qK4CvB1FtAQDbt4fLfOVX+Otaiih71h4Refjr3zxDbVu3hufx618/T/tMT01RW//gdmqbneJrnIyI4KxPh89nocDXPp8Pr6OXI5KPruGKzu/unyamj657FCHEDYd+4SdETJHzCxFT5PxCxBQ5vxAxRc4vREypaQLPRCKBxqZw7TfzMu2XTIWn2drMJa9kmidojKoJl8vxSMG2jrAcuUQirADgwtgItW3ZziXHbVu2UNvoSDhiDgBeez08/4EtXCrr6edyZNm4dNRQz7W+sfHwHBNJvvaZiCi2qISsAwMDEcfMBtujYt+SdXys+QVe4+/COK+9+MT/+t/UdvddHwq2nzh2lPapqwv7xGqZ+9FadOcXIqbI+YWIKXJ+IWKKnF+ImCLnFyKmyPmFiCm1l/pI7bc5Uo8PABrQGGzfu2837dPe2U1ts3NcmnvrzGlqKxEZ5fDhw7TPnXfy+m1NLQ3UNjp2htoaMjxCbPeecNTZapFHzC3leDSaGc+4mWng945nf3sk2D4wuI32aSIyMACMT/Aaf1siZNGZmXBe2Y9+lMelPfOb31Lb2AUus84v8OuqoYGfayf34GSKn+elxXDSVUl9QogrIucXIqbI+YWIKXJ+IWKKnF+ImFLT3X73Mkqr4cCThnoeTFEuh3OZ1dXx9650Az9eYZrn92NjAcDScng3d2BLP+3T3cODZubm+S773Ay37dsTzksHAOMT4d3oqF3qnt5wOTQAOHYknBMQiM4xd/99Hw+2zy7yklwtLTz4qC4dVnwA4FdP8935VnLMXJ7PI7fCy5d1dPFSbw8+yGvXDA7wa6S9Jbz+LS080GnkfPh8NtRzlWgtuvMLEVPk/ELEFDm/EDFFzi9ETJHzCxFT5PxCxJT1lOt6FMD9ACbc/ZZq21cA/CmAyerTvuTuP7/SsdwdhUK4zFBnJ5d5xsYng+0nT/JyXS0R+dTSGS4bDW7lefXa2sKyXS7H87rlIySldIRUmUrzgJrJSf7a3MLy2779e2ifvv4uavvB4yepbddOXrqqtbUl2L5c5PLgxOQYtU1O86CZKMm3sTkcLDQ7O0v7sLJsAHD2NJfSPv5P/yW1HXvlFWorFsPSc7aRBzrdetttwfZM47O0z1rWc+f/LoB7A+3fcPcD1X9XdHwhxI3FFZ3f3Z8CwH9xIoR4T7KR7/yfN7MjZvaomfGfsQkhbkiu1vm/BWAXgAMARgF8jT3RzB42s0Nmdmh2jpdnFkLUlqtyfncfd/dVdy8D+DYAmq7G3Q+6+7C7D7e18o0UIURtuSrnN7PLoxQ+AeDYtZmOEKJWrEfq+z6AewB0mdl5AF8GcI+ZHQDgAE4D+LN1jZZMoa41LKVNr/ACSuVMeEthsRzOzwYAC5Pj1LZrN4+KO3aMSzLv239TsD1H8qkBQFcXl9EyjeHyXwBQKvKcbydPvk5tu3e9L9je2c7nUSjwT2T3/NEfUNu2wSFqm10JS5xz81z6rE+F5UEAmJvgMmA6xddqqCccTdfQyMuGXTz/O2or9/Nztrg0RW0vHXuR2m7ef2uwvbGd56gcWwxHxxZX15/D74rO7+6fDjR/Z90jCCFuSPQLPyFiipxfiJgi5xcipsj5hYgpcn4hYkpNE3gWCgWcPXs2aOvo5L8QbmpqCrbv3bs3YjQueTQ28qi+thYu5RhZrqHtu2if3CKPRivk+S8eZ2bmqO34cZ5UM9sUlsu6u3tpnwsXLlDbwMAAtY2Oc/mtLRte/76+PtqnXOJJV++44w5qa23lCUhZubHR0ZGI42WpraU9Qo6c4VLf6AhPoLpjKHz9HD9+lPZJpcJS5coKL8u2Ft35hYgpcn4hYoqcX4iYIucXIqbI+YWIKXJ+IWJKTaW+VF0durvCiTqTySTtd+5MWB5cXeU196LkvHwjl0MaG7jMUyp4sL2jg9dva0jxebxy+GVqm5ristHuXVziHBwMR00uLfHIw/oMj4orFsLRYwBQ4suPkZHRYHvLPi45NkWcs1NvvEptv/jFL6iNyXZ33HGA9nnzDR412dvPz3W2hc//vnvDtQsBIE9qHv7mmedpn7a2jmD7SkTC2LXozi9ETJHzCxFT5PxCxBQ5vxAxRc4vREyp6W5/ubyK3FI4YCWb5bvsuaWFYHupxEs/NaR5qaOmdDhQCAB2vI/n92O0Z8M7rwDQmeVlyN549RS1Zfr5zvG2bVupLZUKqybnz52jfZqbm6mtUOAqQV8fD/qZuRg+Z7kcVw+WF/j5jCKR4Pew5sbwue7p5uflrrs+RG3dPTwA7ZWjR6itp7ub2mZmw8Ffv/8hmhQb2Ww4mOnx/8GDrdaiO78QMUXOL0RMkfMLEVPk/ELEFDm/EDFFzi9ETFlPua6tAP4aQC8q5bkOuvs3zawDwA8ADKFSsuuT7s7rZwFYXl7GqyfCecmGh4dpv907twXbE+DBQJmIAB2PqGhUKvCyYW+++VawPZ/jES49PTwQZP++/dTWkOEltC5c4PnnWLBT3wAPqJmb46ctVc9l0YYIW/9gWIoaPccDlo4c5jnr7hzm8tun/+ST1DY1HS7bNjEZDjwCgI4OnqdvJc+lz+4uLgM2RgRPzU2H19+dB6DNz10Mtpcjgt3Wsp47fwnAF919P4APAvgLM9sP4BEAT7r7HgBPVv8WQrxHuKLzu/uou79UfbwA4CSAQQAPAHis+rTHADx4vSYphLj2vKvv/GY2BOB2AM8B6HX3S5+dxlD5WiCEeI+wbuc3s2YAPwbwBXefv9zm7o7KfkCo38NmdsjMDi0trb98sBDi+rIu5zezFCqO/z13/0m1edzM+qv2fgATob7uftDdh919uKlJ4oIQNwpX9EarlDz5DoCT7v71y0xPAHio+vghAD+79tMTQlwv1hPVdxeAzwI4amaXks59CcBXAfzQzD4H4AwArrdUSaWS6OsNyyHJBP9KkEyEc+ehxGW5TJqXfsrnuRwyNsJLVz33zLPB9txCjvbp+wiX+irflsIsRpT5SibDJagAoLUzLHGmI9aj6DzSrljmcqoZt6VJ7sLmZi5fRZUUm5+fpbbJSS6jsevq5r17+FgLXI48/PIL1LZv/83UNjnBj9naGo5ArUvxe/PgQDiyM5M5RPu84/hXeoK7Pw2AXW0fXfdIQogbCn0JFyKmyPmFiClyfiFiipxfiJgi5xciptQ0gWdDQz327gsnyFxZ4fJbqRC2FUn5LABoNx5hlW3i0WhNGZ448/YDtwbbu7u4nNfRHo5uA4Cz58JRggBQKnFJjMl5ALBSCMuOF6d45F4uosRTKs2Tk9bV8cjDdDosv6XT9bTP1q08Men5szwBaanI1+qmveHr7W9+9Djvc/NOanv/+2+htlSaS59Hxs5TW19vuMSaRUjBI+fDJewKhQLtsxbd+YWIKXJ+IWKKnF+ImCLnFyKmyPmFiClyfiFiSk2lPodj1cP12FiNOQDo3xaWQhbneDLFYoHLPxPTk9TW3sqlrd27hoLtUbXiTp48Rm1zs3weu/bwmoHnx8IyDwAs5cK1EPsG+mifkvMoQTg/LwvzPPLQWsIy4K9+9Sva5+n/9zK1dXdyCfaP7r+X2t5447Vg+0DEehw/fpzadpBksgCwssKvuaGhIWqbI7X6ikUe6bq6GrZFRYquRXd+IWKKnF+ImCLnFyKmyPmFiClyfiFiSm13+92xQvLuOVEBAODi1HTYUOa71ItzPK9eY0RgTyrNjzk/Px9sLxZ5UFKUrbWtmdrS9fx9eftQWP0AgMVFUmoqwfMd5nJ8Vzmb5UFE5SI/5tRUOGddJR9smNZWriz88R/fT239fd3UNjsdTCqNHTu30D5t7fz6ePXVV6ltz7591FYq87VyC5/r7l7+uh79zneD7XNz3I/Woju/EDFFzi9ETJHzCxFT5PxCxBQ5vxAxRc4vREy5otRnZlsB/DUqJbgdwEF3/6aZfQXAnwK4FJ3yJXf/edSxEok6NGXDgTOHD7/CO5bD+dv27dlLu2SauVyztMADUgAue3V1hfMC1tXxZWxs4qWkZud5Xr03T3FJqamFS4SlMpcWGcUIGeq1kzzIpb4+XGYKALo7wqW3Dtz6ftpnx7bt1LZrNw90SiW5RLicDwc6nR3hOfVSPDUhFpZ4MNnLR45S22qELF2XCl+rtsjLqA1sC69HKn2G9nnHuOt4TgnAF939JTPLAnjRzH5ZtX3D3f/jukcTQtwwrKdW3yiA0erjBTM7CYD/ykQI8Z7gXX3nN7MhALcDeK7a9HkzO2Jmj5pF5MoWQtxwrNv5zawZwI8BfMHd5wF8C8AuAAdQ+WTwNdLvYTM7ZGaHZmd5sgMhRG1Zl/ObWQoVx/+eu/8EANx93N1X3b0M4NsA7gz1dfeD7j7s7sNtbbxggxCitlzR+a0SifEdACfd/euXtfdf9rRPAOD5qoQQNxzr2e2/C8BnARw1s0tJ1r4E4NNmdgAV+e80gD+74pESdbB0Z9C0Zdt+2m0lH47Qyxe4fFJe5ZJXQ4bLgJbkx5y8OB5sX1nh5a4GB/ne6EqB95ubmaW2vj6efy5fCr/uqDJOba0kEhBAczpFbasROeYM4XVs6eRbQ729YXkQACYnw9F5AFAu80i22blwdCErawYAg4N8Hk0tbdSWL/J5tLfw3JC55bDUOjIWnjsAbB0KRxCm68PXaIj17PY/DQTPZKSmL4S4sdEv/ISIKXJ+IWKKnF+ImCLnFyKmyPmFiCk1TeC5vFzE0ROjQdvOIV4Gqbc//OOgi+MXaJ+VIpdyoiSlTIpLfRfHRoLtFiE5LiwsUFtLC5fYurv6qa0l20VtK1PhSMGVPJehPOIesH2Qz2N5mf9ic3IiPI9ikfdpbW2ltrOneTRdS0SUI5NF8xFSH1LcLVqzfI51EeuxtMzX/8jR14PtrxzlkZ27doalvpWV9Ud16s4vREyR8wsRU+T8QsQUOb8QMUXOL0RMkfMLEVNqKvWVywksLYdlmYkpLpcVV8MJGuszPXywNJdyZma4bLTMg9iQJZFZUfXschEJHzONXOrLrkTUDIxIipJKhufS3MgjGfMFLkONXDhLbU31/Jgoh6MIC6s8EnB5ma/VwlK4TiKAyDqELIHqyBiPflvM8Xn0RkZp8tc2u8CjKhMN4etg98230T433xROhNrQyM/XO8Zd9zOFEP+okPMLEVPk/ELEFDm/EDFFzi9ETJHzCxFTair1Jesa0NK+O2grlp32m5oOS1uN9Xz6LY1cfisW+VhlkiwUABrqwzrgxXGeaHF+nktUdXWN1Gbgac4XF/kcO0g0YD5CcszlImSoFj5WIkI+bG4Ov7bcEh9rfCIc8QkAMzN8jScnuWzX3BqWltMNfH3bunjUZGsbT8R57sIktS3keLRdV09YPuzo4XUe80T+jnCjd6A7vxAxRc4vREyR8wsRU+T8QsQUOb8QMeWKu/1m1gDgKQD11ef/yN2/bGY7ADwOoBPAiwA+6+58KxdAsVjG6Hg+aGtr5TvfZVIWas55fry6Pp7XrbONl1yqQ5raEhaex+TFcL46ABgd4XkGF+b4cu3bewu15Zf5lu4br50Ptj/z7CHaZ+uWHdT2/tv5WLncIrVlm8JrnEry9c3np6mtp4cHcS1EBOIMbh0Itj936AXaZ+sQX4+5BV5ibWmZ7+hHBXE1tYYVhFyer/30xfC1vxoROLWW9dz5VwB8xN1vQ6Uc971m9kEAfwXgG+6+G8AMgM+te1QhxKZzRef3Cpfe4lPVfw7gIwB+VG1/DMCD12WGQojrwrq+85tZslqhdwLALwGcAjDr7pcCwc8D4IHOQogbjnU5v7uvuvsBAFsA3AngpvUOYGYPm9khMzu0tBCRK10IUVPe1W6/u88C+HsAHwLQZmaXNgy3AAhWtHD3g+4+7O7DTVm+qSeEqC1XdH4z6zazturjDICPATiJypvAP68+7SEAP7tekxRCXHvWE9jTD+AxM0ui8mbxQ3f/WzM7AeBxM/v3AA4D+M6VDuQOFArh95t8nr8P+WpY8qhz3mdmjn/FmJ/m0hxKc9TU2RYOBsktheVLADh16jS1vfE6tw0O7KK2RIIH1Lx16s1g+2+fPUH77PnMrdQ2PhouJQUAM+lZatsyOBRsb23hQTOlEs8lmGnkgTgz8/ycpVLhfoODW2mfwYg8fbOLXOpz49djQyOXnmfnw9fqxCQPClsmwVilEs9nuJYrOr+7HwFwe6D9LVS+/wsh3oPoF35CxBQ5vxAxRc4vREyR8wsRU+T8QsQUc38XSb82OpjZJIAz1T+7AFys2eAczePtaB5v5702j+3u3r2eA9bU+d82sNkhdx/elME1D81D89DHfiHiipxfiJiymc5/cBPHvhzN4+1oHm/nH+08Nu07vxBic9HHfiFiyqY4v5nda2avmdmbZvbIZsyhOo/TZnbUzF42M57h8tqP+6iZTZjZscvaOszsl2b2RvX/9k2ax1fMbKS6Ji+b2X01mMdWM/t7MzthZsfN7F9V22u6JhHzqOmamFmDmT1vZq9U5/Fvq+07zOy5qt/8wMx4NtT14O41/QcgiUoasJ0A0gBeAbC/1vOozuU0gK5NGPfDAO4AcOyytv8A4JHq40cA/NUmzeMrAP51jdejH8Ad1cdZAK8D2F/rNYmYR03XBIABaK4+TgF4DsAHAfwQwKeq7f8VwJ9vZJzNuPPfCeBNd3/LK6m+HwfwwCbMY9Nw96cArM1T/QAqiVCBGiVEJfOoOe4+6u4vVR8voJIsZhA1XpOIedQUr3Ddk+ZuhvMPAjh32d+bmfzTAfydmb1oZg9v0hwu0evul8rUjgHo3cS5fN7MjlS/Flz3rx+XY2ZDqOSPeA6buCZr5gHUeE1qkTQ37ht+d7v7HQD+GYC/MLMPb/aEgMo7PypvTJvBtwDsQqVGwyiAr9VqYDNrBvBjAF9w97elsanlmgTmUfM18Q0kzV0vm+H8IwAuz6FEk39eb9x9pPr/BICfYnMzE42bWT8AVP+f2IxJuPt49cIrA/g2arQmZpZCxeG+5+4/qTbXfE1C89isNamO/a6T5q6XzXD+FwDsqe5cpgF8CsATtZ6EmTWZWfbSYwAfB3Asutd15QlUEqECm5gQ9ZKzVfkEarAmZmao5IA86e5fv8xU0zVh86j1mtQsaW6tdjDX7Gbeh8pO6ikA/2aT5rATFaXhFQDHazkPAN9H5eNjEZXvbp8cZ98OAAAAfElEQVRDpebhkwDeAPB/AXRs0jz+O4CjAI6g4nz9NZjH3ah8pD8C4OXqv/tqvSYR86jpmgC4FZWkuEdQeaP5y8uu2ecBvAngbwDUb2Qc/cJPiJgS9w0/IWKLnF+ImCLnFyKmyPmFiClyfiFiipxfiJgi5xcipsj5hYgp/x+MT3ZRRtKhNgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         label   id description\n",
      "812  n07583066  813   guacamole\n"
     ]
    }
   ],
   "source": [
    "plotData = train_images[0]\n",
    "plt.imshow(plotData)\n",
    "plt.show()\n",
    "print(text_labels.loc[text_labels['label']==train_labels[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Keras CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers\n",
    "First we will select an optimizer for the task. We will start with a smaller number of epochs to eliminate any that are obviously poor choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SGD optimizer\n",
      "Epoch 1/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.2982 - acc: 0.0052 - val_loss: 5.2933 - val_acc: 0.0059\n",
      "Epoch 2/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.2358 - acc: 0.0096 - val_loss: 5.1405 - val_acc: 0.0113\n",
      "Epoch 3/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.1478 - acc: 0.0128 - val_loss: 5.0788 - val_acc: 0.0182\n",
      "Epoch 4/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.0939 - acc: 0.0174 - val_loss: 4.9952 - val_acc: 0.0296\n",
      "Epoch 5/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.0258 - acc: 0.0234 - val_loss: 4.8967 - val_acc: 0.0385\n",
      "Epoch 6/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.9411 - acc: 0.0317 - val_loss: 4.7850 - val_acc: 0.0496\n",
      "Epoch 7/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8614 - acc: 0.0387 - val_loss: 4.7128 - val_acc: 0.0599\n",
      "Epoch 8/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.7902 - acc: 0.0462 - val_loss: 4.6497 - val_acc: 0.0657\n",
      "Epoch 9/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.7283 - acc: 0.0521 - val_loss: 4.6031 - val_acc: 0.0665\n",
      "Epoch 10/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.6744 - acc: 0.0587 - val_loss: 4.5275 - val_acc: 0.0788\n",
      "Epoch 11/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.6280 - acc: 0.0647 - val_loss: 4.4615 - val_acc: 0.0880\n",
      "Epoch 12/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.5830 - acc: 0.0706 - val_loss: 4.4305 - val_acc: 0.0939\n",
      "Epoch 13/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.5409 - acc: 0.0760 - val_loss: 4.3853 - val_acc: 0.0943\n",
      "Epoch 14/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.5050 - acc: 0.0816 - val_loss: 4.3523 - val_acc: 0.1005\n",
      "Epoch 15/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.4708 - acc: 0.0868 - val_loss: 4.3456 - val_acc: 0.0964\n",
      "Epoch 16/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.4376 - acc: 0.0893 - val_loss: 4.2849 - val_acc: 0.1062\n",
      "Epoch 17/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.4078 - acc: 0.0931 - val_loss: 4.2400 - val_acc: 0.1165\n",
      "Epoch 18/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3811 - acc: 0.0969 - val_loss: 4.2200 - val_acc: 0.1150\n",
      "Epoch 19/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3562 - acc: 0.1006 - val_loss: 4.2318 - val_acc: 0.1136\n",
      "Epoch 20/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3361 - acc: 0.1032 - val_loss: 4.1650 - val_acc: 0.1234\n",
      "Epoch 21/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3074 - acc: 0.1067 - val_loss: 4.1405 - val_acc: 0.1278\n",
      "Epoch 22/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2864 - acc: 0.1098 - val_loss: 4.1719 - val_acc: 0.1237\n",
      "Epoch 23/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2615 - acc: 0.1119 - val_loss: 4.1302 - val_acc: 0.1299\n",
      "Epoch 24/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2445 - acc: 0.1147 - val_loss: 4.2019 - val_acc: 0.1206\n",
      "Epoch 25/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2264 - acc: 0.1174 - val_loss: 4.1289 - val_acc: 0.1295\n",
      "Epoch 26/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2088 - acc: 0.1194 - val_loss: 4.1744 - val_acc: 0.1202\n",
      "Epoch 27/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1874 - acc: 0.1221 - val_loss: 4.1749 - val_acc: 0.1229\n",
      "Epoch 28/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1771 - acc: 0.1242 - val_loss: 4.0753 - val_acc: 0.1412\n",
      "Epoch 29/50\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 4.1562 - acc: 0.1259 - val_loss: 4.1757 - val_acc: 0.1222\n",
      "Epoch 30/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1403 - acc: 0.1293 - val_loss: 4.0168 - val_acc: 0.1463\n",
      "Epoch 31/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1272 - acc: 0.1289 - val_loss: 4.1705 - val_acc: 0.1198\n",
      "Epoch 32/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1112 - acc: 0.1322 - val_loss: 4.0494 - val_acc: 0.1385\n",
      "Epoch 33/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1021 - acc: 0.1346 - val_loss: 4.0837 - val_acc: 0.1357\n",
      "Epoch 34/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0830 - acc: 0.1359 - val_loss: 4.0721 - val_acc: 0.1364\n",
      "Epoch 35/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0707 - acc: 0.1379 - val_loss: 4.0735 - val_acc: 0.1348\n",
      "Epoch 36/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0609 - acc: 0.1389 - val_loss: 4.0804 - val_acc: 0.1352\n",
      "Epoch 37/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0474 - acc: 0.1418 - val_loss: 4.0743 - val_acc: 0.1349\n",
      "Epoch 38/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0341 - acc: 0.1437 - val_loss: 4.0432 - val_acc: 0.1412\n",
      "Epoch 39/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0242 - acc: 0.1435 - val_loss: 4.0185 - val_acc: 0.1446\n",
      "Epoch 40/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0090 - acc: 0.1469 - val_loss: 4.0403 - val_acc: 0.1381\n",
      "Epoch 41/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9978 - acc: 0.1466 - val_loss: 4.1210 - val_acc: 0.1287\n",
      "Epoch 42/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9854 - acc: 0.1488 - val_loss: 4.2714 - val_acc: 0.1142\n",
      "Epoch 43/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9778 - acc: 0.1514 - val_loss: 4.1216 - val_acc: 0.1333\n",
      "Epoch 44/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9667 - acc: 0.1522 - val_loss: 4.0706 - val_acc: 0.1378\n",
      "Epoch 45/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9570 - acc: 0.1543 - val_loss: 4.0405 - val_acc: 0.1451\n",
      "Epoch 46/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9447 - acc: 0.1545 - val_loss: 3.9572 - val_acc: 0.1541\n",
      "Epoch 47/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9310 - acc: 0.1562 - val_loss: 3.9463 - val_acc: 0.1540\n",
      "Epoch 48/50\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 3.9220 - acc: 0.1574 - val_loss: 3.9665 - val_acc: 0.1487\n",
      "Epoch 49/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9109 - acc: 0.1587 - val_loss: 3.9192 - val_acc: 0.1588\n",
      "Epoch 50/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9045 - acc: 0.1610 - val_loss: 3.8916 - val_acc: 0.1597\n",
      "10000/10000 [==============================] - 1s 143us/step\n",
      "Test loss: 3.8916304641723634\n",
      "Test accuracy: 0.1597\n",
      "Runtime: 1234.9703407287598\n",
      "Training RMSprop optimizer\n",
      "Epoch 1/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.9497 - acc: 0.0327 - val_loss: 4.6417 - val_acc: 0.0590\n",
      "Epoch 2/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.7054 - acc: 0.0578 - val_loss: 4.5453 - val_acc: 0.0767\n",
      "Epoch 3/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.6665 - acc: 0.0653 - val_loss: 4.5877 - val_acc: 0.0719\n",
      "Epoch 4/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.6640 - acc: 0.0648 - val_loss: 4.6474 - val_acc: 0.0651\n",
      "Epoch 5/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.6786 - acc: 0.0628 - val_loss: 4.7051 - val_acc: 0.0626\n",
      "Epoch 6/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.6987 - acc: 0.0622 - val_loss: 4.7183 - val_acc: 0.0624\n",
      "Epoch 7/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.7219 - acc: 0.0590 - val_loss: 4.5778 - val_acc: 0.0723\n",
      "Epoch 8/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.7441 - acc: 0.0578 - val_loss: 4.6507 - val_acc: 0.0646\n",
      "Epoch 9/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.7820 - acc: 0.0527 - val_loss: 4.6735 - val_acc: 0.0586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8314 - acc: 0.0474 - val_loss: 4.7025 - val_acc: 0.0573\n",
      "Epoch 11/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8661 - acc: 0.0446 - val_loss: 4.7488 - val_acc: 0.0515\n",
      "Epoch 12/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8788 - acc: 0.0425 - val_loss: 4.7716 - val_acc: 0.0485\n",
      "Epoch 13/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8849 - acc: 0.0404 - val_loss: 4.9086 - val_acc: 0.0411\n",
      "Epoch 14/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8923 - acc: 0.0406 - val_loss: 5.0777 - val_acc: 0.0388\n",
      "Epoch 15/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8887 - acc: 0.0394 - val_loss: 4.7517 - val_acc: 0.0524\n",
      "Epoch 16/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8673 - acc: 0.0411 - val_loss: 4.7493 - val_acc: 0.0458\n",
      "Epoch 17/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8601 - acc: 0.0401 - val_loss: 4.7097 - val_acc: 0.0535\n",
      "Epoch 18/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8470 - acc: 0.0425 - val_loss: 4.7704 - val_acc: 0.0481\n",
      "Epoch 19/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8352 - acc: 0.0435 - val_loss: 4.8183 - val_acc: 0.0442\n",
      "Epoch 20/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8278 - acc: 0.0458 - val_loss: 4.8052 - val_acc: 0.0421\n",
      "Epoch 21/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8295 - acc: 0.0450 - val_loss: 4.7031 - val_acc: 0.0524\n",
      "Epoch 22/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8186 - acc: 0.0454 - val_loss: 4.7653 - val_acc: 0.0523\n",
      "Epoch 23/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8247 - acc: 0.0443 - val_loss: 4.7247 - val_acc: 0.0496\n",
      "Epoch 24/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8234 - acc: 0.0449 - val_loss: 4.7317 - val_acc: 0.0519\n",
      "Epoch 25/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8266 - acc: 0.0456 - val_loss: 4.7167 - val_acc: 0.0544\n",
      "Epoch 26/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8279 - acc: 0.0433 - val_loss: 4.7490 - val_acc: 0.0511\n",
      "Epoch 27/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8319 - acc: 0.0445 - val_loss: 4.7456 - val_acc: 0.0505\n",
      "Epoch 28/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8407 - acc: 0.0439 - val_loss: 4.8018 - val_acc: 0.0413\n",
      "Epoch 29/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8390 - acc: 0.0435 - val_loss: 4.7389 - val_acc: 0.0494\n",
      "Epoch 30/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8412 - acc: 0.0437 - val_loss: 4.8182 - val_acc: 0.0416\n",
      "Epoch 31/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8499 - acc: 0.0424 - val_loss: 4.8440 - val_acc: 0.0449\n",
      "Epoch 32/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8590 - acc: 0.0415 - val_loss: 4.9603 - val_acc: 0.0354\n",
      "Epoch 33/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8584 - acc: 0.0407 - val_loss: 4.8370 - val_acc: 0.0374\n",
      "Epoch 34/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8610 - acc: 0.0410 - val_loss: 4.8089 - val_acc: 0.0377\n",
      "Epoch 35/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8612 - acc: 0.0407 - val_loss: 4.8935 - val_acc: 0.0375\n",
      "Epoch 36/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8641 - acc: 0.0404 - val_loss: 4.8408 - val_acc: 0.0406\n",
      "Epoch 37/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8747 - acc: 0.0399 - val_loss: 4.8694 - val_acc: 0.0340\n",
      "Epoch 38/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8770 - acc: 0.0393 - val_loss: 4.7873 - val_acc: 0.0460\n",
      "Epoch 39/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8864 - acc: 0.0385 - val_loss: 4.8266 - val_acc: 0.0361\n",
      "Epoch 40/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8919 - acc: 0.0376 - val_loss: 4.9038 - val_acc: 0.0336\n",
      "Epoch 41/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8899 - acc: 0.0384 - val_loss: 4.7996 - val_acc: 0.0473\n",
      "Epoch 42/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8984 - acc: 0.0370 - val_loss: 4.8612 - val_acc: 0.0366\n",
      "Epoch 43/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8913 - acc: 0.0380 - val_loss: 4.8058 - val_acc: 0.0419\n",
      "Epoch 44/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8998 - acc: 0.0375 - val_loss: 4.8195 - val_acc: 0.0421\n",
      "Epoch 45/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.9006 - acc: 0.0376 - val_loss: 4.9566 - val_acc: 0.0338\n",
      "Epoch 46/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.9067 - acc: 0.0368 - val_loss: 4.8658 - val_acc: 0.0320\n",
      "Epoch 47/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.9069 - acc: 0.0369 - val_loss: 4.8185 - val_acc: 0.0390\n",
      "Epoch 48/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.9061 - acc: 0.0370 - val_loss: 4.8666 - val_acc: 0.0355\n",
      "Epoch 49/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.9133 - acc: 0.0364 - val_loss: 4.9605 - val_acc: 0.0291\n",
      "Epoch 50/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.9130 - acc: 0.0364 - val_loss: 4.8804 - val_acc: 0.0287\n",
      "10000/10000 [==============================] - 1s 126us/step\n",
      "Test loss: 4.8803506820678715\n",
      "Test accuracy: 0.0287\n",
      "Runtime: 1247.7888658046722\n",
      "Training Adagrad optimizer\n",
      "Epoch 1/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.0430 - acc: 0.0224 - val_loss: 4.7617 - val_acc: 0.0491\n",
      "Epoch 2/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.7292 - acc: 0.0516 - val_loss: 4.5426 - val_acc: 0.0745\n",
      "Epoch 3/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.5925 - acc: 0.0673 - val_loss: 4.4259 - val_acc: 0.0907\n",
      "Epoch 4/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.5171 - acc: 0.0785 - val_loss: 4.3626 - val_acc: 0.0992\n",
      "Epoch 5/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 4.4562 - acc: 0.0866 - val_loss: 4.2970 - val_acc: 0.1065\n",
      "Epoch 6/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.4061 - acc: 0.0919 - val_loss: 4.3206 - val_acc: 0.1043\n",
      "Epoch 7/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3694 - acc: 0.0973 - val_loss: 4.3405 - val_acc: 0.1048\n",
      "Epoch 8/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3333 - acc: 0.1035 - val_loss: 4.2853 - val_acc: 0.1080\n",
      "Epoch 9/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3041 - acc: 0.1048 - val_loss: 4.2710 - val_acc: 0.1101\n",
      "Epoch 10/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2809 - acc: 0.1085 - val_loss: 4.2600 - val_acc: 0.1118\n",
      "Epoch 11/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2562 - acc: 0.1125 - val_loss: 4.2412 - val_acc: 0.1150\n",
      "Epoch 12/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2338 - acc: 0.1155 - val_loss: 4.1637 - val_acc: 0.1252\n",
      "Epoch 13/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2137 - acc: 0.1174 - val_loss: 4.1390 - val_acc: 0.1302\n",
      "Epoch 14/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1987 - acc: 0.1204 - val_loss: 4.2319 - val_acc: 0.1172\n",
      "Epoch 15/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1863 - acc: 0.1222 - val_loss: 4.2110 - val_acc: 0.1191\n",
      "Epoch 16/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1675 - acc: 0.1244 - val_loss: 4.2286 - val_acc: 0.1162\n",
      "Epoch 17/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1510 - acc: 0.1258 - val_loss: 4.1580 - val_acc: 0.1250\n",
      "Epoch 18/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1432 - acc: 0.1275 - val_loss: 4.1890 - val_acc: 0.1215\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1299 - acc: 0.1305 - val_loss: 4.1555 - val_acc: 0.1255\n",
      "Epoch 20/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1236 - acc: 0.1308 - val_loss: 4.1778 - val_acc: 0.1226\n",
      "Epoch 21/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1100 - acc: 0.1333 - val_loss: 4.2052 - val_acc: 0.1174\n",
      "Epoch 22/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0985 - acc: 0.1342 - val_loss: 4.1471 - val_acc: 0.1253\n",
      "Epoch 23/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0925 - acc: 0.1353 - val_loss: 4.1496 - val_acc: 0.1262\n",
      "Epoch 24/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0845 - acc: 0.1360 - val_loss: 4.1684 - val_acc: 0.1223\n",
      "Epoch 25/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0747 - acc: 0.1369 - val_loss: 4.1530 - val_acc: 0.1237\n",
      "Epoch 26/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0631 - acc: 0.1391 - val_loss: 4.1565 - val_acc: 0.1246\n",
      "Epoch 27/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0620 - acc: 0.1400 - val_loss: 4.1971 - val_acc: 0.1196\n",
      "Epoch 28/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0483 - acc: 0.1413 - val_loss: 4.1264 - val_acc: 0.1279\n",
      "Epoch 29/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0443 - acc: 0.1422 - val_loss: 4.0598 - val_acc: 0.1377\n",
      "Epoch 30/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0368 - acc: 0.1428 - val_loss: 4.2253 - val_acc: 0.1180\n",
      "Epoch 31/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0305 - acc: 0.1431 - val_loss: 4.1602 - val_acc: 0.1230\n",
      "Epoch 32/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0269 - acc: 0.1440 - val_loss: 4.1068 - val_acc: 0.1300\n",
      "Epoch 33/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0188 - acc: 0.1449 - val_loss: 4.1372 - val_acc: 0.1270\n",
      "Epoch 34/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0123 - acc: 0.1467 - val_loss: 4.1766 - val_acc: 0.1239\n",
      "Epoch 35/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0030 - acc: 0.1482 - val_loss: 4.1373 - val_acc: 0.1261\n",
      "Epoch 36/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9990 - acc: 0.1476 - val_loss: 4.0761 - val_acc: 0.1321\n",
      "Epoch 37/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9918 - acc: 0.1495 - val_loss: 4.1096 - val_acc: 0.1307\n",
      "Epoch 38/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9908 - acc: 0.1497 - val_loss: 4.1536 - val_acc: 0.1266\n",
      "Epoch 39/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9815 - acc: 0.1502 - val_loss: 4.1080 - val_acc: 0.1300\n",
      "Epoch 40/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9758 - acc: 0.1493 - val_loss: 4.1419 - val_acc: 0.1265\n",
      "Epoch 41/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9753 - acc: 0.1492 - val_loss: 4.1194 - val_acc: 0.1298\n",
      "Epoch 42/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9690 - acc: 0.1520 - val_loss: 4.1092 - val_acc: 0.1300\n",
      "Epoch 43/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9658 - acc: 0.1543 - val_loss: 4.1268 - val_acc: 0.1303\n",
      "Epoch 44/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9614 - acc: 0.1527 - val_loss: 4.0905 - val_acc: 0.1331\n",
      "Epoch 45/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9575 - acc: 0.1542 - val_loss: 4.0526 - val_acc: 0.1372\n",
      "Epoch 46/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9534 - acc: 0.1543 - val_loss: 4.1526 - val_acc: 0.1275\n",
      "Epoch 47/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 3.9482 - acc: 0.1560 - val_loss: 4.1177 - val_acc: 0.1327\n",
      "Epoch 48/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9403 - acc: 0.1564 - val_loss: 4.1136 - val_acc: 0.1303\n",
      "Epoch 49/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9391 - acc: 0.1569 - val_loss: 4.1067 - val_acc: 0.1333\n",
      "Epoch 50/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9312 - acc: 0.1576 - val_loss: 4.1348 - val_acc: 0.1302\n",
      "10000/10000 [==============================] - 1s 127us/step\n",
      "Test loss: 4.134802265167236\n",
      "Test accuracy: 0.1302\n",
      "Runtime: 1253.2157349586487\n",
      "Training Adadelta optimizer\n",
      "Epoch 1/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.0688 - acc: 0.0197 - val_loss: 4.8003 - val_acc: 0.0404\n",
      "Epoch 2/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.7374 - acc: 0.0538 - val_loss: 4.5508 - val_acc: 0.0770\n",
      "Epoch 3/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.5863 - acc: 0.0702 - val_loss: 4.5602 - val_acc: 0.0775\n",
      "Epoch 4/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.5066 - acc: 0.0820 - val_loss: 4.3407 - val_acc: 0.1019\n",
      "Epoch 5/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.4519 - acc: 0.0892 - val_loss: 4.2902 - val_acc: 0.1038\n",
      "Epoch 6/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.4108 - acc: 0.0955 - val_loss: 4.2413 - val_acc: 0.1149\n",
      "Epoch 7/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3816 - acc: 0.0987 - val_loss: 4.2411 - val_acc: 0.1129\n",
      "Epoch 8/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3686 - acc: 0.1008 - val_loss: 4.3086 - val_acc: 0.1061\n",
      "Epoch 9/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3590 - acc: 0.1033 - val_loss: 4.1823 - val_acc: 0.1233\n",
      "Epoch 10/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3488 - acc: 0.1061 - val_loss: 4.2585 - val_acc: 0.1155\n",
      "Epoch 11/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3364 - acc: 0.1084 - val_loss: 4.3537 - val_acc: 0.1040\n",
      "Epoch 12/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3423 - acc: 0.1066 - val_loss: 4.3385 - val_acc: 0.1022\n",
      "Epoch 13/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3320 - acc: 0.1072 - val_loss: 4.2066 - val_acc: 0.1194\n",
      "Epoch 14/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3307 - acc: 0.1083 - val_loss: 4.2385 - val_acc: 0.1162\n",
      "Epoch 15/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3284 - acc: 0.1088 - val_loss: 4.3756 - val_acc: 0.0983\n",
      "Epoch 16/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3311 - acc: 0.1092 - val_loss: 4.3474 - val_acc: 0.1034\n",
      "Epoch 17/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3360 - acc: 0.1089 - val_loss: 4.4212 - val_acc: 0.0930\n",
      "Epoch 18/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3363 - acc: 0.1092 - val_loss: 4.3415 - val_acc: 0.1086\n",
      "Epoch 19/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3319 - acc: 0.1097 - val_loss: 4.3229 - val_acc: 0.1029\n",
      "Epoch 20/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3295 - acc: 0.1077 - val_loss: 4.3954 - val_acc: 0.0960\n",
      "Epoch 21/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3324 - acc: 0.1092 - val_loss: 4.2541 - val_acc: 0.1120\n",
      "Epoch 22/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3340 - acc: 0.1097 - val_loss: 4.4092 - val_acc: 0.0975\n",
      "Epoch 23/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3355 - acc: 0.1098 - val_loss: 4.2614 - val_acc: 0.1139\n",
      "Epoch 24/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3351 - acc: 0.1095 - val_loss: 4.1202 - val_acc: 0.1311\n",
      "Epoch 25/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3396 - acc: 0.1092 - val_loss: 4.4107 - val_acc: 0.0954\n",
      "Epoch 26/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3356 - acc: 0.1088 - val_loss: 4.4070 - val_acc: 0.0974\n",
      "Epoch 27/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3386 - acc: 0.1085 - val_loss: 4.4761 - val_acc: 0.0885\n",
      "Epoch 28/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3387 - acc: 0.1086 - val_loss: 4.2466 - val_acc: 0.1161\n",
      "Epoch 29/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3402 - acc: 0.1079 - val_loss: 4.3862 - val_acc: 0.1019\n",
      "Epoch 30/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3423 - acc: 0.1081 - val_loss: 4.2275 - val_acc: 0.1104\n",
      "Epoch 31/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3452 - acc: 0.1086 - val_loss: 4.4524 - val_acc: 0.0967\n",
      "Epoch 32/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3498 - acc: 0.1073 - val_loss: 4.4561 - val_acc: 0.0919\n",
      "Epoch 33/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3468 - acc: 0.1082 - val_loss: 4.4930 - val_acc: 0.0921\n",
      "Epoch 34/50\n",
      "3125/3125 [==============================] - 27s 9ms/step - loss: 4.3447 - acc: 0.1069 - val_loss: 4.2863 - val_acc: 0.1085\n",
      "Epoch 35/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3521 - acc: 0.1067 - val_loss: 4.4492 - val_acc: 0.0914\n",
      "Epoch 36/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3554 - acc: 0.1065 - val_loss: 4.3215 - val_acc: 0.1053\n",
      "Epoch 37/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3551 - acc: 0.1060 - val_loss: 4.4305 - val_acc: 0.0925\n",
      "Epoch 38/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3612 - acc: 0.1062 - val_loss: 4.3812 - val_acc: 0.1010\n",
      "Epoch 39/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3585 - acc: 0.1065 - val_loss: 4.3681 - val_acc: 0.1030\n",
      "Epoch 40/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3649 - acc: 0.1059 - val_loss: 4.3717 - val_acc: 0.0966\n",
      "Epoch 41/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3663 - acc: 0.1059 - val_loss: 4.2144 - val_acc: 0.1163\n",
      "Epoch 42/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3683 - acc: 0.1050 - val_loss: 4.6620 - val_acc: 0.0771\n",
      "Epoch 43/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3685 - acc: 0.1065 - val_loss: 4.2637 - val_acc: 0.1100\n",
      "Epoch 44/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3692 - acc: 0.1041 - val_loss: 4.4826 - val_acc: 0.0937\n",
      "Epoch 45/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3709 - acc: 0.1054 - val_loss: 4.4205 - val_acc: 0.0958\n",
      "Epoch 46/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3698 - acc: 0.1046 - val_loss: 4.4221 - val_acc: 0.0907\n",
      "Epoch 47/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 4.3792 - acc: 0.1034 - val_loss: 4.3911 - val_acc: 0.0961\n",
      "Epoch 48/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3795 - acc: 0.1044 - val_loss: 4.4331 - val_acc: 0.0910\n",
      "Epoch 49/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3803 - acc: 0.1042 - val_loss: 4.3320 - val_acc: 0.1034\n",
      "Epoch 50/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3815 - acc: 0.1041 - val_loss: 4.4073 - val_acc: 0.0900\n",
      "10000/10000 [==============================] - 1s 129us/step\n",
      "Test loss: 4.407295335388183\n",
      "Test accuracy: 0.09\n",
      "Runtime: 1262.6598680019379\n",
      "Training Adam optimizer\n",
      "Epoch 1/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.0965 - acc: 0.0178 - val_loss: 4.8952 - val_acc: 0.0299\n",
      "Epoch 2/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8205 - acc: 0.0417 - val_loss: 4.7447 - val_acc: 0.0509\n",
      "Epoch 3/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.6866 - acc: 0.0571 - val_loss: 4.5761 - val_acc: 0.0669\n",
      "Epoch 4/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.6143 - acc: 0.0668 - val_loss: 4.5785 - val_acc: 0.0728\n",
      "Epoch 5/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 4.5593 - acc: 0.0725 - val_loss: 4.4372 - val_acc: 0.0892\n",
      "Epoch 6/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.5140 - acc: 0.0789 - val_loss: 4.4026 - val_acc: 0.0900\n",
      "Epoch 7/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.4832 - acc: 0.0830 - val_loss: 4.3598 - val_acc: 0.0928\n",
      "Epoch 8/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.4575 - acc: 0.0864 - val_loss: 4.3902 - val_acc: 0.0927\n",
      "Epoch 9/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.4373 - acc: 0.0878 - val_loss: 4.3357 - val_acc: 0.0946\n",
      "Epoch 10/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 4.4237 - acc: 0.0921 - val_loss: 4.2881 - val_acc: 0.1063\n",
      "Epoch 11/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.4028 - acc: 0.0947 - val_loss: 4.2807 - val_acc: 0.1066\n",
      "Epoch 12/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3895 - acc: 0.0939 - val_loss: 4.2722 - val_acc: 0.1095\n",
      "Epoch 13/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3794 - acc: 0.0961 - val_loss: 4.3096 - val_acc: 0.0978\n",
      "Epoch 14/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3692 - acc: 0.0978 - val_loss: 4.2746 - val_acc: 0.1081\n",
      "Epoch 15/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3567 - acc: 0.0993 - val_loss: 4.2947 - val_acc: 0.1042\n",
      "Epoch 16/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3505 - acc: 0.0995 - val_loss: 4.2971 - val_acc: 0.1047\n",
      "Epoch 17/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3405 - acc: 0.1010 - val_loss: 4.3333 - val_acc: 0.1008\n",
      "Epoch 18/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3293 - acc: 0.1024 - val_loss: 4.3080 - val_acc: 0.1045\n",
      "Epoch 19/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3224 - acc: 0.1049 - val_loss: 4.3303 - val_acc: 0.1013\n",
      "Epoch 20/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3223 - acc: 0.1042 - val_loss: 4.2657 - val_acc: 0.1072\n",
      "Epoch 21/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3099 - acc: 0.1043 - val_loss: 4.3233 - val_acc: 0.1013\n",
      "Epoch 22/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3095 - acc: 0.1053 - val_loss: 4.2924 - val_acc: 0.1033\n",
      "Epoch 23/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3026 - acc: 0.1067 - val_loss: 4.3895 - val_acc: 0.0916\n",
      "Epoch 24/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2946 - acc: 0.1070 - val_loss: 4.2164 - val_acc: 0.1128\n",
      "Epoch 25/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2899 - acc: 0.1073 - val_loss: 4.3408 - val_acc: 0.1001\n",
      "Epoch 26/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2903 - acc: 0.1092 - val_loss: 4.3740 - val_acc: 0.0985\n",
      "Epoch 27/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2843 - acc: 0.1087 - val_loss: 4.2863 - val_acc: 0.1046\n",
      "Epoch 28/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2851 - acc: 0.1079 - val_loss: 4.4584 - val_acc: 0.0920\n",
      "Epoch 29/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2809 - acc: 0.1087 - val_loss: 4.2481 - val_acc: 0.1099\n",
      "Epoch 30/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 4.2800 - acc: 0.1095 - val_loss: 4.3652 - val_acc: 0.1003\n",
      "Epoch 31/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2733 - acc: 0.1094 - val_loss: 4.4724 - val_acc: 0.0872\n",
      "Epoch 32/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2753 - acc: 0.1090 - val_loss: 4.4147 - val_acc: 0.0933\n",
      "Epoch 33/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2731 - acc: 0.1104 - val_loss: 4.4046 - val_acc: 0.0945\n",
      "Epoch 34/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2683 - acc: 0.1107 - val_loss: 4.2749 - val_acc: 0.1085\n",
      "Epoch 35/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2671 - acc: 0.1116 - val_loss: 4.4116 - val_acc: 0.0955\n",
      "Epoch 36/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2685 - acc: 0.1107 - val_loss: 4.3535 - val_acc: 0.1012\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2731 - acc: 0.1097 - val_loss: 4.3932 - val_acc: 0.0956\n",
      "Epoch 38/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2579 - acc: 0.1112 - val_loss: 4.3234 - val_acc: 0.1040\n",
      "Epoch 39/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2640 - acc: 0.1125 - val_loss: 4.4533 - val_acc: 0.0902\n",
      "Epoch 40/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2662 - acc: 0.1137 - val_loss: 4.1907 - val_acc: 0.1185\n",
      "Epoch 41/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2662 - acc: 0.1123 - val_loss: 4.2816 - val_acc: 0.1116\n",
      "Epoch 42/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2613 - acc: 0.1114 - val_loss: 4.3101 - val_acc: 0.1063\n",
      "Epoch 43/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2611 - acc: 0.1119 - val_loss: 4.2204 - val_acc: 0.1166\n",
      "Epoch 44/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2605 - acc: 0.1109 - val_loss: 4.2764 - val_acc: 0.1058\n",
      "Epoch 45/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2574 - acc: 0.1130 - val_loss: 4.2668 - val_acc: 0.1137\n",
      "Epoch 46/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2592 - acc: 0.1112 - val_loss: 4.3270 - val_acc: 0.1042\n",
      "Epoch 47/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2568 - acc: 0.1130 - val_loss: 4.3752 - val_acc: 0.1067\n",
      "Epoch 48/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2522 - acc: 0.1139 - val_loss: 4.4173 - val_acc: 0.1002\n",
      "Epoch 49/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2634 - acc: 0.1121 - val_loss: 4.3263 - val_acc: 0.1034\n",
      "Epoch 50/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2543 - acc: 0.1131 - val_loss: 4.3930 - val_acc: 0.1026\n",
      "10000/10000 [==============================] - 1s 134us/step\n",
      "Test loss: 4.3929524444580075\n",
      "Test accuracy: 0.1026\n",
      "Runtime: 1263.0200555324554\n",
      "Training Adamax optimizer\n",
      "Epoch 1/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.0345 - acc: 0.0236 - val_loss: 4.7009 - val_acc: 0.0564\n",
      "Epoch 2/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.7080 - acc: 0.0551 - val_loss: 4.5171 - val_acc: 0.0746\n",
      "Epoch 3/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.5419 - acc: 0.0752 - val_loss: 4.3767 - val_acc: 0.0951\n",
      "Epoch 4/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.4225 - acc: 0.0909 - val_loss: 4.2819 - val_acc: 0.1037\n",
      "Epoch 5/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3299 - acc: 0.1016 - val_loss: 4.2269 - val_acc: 0.1137\n",
      "Epoch 6/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 4.2508 - acc: 0.1115 - val_loss: 4.2133 - val_acc: 0.1182\n",
      "Epoch 7/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1919 - acc: 0.1198 - val_loss: 4.2008 - val_acc: 0.1196\n",
      "Epoch 8/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1395 - acc: 0.1274 - val_loss: 4.2256 - val_acc: 0.1211\n",
      "Epoch 9/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0945 - acc: 0.1344 - val_loss: 3.9639 - val_acc: 0.1474\n",
      "Epoch 10/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0608 - acc: 0.1384 - val_loss: 4.0020 - val_acc: 0.1452\n",
      "Epoch 11/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0259 - acc: 0.1429 - val_loss: 4.0745 - val_acc: 0.1375\n",
      "Epoch 12/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0005 - acc: 0.1482 - val_loss: 4.0282 - val_acc: 0.1439\n",
      "Epoch 13/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9784 - acc: 0.1506 - val_loss: 4.1686 - val_acc: 0.1372\n",
      "Epoch 14/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9515 - acc: 0.1537 - val_loss: 4.0776 - val_acc: 0.1390\n",
      "Epoch 15/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9394 - acc: 0.1557 - val_loss: 3.9187 - val_acc: 0.1604\n",
      "Epoch 16/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9201 - acc: 0.1574 - val_loss: 4.1063 - val_acc: 0.1400\n",
      "Epoch 17/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9023 - acc: 0.1612 - val_loss: 4.0555 - val_acc: 0.1416\n",
      "Epoch 18/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8921 - acc: 0.1617 - val_loss: 3.9654 - val_acc: 0.1545\n",
      "Epoch 19/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8796 - acc: 0.1643 - val_loss: 4.1267 - val_acc: 0.1429\n",
      "Epoch 20/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8709 - acc: 0.1657 - val_loss: 4.0197 - val_acc: 0.1494\n",
      "Epoch 21/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 3.8592 - acc: 0.1653 - val_loss: 3.9879 - val_acc: 0.1573\n",
      "Epoch 22/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8468 - acc: 0.1691 - val_loss: 4.0342 - val_acc: 0.1536\n",
      "Epoch 23/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 3.8388 - acc: 0.1703 - val_loss: 3.9356 - val_acc: 0.1614\n",
      "Epoch 24/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8321 - acc: 0.1708 - val_loss: 4.1513 - val_acc: 0.1426\n",
      "Epoch 25/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8268 - acc: 0.1724 - val_loss: 4.1608 - val_acc: 0.1414\n",
      "Epoch 26/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8159 - acc: 0.1736 - val_loss: 3.9125 - val_acc: 0.1675\n",
      "Epoch 27/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8090 - acc: 0.1752 - val_loss: 3.9005 - val_acc: 0.1616\n",
      "Epoch 28/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8079 - acc: 0.1755 - val_loss: 3.9510 - val_acc: 0.1600\n",
      "Epoch 29/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8002 - acc: 0.1782 - val_loss: 3.9206 - val_acc: 0.1619\n",
      "Epoch 30/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7930 - acc: 0.1788 - val_loss: 3.9662 - val_acc: 0.1561\n",
      "Epoch 31/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7848 - acc: 0.1792 - val_loss: 3.9301 - val_acc: 0.1612\n",
      "Epoch 32/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7789 - acc: 0.1785 - val_loss: 4.0269 - val_acc: 0.1534\n",
      "Epoch 33/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7763 - acc: 0.1813 - val_loss: 3.8668 - val_acc: 0.1657\n",
      "Epoch 34/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7723 - acc: 0.1813 - val_loss: 3.9717 - val_acc: 0.1627\n",
      "Epoch 35/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7678 - acc: 0.1807 - val_loss: 3.9299 - val_acc: 0.1635\n",
      "Epoch 36/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7651 - acc: 0.1815 - val_loss: 4.0389 - val_acc: 0.1567\n",
      "Epoch 37/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7609 - acc: 0.1834 - val_loss: 4.0134 - val_acc: 0.1567\n",
      "Epoch 38/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7574 - acc: 0.1839 - val_loss: 3.9903 - val_acc: 0.1637\n",
      "Epoch 39/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7574 - acc: 0.1833 - val_loss: 3.9944 - val_acc: 0.1603\n",
      "Epoch 40/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 3.7556 - acc: 0.1844 - val_loss: 3.9192 - val_acc: 0.1669\n",
      "Epoch 41/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7541 - acc: 0.1847 - val_loss: 4.1489 - val_acc: 0.1478\n",
      "Epoch 42/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7437 - acc: 0.1858 - val_loss: 4.0003 - val_acc: 0.1605\n",
      "Epoch 43/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7446 - acc: 0.1870 - val_loss: 3.9191 - val_acc: 0.1681\n",
      "Epoch 44/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7437 - acc: 0.1851 - val_loss: 4.1093 - val_acc: 0.1461\n",
      "Epoch 45/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7355 - acc: 0.1878 - val_loss: 3.8030 - val_acc: 0.1830\n",
      "Epoch 46/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7348 - acc: 0.1875 - val_loss: 4.1099 - val_acc: 0.1473\n",
      "Epoch 47/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7377 - acc: 0.1880 - val_loss: 3.9745 - val_acc: 0.1631\n",
      "Epoch 48/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7319 - acc: 0.1881 - val_loss: 3.8988 - val_acc: 0.1699\n",
      "Epoch 49/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7341 - acc: 0.1887 - val_loss: 3.8352 - val_acc: 0.1756\n",
      "Epoch 50/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7227 - acc: 0.1888 - val_loss: 3.8749 - val_acc: 0.1749\n",
      "10000/10000 [==============================] - 1s 137us/step\n",
      "Test loss: 3.8749251670837404\n",
      "Test accuracy: 0.1749\n",
      "Runtime: 1265.916042804718\n",
      "Training Nadam optimizer\n",
      "Epoch 1/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3004 - acc: 0.0044 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 2/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0046 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 3/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0045 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 4/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0044 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 5/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0047 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 6/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0044 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 7/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 5.3001 - acc: 0.0045 - val_loss: 5.2988 - val_acc: 0.0050\n",
      "Epoch 8/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0045 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 9/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3009 - acc: 0.0046 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 10/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0043 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 11/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0046 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 12/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 5.3001 - acc: 0.0044 - val_loss: 5.2988 - val_acc: 0.0050\n",
      "Epoch 13/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3001 - acc: 0.0044 - val_loss: 5.2988 - val_acc: 0.0050\n",
      "Epoch 14/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0047 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 15/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0047 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 16/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0048 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 17/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0044 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 18/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 5.3002 - acc: 0.0045 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 19/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0044 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 20/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0046 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 21/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0046 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 22/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 5.3001 - acc: 0.0044 - val_loss: 5.2988 - val_acc: 0.0050\n",
      "Epoch 23/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0043 - val_loss: 5.2988 - val_acc: 0.0050\n",
      "Epoch 24/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0044 - val_loss: 5.2986 - val_acc: 0.0050\n",
      "Epoch 25/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0047 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 26/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 5.3001 - acc: 0.0044 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 27/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0045 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 28/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0045 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 29/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0045 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 30/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3003 - acc: 0.0043 - val_loss: 5.2986 - val_acc: 0.0050\n",
      "Epoch 31/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0045 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 32/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0047 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 33/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3003 - acc: 0.0043 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 34/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0047 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 35/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0046 - val_loss: 5.2986 - val_acc: 0.0050\n",
      "Epoch 36/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0044 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 37/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 5.3002 - acc: 0.0047 - val_loss: 5.2988 - val_acc: 0.0050\n",
      "Epoch 38/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0046 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 39/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0042 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 40/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0044 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 41/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 5.3002 - acc: 0.0044 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 42/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0047 - val_loss: 5.2986 - val_acc: 0.0050\n",
      "Epoch 43/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3001 - acc: 0.0046 - val_loss: 5.2988 - val_acc: 0.0050\n",
      "Epoch 44/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0043 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 45/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0047 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 46/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0048 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 47/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 5.3002 - acc: 0.0042 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 48/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 5.3002 - acc: 0.0046 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 49/50\n",
      "3125/3125 [==============================] - 27s 9ms/step - loss: 5.3001 - acc: 0.0049 - val_loss: 5.2988 - val_acc: 0.0050\n",
      "Epoch 50/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0043 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "10000/10000 [==============================] - 1s 132us/step\n",
      "Test loss: 5.298713544464111\n",
      "Test accuracy: 0.005\n",
      "Runtime: 1269.412302017212\n"
     ]
    }
   ],
   "source": [
    "\n",
    "opts = [('SGD', SGD()), ('RMSprop', RMSprop()), ('Adagrad', Adagrad()), ('Adadelta', Adadelta()), \n",
    "        ('Adam', Adam()), ('Adamax', Adamax()), ('Nadam', Nadam())]\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 200\n",
    "epochs = 50\n",
    "\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "\n",
    "\n",
    "for name, opt in opts:\n",
    "    print('Training ' + name + ' optimizer')\n",
    "    logs = \"logs/optimizer/\"+name\n",
    "    tensorboard = TensorBoard(log_dir=logs)\n",
    "    \n",
    "    model_name = name + '_keras_imagenet200_base.h5'\n",
    "    \n",
    "    model_base = Sequential()\n",
    "    model_base.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=train_images.shape[1:]))\n",
    "    model_base.add(Activation('relu'))\n",
    "    model_base.add(Conv2D(32, (3, 3)))\n",
    "    model_base.add(Activation('relu'))\n",
    "    model_base.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model_base.add(Dropout(0.25))\n",
    "\n",
    "    model_base.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model_base.add(Activation('relu'))\n",
    "    model_base.add(Conv2D(64, (3, 3)))\n",
    "    model_base.add(Activation('relu'))\n",
    "    model_base.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model_base.add(Dropout(0.25))\n",
    "\n",
    "    model_base.add(Flatten())\n",
    "    model_base.add(Dense(512))\n",
    "    model_base.add(Activation('relu'))\n",
    "    model_base.add(Dropout(0.5))\n",
    "    model_base.add(Dense(num_classes))\n",
    "    model_base.add(Activation('softmax'))\n",
    "    \n",
    "    # Let's train the model using RMSprop\n",
    "    model_base.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    start = time()\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=90,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(train_images)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model_base.fit_generator(datagen.flow(train_images, y_train, batch_size=batch_size),\n",
    "                                     epochs=epochs,\n",
    "                                     validation_data=(val_images, y_test),\n",
    "                                     workers=4,\n",
    "                                     steps_per_epoch=len(train_images)/batch_size, \n",
    "                                     callbacks=[tensorboard])\n",
    "    \n",
    "    # Save model and weights\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    model_path = os.path.join(save_dir, model_name)\n",
    "    model_base.save(model_path)\n",
    "\n",
    "    # Score trained model.\n",
    "    scores = model_base.evaluate(val_images, y_test, verbose=1)\n",
    "\n",
    "    end = time()\n",
    "    print('Test loss:', scores[0])\n",
    "    print('Test accuracy:', scores[1])\n",
    "    print('Runtime:', str(end-start))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SGD optimizer\n",
      "Epoch 1/100\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 5.2978 - acc: 0.0048 - val_loss: 5.2914 - val_acc: 0.0053\n",
      "Epoch 2/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.2566 - acc: 0.0070 - val_loss: 5.2114 - val_acc: 0.0113\n",
      "Epoch 3/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.1814 - acc: 0.0107 - val_loss: 5.1011 - val_acc: 0.0162\n",
      "Epoch 4/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.1120 - acc: 0.0160 - val_loss: 5.0289 - val_acc: 0.0247\n",
      "Epoch 5/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.0430 - acc: 0.0225 - val_loss: 4.9140 - val_acc: 0.0413\n",
      "Epoch 6/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.9505 - acc: 0.0305 - val_loss: 4.7935 - val_acc: 0.0493\n",
      "Epoch 7/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8572 - acc: 0.0385 - val_loss: 4.6980 - val_acc: 0.0610\n",
      "Epoch 8/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.7894 - acc: 0.0457 - val_loss: 4.6174 - val_acc: 0.0700\n",
      "Epoch 9/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.7283 - acc: 0.0530 - val_loss: 4.5622 - val_acc: 0.0761\n",
      "Epoch 10/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.6762 - acc: 0.0597 - val_loss: 4.5028 - val_acc: 0.0826\n",
      "Epoch 11/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.6283 - acc: 0.0658 - val_loss: 4.4490 - val_acc: 0.0928\n",
      "Epoch 12/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.5856 - acc: 0.0707 - val_loss: 4.4542 - val_acc: 0.0903\n",
      "Epoch 13/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.5448 - acc: 0.0769 - val_loss: 4.3673 - val_acc: 0.1004\n",
      "Epoch 14/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.5090 - acc: 0.0809 - val_loss: 4.3171 - val_acc: 0.1106\n",
      "Epoch 15/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.4733 - acc: 0.0854 - val_loss: 4.3042 - val_acc: 0.1090\n",
      "Epoch 16/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.4412 - acc: 0.0906 - val_loss: 4.2935 - val_acc: 0.1074\n",
      "Epoch 17/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.4113 - acc: 0.0938 - val_loss: 4.2629 - val_acc: 0.1123\n",
      "Epoch 18/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3824 - acc: 0.0975 - val_loss: 4.2421 - val_acc: 0.1155\n",
      "Epoch 19/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3581 - acc: 0.1006 - val_loss: 4.1927 - val_acc: 0.1182\n",
      "Epoch 20/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3344 - acc: 0.1043 - val_loss: 4.1509 - val_acc: 0.1295\n",
      "Epoch 21/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3082 - acc: 0.1055 - val_loss: 4.1397 - val_acc: 0.1275\n",
      "Epoch 22/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2863 - acc: 0.1096 - val_loss: 4.1648 - val_acc: 0.1215\n",
      "Epoch 23/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2663 - acc: 0.1119 - val_loss: 4.2415 - val_acc: 0.1146\n",
      "Epoch 24/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2432 - acc: 0.1153 - val_loss: 4.1483 - val_acc: 0.1254\n",
      "Epoch 25/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2267 - acc: 0.1169 - val_loss: 4.0898 - val_acc: 0.1337\n",
      "Epoch 26/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2084 - acc: 0.1197 - val_loss: 4.1234 - val_acc: 0.1314\n",
      "Epoch 27/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1926 - acc: 0.1211 - val_loss: 4.1774 - val_acc: 0.1235\n",
      "Epoch 28/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1739 - acc: 0.1240 - val_loss: 4.0991 - val_acc: 0.1350\n",
      "Epoch 29/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1597 - acc: 0.1264 - val_loss: 4.1126 - val_acc: 0.1360\n",
      "Epoch 30/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1396 - acc: 0.1281 - val_loss: 4.1366 - val_acc: 0.1277\n",
      "Epoch 31/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1227 - acc: 0.1307 - val_loss: 4.0530 - val_acc: 0.1402\n",
      "Epoch 32/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1140 - acc: 0.1315 - val_loss: 4.1413 - val_acc: 0.1268\n",
      "Epoch 33/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1002 - acc: 0.1344 - val_loss: 4.0272 - val_acc: 0.1422\n",
      "Epoch 34/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0838 - acc: 0.1379 - val_loss: 4.0143 - val_acc: 0.1459\n",
      "Epoch 35/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0721 - acc: 0.1371 - val_loss: 4.1575 - val_acc: 0.1293\n",
      "Epoch 36/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0598 - acc: 0.1398 - val_loss: 4.0967 - val_acc: 0.1327\n",
      "Epoch 37/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0470 - acc: 0.1404 - val_loss: 4.0948 - val_acc: 0.1373\n",
      "Epoch 38/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0394 - acc: 0.1425 - val_loss: 4.0772 - val_acc: 0.1373\n",
      "Epoch 39/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0176 - acc: 0.1471 - val_loss: 3.9937 - val_acc: 0.1519\n",
      "Epoch 40/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0118 - acc: 0.1464 - val_loss: 4.1441 - val_acc: 0.1336\n",
      "Epoch 41/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0005 - acc: 0.1483 - val_loss: 4.0351 - val_acc: 0.1436\n",
      "Epoch 42/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9909 - acc: 0.1485 - val_loss: 3.9878 - val_acc: 0.1510\n",
      "Epoch 43/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9766 - acc: 0.1505 - val_loss: 3.9808 - val_acc: 0.1493\n",
      "Epoch 44/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9693 - acc: 0.1498 - val_loss: 4.0263 - val_acc: 0.1437\n",
      "Epoch 45/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9614 - acc: 0.1523 - val_loss: 4.1672 - val_acc: 0.1319\n",
      "Epoch 46/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9497 - acc: 0.1552 - val_loss: 4.1010 - val_acc: 0.1381\n",
      "Epoch 47/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9425 - acc: 0.1565 - val_loss: 4.0455 - val_acc: 0.1410\n",
      "Epoch 48/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9339 - acc: 0.1567 - val_loss: 4.0941 - val_acc: 0.1360\n",
      "Epoch 49/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9260 - acc: 0.1568 - val_loss: 3.9734 - val_acc: 0.1506\n",
      "Epoch 50/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9162 - acc: 0.1598 - val_loss: 3.9749 - val_acc: 0.1555\n",
      "Epoch 51/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9083 - acc: 0.1596 - val_loss: 4.0289 - val_acc: 0.1436\n",
      "Epoch 52/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8988 - acc: 0.1603 - val_loss: 3.9225 - val_acc: 0.1585\n",
      "Epoch 53/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8943 - acc: 0.1613 - val_loss: 4.0598 - val_acc: 0.1417\n",
      "Epoch 54/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8823 - acc: 0.1633 - val_loss: 4.1442 - val_acc: 0.1352\n",
      "Epoch 55/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8770 - acc: 0.1638 - val_loss: 3.9457 - val_acc: 0.1568\n",
      "Epoch 56/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8722 - acc: 0.1652 - val_loss: 4.0240 - val_acc: 0.1449\n",
      "Epoch 57/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8628 - acc: 0.1660 - val_loss: 3.9512 - val_acc: 0.1569\n",
      "Epoch 58/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8568 - acc: 0.1661 - val_loss: 3.9511 - val_acc: 0.1550\n",
      "Epoch 59/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8485 - acc: 0.1685 - val_loss: 3.8387 - val_acc: 0.1743\n",
      "Epoch 60/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8400 - acc: 0.1714 - val_loss: 3.8834 - val_acc: 0.1654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8347 - acc: 0.1702 - val_loss: 3.9722 - val_acc: 0.1563\n",
      "Epoch 62/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8319 - acc: 0.1726 - val_loss: 3.8830 - val_acc: 0.1672\n",
      "Epoch 63/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8224 - acc: 0.1729 - val_loss: 3.9292 - val_acc: 0.1556\n",
      "Epoch 64/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8196 - acc: 0.1738 - val_loss: 3.9330 - val_acc: 0.1590\n",
      "Epoch 65/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8114 - acc: 0.1730 - val_loss: 3.9807 - val_acc: 0.1548\n",
      "Epoch 66/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8100 - acc: 0.1739 - val_loss: 3.9770 - val_acc: 0.1522\n",
      "Epoch 67/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7995 - acc: 0.1750 - val_loss: 3.9320 - val_acc: 0.1594\n",
      "Epoch 68/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7882 - acc: 0.1770 - val_loss: 3.8741 - val_acc: 0.1684\n",
      "Epoch 69/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7821 - acc: 0.1797 - val_loss: 3.9608 - val_acc: 0.1546\n",
      "Epoch 70/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7825 - acc: 0.1788 - val_loss: 4.1162 - val_acc: 0.1451\n",
      "Epoch 71/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7777 - acc: 0.1796 - val_loss: 3.9798 - val_acc: 0.1558\n",
      "Epoch 72/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7682 - acc: 0.1804 - val_loss: 3.9615 - val_acc: 0.1563\n",
      "Epoch 73/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7646 - acc: 0.1801 - val_loss: 3.9591 - val_acc: 0.1600\n",
      "Epoch 74/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7652 - acc: 0.1812 - val_loss: 4.0223 - val_acc: 0.1529\n",
      "Epoch 75/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7545 - acc: 0.1809 - val_loss: 3.8710 - val_acc: 0.1691\n",
      "Epoch 76/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7545 - acc: 0.1826 - val_loss: 3.8765 - val_acc: 0.1691\n",
      "Epoch 77/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7423 - acc: 0.1846 - val_loss: 3.8410 - val_acc: 0.1736\n",
      "Epoch 78/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7458 - acc: 0.1840 - val_loss: 3.9373 - val_acc: 0.1610\n",
      "Epoch 79/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7404 - acc: 0.1837 - val_loss: 3.8815 - val_acc: 0.1686\n",
      "Epoch 80/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7358 - acc: 0.1840 - val_loss: 3.9605 - val_acc: 0.1574\n",
      "Epoch 81/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7234 - acc: 0.1864 - val_loss: 3.8920 - val_acc: 0.1668\n",
      "Epoch 82/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7255 - acc: 0.1871 - val_loss: 3.8221 - val_acc: 0.1797\n",
      "Epoch 83/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7218 - acc: 0.1880 - val_loss: 3.8588 - val_acc: 0.1742\n",
      "Epoch 84/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7143 - acc: 0.1881 - val_loss: 3.9173 - val_acc: 0.1651\n",
      "Epoch 85/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7152 - acc: 0.1908 - val_loss: 3.8380 - val_acc: 0.1724\n",
      "Epoch 86/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7110 - acc: 0.1900 - val_loss: 3.9085 - val_acc: 0.1645\n",
      "Epoch 87/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7016 - acc: 0.1900 - val_loss: 3.8850 - val_acc: 0.1690\n",
      "Epoch 88/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7003 - acc: 0.1909 - val_loss: 3.9769 - val_acc: 0.1528\n",
      "Epoch 89/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7003 - acc: 0.1912 - val_loss: 3.9775 - val_acc: 0.1574\n",
      "Epoch 90/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6968 - acc: 0.1912 - val_loss: 3.7551 - val_acc: 0.1833\n",
      "Epoch 91/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6935 - acc: 0.1923 - val_loss: 3.9341 - val_acc: 0.1621\n",
      "Epoch 92/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6860 - acc: 0.1916 - val_loss: 3.8939 - val_acc: 0.1653\n",
      "Epoch 93/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6816 - acc: 0.1947 - val_loss: 3.8924 - val_acc: 0.1737\n",
      "Epoch 94/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6794 - acc: 0.1922 - val_loss: 3.8845 - val_acc: 0.1668\n",
      "Epoch 95/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6752 - acc: 0.1939 - val_loss: 3.8993 - val_acc: 0.1630\n",
      "Epoch 96/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6728 - acc: 0.1944 - val_loss: 3.8600 - val_acc: 0.1754\n",
      "Epoch 97/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6650 - acc: 0.1948 - val_loss: 3.9931 - val_acc: 0.1585\n",
      "Epoch 98/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6646 - acc: 0.1953 - val_loss: 4.0023 - val_acc: 0.1559\n",
      "Epoch 99/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6631 - acc: 0.1972 - val_loss: 3.9016 - val_acc: 0.1655\n",
      "Epoch 100/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6604 - acc: 0.1969 - val_loss: 3.7905 - val_acc: 0.1810\n",
      "10000/10000 [==============================] - 1s 125us/step\n",
      "Test loss: 3.790474868011475\n",
      "Test accuracy: 0.181\n",
      "Runtime: 2496.592635154724\n",
      "Training Adamax optimizer\n",
      "Epoch 1/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.1291 - acc: 0.0164 - val_loss: 4.8706 - val_acc: 0.0384\n",
      "Epoch 2/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.7691 - acc: 0.0489 - val_loss: 4.5008 - val_acc: 0.0828\n",
      "Epoch 3/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.5444 - acc: 0.0749 - val_loss: 4.3769 - val_acc: 0.0910\n",
      "Epoch 4/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.4032 - acc: 0.0927 - val_loss: 4.2911 - val_acc: 0.1041\n",
      "Epoch 5/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2964 - acc: 0.1059 - val_loss: 4.1664 - val_acc: 0.1213\n",
      "Epoch 6/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2246 - acc: 0.1167 - val_loss: 4.1426 - val_acc: 0.1256\n",
      "Epoch 7/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1653 - acc: 0.1238 - val_loss: 4.1263 - val_acc: 0.1234\n",
      "Epoch 8/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1192 - acc: 0.1286 - val_loss: 4.0455 - val_acc: 0.1377\n",
      "Epoch 9/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0751 - acc: 0.1359 - val_loss: 4.0399 - val_acc: 0.1353\n",
      "Epoch 10/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0450 - acc: 0.1399 - val_loss: 4.0614 - val_acc: 0.1362\n",
      "Epoch 11/100\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 4.0207 - acc: 0.1425 - val_loss: 4.1567 - val_acc: 0.1283\n",
      "Epoch 12/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9927 - acc: 0.1483 - val_loss: 4.1383 - val_acc: 0.1296\n",
      "Epoch 13/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9742 - acc: 0.1506 - val_loss: 4.0987 - val_acc: 0.1343\n",
      "Epoch 14/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9543 - acc: 0.1522 - val_loss: 3.9434 - val_acc: 0.1588\n",
      "Epoch 15/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9341 - acc: 0.1563 - val_loss: 4.0152 - val_acc: 0.1451\n",
      "Epoch 16/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9177 - acc: 0.1590 - val_loss: 4.0619 - val_acc: 0.1411\n",
      "Epoch 17/100\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 3.9010 - acc: 0.1610 - val_loss: 4.0138 - val_acc: 0.1446\n",
      "Epoch 18/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8924 - acc: 0.1619 - val_loss: 3.9476 - val_acc: 0.1545\n",
      "Epoch 19/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8811 - acc: 0.1638 - val_loss: 3.9382 - val_acc: 0.1564\n",
      "Epoch 20/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8689 - acc: 0.1661 - val_loss: 3.9279 - val_acc: 0.1599\n",
      "Epoch 21/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8625 - acc: 0.1668 - val_loss: 4.0003 - val_acc: 0.1500\n",
      "Epoch 22/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8516 - acc: 0.1675 - val_loss: 4.0299 - val_acc: 0.1457\n",
      "Epoch 23/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8395 - acc: 0.1702 - val_loss: 3.8666 - val_acc: 0.1681\n",
      "Epoch 24/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8369 - acc: 0.1707 - val_loss: 3.9074 - val_acc: 0.1637\n",
      "Epoch 25/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8252 - acc: 0.1715 - val_loss: 4.0933 - val_acc: 0.1457\n",
      "Epoch 26/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8224 - acc: 0.1725 - val_loss: 4.0738 - val_acc: 0.1420\n",
      "Epoch 27/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8154 - acc: 0.1747 - val_loss: 3.8028 - val_acc: 0.1772\n",
      "Epoch 28/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8039 - acc: 0.1757 - val_loss: 4.0321 - val_acc: 0.1513\n",
      "Epoch 29/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8054 - acc: 0.1762 - val_loss: 4.0096 - val_acc: 0.1510\n",
      "Epoch 30/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7947 - acc: 0.1771 - val_loss: 3.9246 - val_acc: 0.1626\n",
      "Epoch 31/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7942 - acc: 0.1786 - val_loss: 4.0129 - val_acc: 0.1511\n",
      "Epoch 32/100\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 3.7924 - acc: 0.1782 - val_loss: 3.8847 - val_acc: 0.1673\n",
      "Epoch 33/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7831 - acc: 0.1791 - val_loss: 3.9709 - val_acc: 0.1626\n",
      "Epoch 34/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7784 - acc: 0.1799 - val_loss: 3.8866 - val_acc: 0.1677\n",
      "Epoch 35/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7759 - acc: 0.1823 - val_loss: 3.9920 - val_acc: 0.1593\n",
      "Epoch 36/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7766 - acc: 0.1806 - val_loss: 4.1213 - val_acc: 0.1431\n",
      "Epoch 37/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7722 - acc: 0.1798 - val_loss: 3.8062 - val_acc: 0.1727\n",
      "Epoch 38/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7652 - acc: 0.1831 - val_loss: 3.9379 - val_acc: 0.1572\n",
      "Epoch 39/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7606 - acc: 0.1821 - val_loss: 3.9975 - val_acc: 0.1596\n",
      "Epoch 40/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7560 - acc: 0.1825 - val_loss: 3.8917 - val_acc: 0.1708\n",
      "Epoch 41/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7522 - acc: 0.1839 - val_loss: 3.9538 - val_acc: 0.1620\n",
      "Epoch 42/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7522 - acc: 0.1845 - val_loss: 3.8968 - val_acc: 0.1706\n",
      "Epoch 43/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7480 - acc: 0.1858 - val_loss: 3.8617 - val_acc: 0.1715\n",
      "Epoch 44/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7479 - acc: 0.1845 - val_loss: 3.9688 - val_acc: 0.1595\n",
      "Epoch 45/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7479 - acc: 0.1845 - val_loss: 3.8251 - val_acc: 0.1776\n",
      "Epoch 46/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7434 - acc: 0.1862 - val_loss: 3.8918 - val_acc: 0.1723\n",
      "Epoch 47/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7402 - acc: 0.1872 - val_loss: 4.0433 - val_acc: 0.1557\n",
      "Epoch 48/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7381 - acc: 0.1862 - val_loss: 3.9057 - val_acc: 0.1766\n",
      "Epoch 49/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7375 - acc: 0.1862 - val_loss: 3.9328 - val_acc: 0.1658\n",
      "Epoch 50/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7376 - acc: 0.1870 - val_loss: 4.0422 - val_acc: 0.1523\n",
      "Epoch 51/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7350 - acc: 0.1875 - val_loss: 3.9205 - val_acc: 0.1641\n",
      "Epoch 52/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7339 - acc: 0.1878 - val_loss: 3.8939 - val_acc: 0.1672\n",
      "Epoch 53/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7281 - acc: 0.1895 - val_loss: 4.0192 - val_acc: 0.1596\n",
      "Epoch 54/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7233 - acc: 0.1893 - val_loss: 3.9198 - val_acc: 0.1693\n",
      "Epoch 55/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7256 - acc: 0.1874 - val_loss: 4.0742 - val_acc: 0.1531\n",
      "Epoch 56/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7251 - acc: 0.1902 - val_loss: 3.8804 - val_acc: 0.1728\n",
      "Epoch 57/100\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 3.7222 - acc: 0.1905 - val_loss: 4.0270 - val_acc: 0.1568\n",
      "Epoch 58/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7159 - acc: 0.1898 - val_loss: 3.9490 - val_acc: 0.1649\n",
      "Epoch 59/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7179 - acc: 0.1901 - val_loss: 4.0360 - val_acc: 0.1524\n",
      "Epoch 60/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7153 - acc: 0.1907 - val_loss: 3.9637 - val_acc: 0.1684\n",
      "Epoch 61/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7176 - acc: 0.1900 - val_loss: 3.8738 - val_acc: 0.1798\n",
      "Epoch 62/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7161 - acc: 0.1902 - val_loss: 3.8691 - val_acc: 0.1742\n",
      "Epoch 63/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7204 - acc: 0.1900 - val_loss: 4.0667 - val_acc: 0.1526\n",
      "Epoch 64/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7159 - acc: 0.1914 - val_loss: 4.1144 - val_acc: 0.1524\n",
      "Epoch 65/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7105 - acc: 0.1925 - val_loss: 3.8725 - val_acc: 0.1738\n",
      "Epoch 66/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7128 - acc: 0.1907 - val_loss: 4.1705 - val_acc: 0.1569\n",
      "Epoch 67/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7189 - acc: 0.1898 - val_loss: 4.0329 - val_acc: 0.1597\n",
      "Epoch 68/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7118 - acc: 0.1907 - val_loss: 3.8534 - val_acc: 0.1775\n",
      "Epoch 69/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7091 - acc: 0.1916 - val_loss: 3.8631 - val_acc: 0.1779\n",
      "Epoch 70/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7055 - acc: 0.1946 - val_loss: 3.8624 - val_acc: 0.1856\n",
      "Epoch 71/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7107 - acc: 0.1921 - val_loss: 3.9683 - val_acc: 0.1618\n",
      "Epoch 72/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7104 - acc: 0.1933 - val_loss: 3.8502 - val_acc: 0.1864\n",
      "Epoch 73/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7042 - acc: 0.1936 - val_loss: 3.8229 - val_acc: 0.1819\n",
      "Epoch 74/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7108 - acc: 0.1924 - val_loss: 3.8543 - val_acc: 0.1724\n",
      "Epoch 75/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7112 - acc: 0.1929 - val_loss: 3.9549 - val_acc: 0.1662\n",
      "Epoch 76/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7030 - acc: 0.1928 - val_loss: 3.9490 - val_acc: 0.1732\n",
      "Epoch 77/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7114 - acc: 0.1927 - val_loss: 3.7943 - val_acc: 0.1828\n",
      "Epoch 78/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7042 - acc: 0.1932 - val_loss: 3.9577 - val_acc: 0.1636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7080 - acc: 0.1926 - val_loss: 3.9969 - val_acc: 0.1618\n",
      "Epoch 80/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7064 - acc: 0.1939 - val_loss: 3.9885 - val_acc: 0.1655\n",
      "Epoch 81/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7044 - acc: 0.1917 - val_loss: 3.9069 - val_acc: 0.1779\n",
      "Epoch 82/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7050 - acc: 0.1929 - val_loss: 3.8028 - val_acc: 0.1826\n",
      "Epoch 83/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6972 - acc: 0.1929 - val_loss: 3.9967 - val_acc: 0.1696\n",
      "Epoch 84/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7009 - acc: 0.1936 - val_loss: 3.8741 - val_acc: 0.1747\n",
      "Epoch 85/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7062 - acc: 0.1946 - val_loss: 3.8964 - val_acc: 0.1763\n",
      "Epoch 86/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7021 - acc: 0.1943 - val_loss: 4.0409 - val_acc: 0.1685\n",
      "Epoch 87/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6995 - acc: 0.1941 - val_loss: 3.8420 - val_acc: 0.1844\n",
      "Epoch 88/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6968 - acc: 0.1949 - val_loss: 3.9136 - val_acc: 0.1747\n",
      "Epoch 89/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7029 - acc: 0.1951 - val_loss: 3.9067 - val_acc: 0.1718\n",
      "Epoch 90/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6987 - acc: 0.1944 - val_loss: 3.8877 - val_acc: 0.1762\n",
      "Epoch 91/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6992 - acc: 0.1947 - val_loss: 4.0369 - val_acc: 0.1665\n",
      "Epoch 92/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7039 - acc: 0.1930 - val_loss: 4.0264 - val_acc: 0.1649\n",
      "Epoch 93/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7025 - acc: 0.1945 - val_loss: 3.9214 - val_acc: 0.1722\n",
      "Epoch 94/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7006 - acc: 0.1933 - val_loss: 4.0065 - val_acc: 0.1685\n",
      "Epoch 95/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7018 - acc: 0.1931 - val_loss: 3.8697 - val_acc: 0.1767\n",
      "Epoch 96/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6989 - acc: 0.1942 - val_loss: 4.0194 - val_acc: 0.1660\n",
      "Epoch 97/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6990 - acc: 0.1950 - val_loss: 3.9220 - val_acc: 0.1786\n",
      "Epoch 98/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6999 - acc: 0.1932 - val_loss: 4.0216 - val_acc: 0.1637\n",
      "Epoch 99/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6951 - acc: 0.1958 - val_loss: 3.8394 - val_acc: 0.1862\n",
      "Epoch 100/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7002 - acc: 0.1941 - val_loss: 3.9430 - val_acc: 0.1747\n",
      "10000/10000 [==============================] - 1s 125us/step\n",
      "Test loss: 3.9429873306274414\n",
      "Test accuracy: 0.1747\n",
      "Runtime: 2517.3177618980408\n"
     ]
    }
   ],
   "source": [
    "opts = [('SGD', SGD()), ('Adamax', Adamax())]\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 200\n",
    "epochs = 100\n",
    "\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "\n",
    "\n",
    "for name, opt in opts:\n",
    "    print('Training ' + name + ' optimizer')\n",
    "    logs = \"logs/optimizer/100/\"+name\n",
    "    tensorboard = TensorBoard(log_dir=logs)\n",
    "    \n",
    "    model_name = name + '_100_keras_imagenet200_base.h5'\n",
    "    \n",
    "    model_base = Sequential()\n",
    "    model_base.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=train_images.shape[1:]))\n",
    "    model_base.add(Activation('relu'))\n",
    "    model_base.add(Conv2D(32, (3, 3)))\n",
    "    model_base.add(Activation('relu'))\n",
    "    model_base.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model_base.add(Dropout(0.25))\n",
    "\n",
    "    model_base.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model_base.add(Activation('relu'))\n",
    "    model_base.add(Conv2D(64, (3, 3)))\n",
    "    model_base.add(Activation('relu'))\n",
    "    model_base.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model_base.add(Dropout(0.25))\n",
    "\n",
    "    model_base.add(Flatten())\n",
    "    model_base.add(Dense(512))\n",
    "    model_base.add(Activation('relu'))\n",
    "    model_base.add(Dropout(0.5))\n",
    "    model_base.add(Dense(num_classes))\n",
    "    model_base.add(Activation('softmax'))\n",
    "    \n",
    "    # Let's train the model using RMSprop\n",
    "    model_base.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    start = time()\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=90,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(train_images)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model_base.fit_generator(datagen.flow(train_images, y_train, batch_size=batch_size),\n",
    "                                     epochs=epochs,\n",
    "                                     validation_data=(val_images, y_test),\n",
    "                                     workers=4,\n",
    "                                     steps_per_epoch=len(train_images)/batch_size, \n",
    "                                     callbacks=[tensorboard])\n",
    "    \n",
    "    # Save model and weights\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    model_path = os.path.join(save_dir, model_name)\n",
    "    model_base.save(model_path)\n",
    "\n",
    "    # Score trained model.\n",
    "    scores = model_base.evaluate(val_images, y_test, verbose=1)\n",
    "\n",
    "    end = time()\n",
    "    print('Test loss:', scores[0])\n",
    "    print('Test accuracy:', scores[1])\n",
    "    print('Runtime:', str(end-start))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: CIFAR 100 Starting Code\n",
    "https://andrewkruger.github.io/projects/2017-08-05-keras-convolutional-neural-network-for-cifar-100#the-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1563/1562 [==============================] - 37s 23ms/step - loss: 4.8993 - acc: 0.0435 - val_loss: 4.4843 - val_acc: 0.0967\n",
      "Epoch 2/200\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 4.5560 - acc: 0.0845 - val_loss: 4.1693 - val_acc: 0.1394\n",
      "Epoch 3/200\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 4.4113 - acc: 0.1047 - val_loss: 4.0295 - val_acc: 0.1616\n",
      "Epoch 4/200\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 4.3023 - acc: 0.1209 - val_loss: 3.9087 - val_acc: 0.1765\n",
      "Epoch 5/200\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 4.2180 - acc: 0.1355 - val_loss: 3.8326 - val_acc: 0.1934\n",
      "Epoch 6/200\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 4.1376 - acc: 0.1467 - val_loss: 3.6963 - val_acc: 0.2128\n",
      "Epoch 7/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 4.0630 - acc: 0.1575 - val_loss: 3.7248 - val_acc: 0.2086\n",
      "Epoch 8/200\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 3.9884 - acc: 0.1697 - val_loss: 3.5665 - val_acc: 0.2326\n",
      "Epoch 9/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 3.9194 - acc: 0.1807 - val_loss: 3.5528 - val_acc: 0.2344\n",
      "Epoch 10/200\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 3.8554 - acc: 0.1916 - val_loss: 3.4688 - val_acc: 0.2528\n",
      "Epoch 11/200\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 3.7962 - acc: 0.2005 - val_loss: 3.4869 - val_acc: 0.2443\n",
      "Epoch 12/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 3.7338 - acc: 0.2112 - val_loss: 3.3742 - val_acc: 0.2629\n",
      "Epoch 13/200\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 3.6773 - acc: 0.2193 - val_loss: 3.3692 - val_acc: 0.2665\n",
      "Epoch 14/200\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 3.6210 - acc: 0.2305 - val_loss: 3.3832 - val_acc: 0.2642\n",
      "Epoch 15/200\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 3.5635 - acc: 0.2403 - val_loss: 3.2813 - val_acc: 0.2801\n",
      "Epoch 16/200\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 3.5113 - acc: 0.2495 - val_loss: 3.1987 - val_acc: 0.3019\n",
      "Epoch 17/200\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 3.4692 - acc: 0.2553 - val_loss: 3.1840 - val_acc: 0.2997\n",
      "Epoch 18/200\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 3.4238 - acc: 0.2641 - val_loss: 3.1785 - val_acc: 0.3054\n",
      "Epoch 19/200\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 3.3826 - acc: 0.2705 - val_loss: 3.0978 - val_acc: 0.3163\n",
      "Epoch 20/200\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 3.3336 - acc: 0.2794 - val_loss: 3.1142 - val_acc: 0.3165\n",
      "Epoch 21/200\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 3.3005 - acc: 0.2850 - val_loss: 3.0817 - val_acc: 0.3222\n",
      "Epoch 22/200\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 3.2708 - acc: 0.2896 - val_loss: 3.0994 - val_acc: 0.3189\n",
      "Epoch 23/200\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 3.2454 - acc: 0.2935 - val_loss: 3.0358 - val_acc: 0.3289\n",
      "Epoch 24/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 3.2162 - acc: 0.2994 - val_loss: 3.0077 - val_acc: 0.3302\n",
      "Epoch 25/200\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 3.1868 - acc: 0.3064 - val_loss: 3.0404 - val_acc: 0.3301\n",
      "Epoch 26/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 3.1576 - acc: 0.3118 - val_loss: 3.0314 - val_acc: 0.3328\n",
      "Epoch 27/200\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 3.1480 - acc: 0.3126 - val_loss: 3.0735 - val_acc: 0.3219\n",
      "Epoch 28/200\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 3.1358 - acc: 0.3179 - val_loss: 3.0167 - val_acc: 0.3358\n",
      "Epoch 29/200\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 3.1097 - acc: 0.3223 - val_loss: 3.0001 - val_acc: 0.3377\n",
      "Epoch 30/200\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 3.0882 - acc: 0.3269 - val_loss: 3.0353 - val_acc: 0.3308\n",
      "Epoch 31/200\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 3.0800 - acc: 0.3282 - val_loss: 2.9790 - val_acc: 0.3408\n",
      "Epoch 32/200\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 3.0598 - acc: 0.3320 - val_loss: 2.9907 - val_acc: 0.3415\n",
      "Epoch 33/200\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 3.0530 - acc: 0.3338 - val_loss: 3.0079 - val_acc: 0.3419\n",
      "Epoch 34/200\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 3.0387 - acc: 0.3373 - val_loss: 2.9635 - val_acc: 0.3500\n",
      "Epoch 35/200\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 3.0165 - acc: 0.3400 - val_loss: 3.0270 - val_acc: 0.3334\n",
      "Epoch 36/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 3.0012 - acc: 0.3450 - val_loss: 3.0350 - val_acc: 0.3380\n",
      "Epoch 37/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 2.9899 - acc: 0.3465 - val_loss: 2.9951 - val_acc: 0.3440\n",
      "Epoch 38/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 2.9722 - acc: 0.3484 - val_loss: 2.9374 - val_acc: 0.3548\n",
      "Epoch 39/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.9608 - acc: 0.3525 - val_loss: 2.9105 - val_acc: 0.3605\n",
      "Epoch 40/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 2.9512 - acc: 0.3545 - val_loss: 2.9878 - val_acc: 0.3533\n",
      "Epoch 41/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.9369 - acc: 0.3585 - val_loss: 2.9070 - val_acc: 0.3597\n",
      "Epoch 42/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 2.9199 - acc: 0.3622 - val_loss: 2.8952 - val_acc: 0.3668\n",
      "Epoch 43/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 2.8975 - acc: 0.3656 - val_loss: 3.0372 - val_acc: 0.3438\n",
      "Epoch 44/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.8893 - acc: 0.3674 - val_loss: 3.0559 - val_acc: 0.3443\n",
      "Epoch 45/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 2.8759 - acc: 0.3692 - val_loss: 2.9639 - val_acc: 0.3567\n",
      "Epoch 46/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 2.8640 - acc: 0.3728 - val_loss: 3.0046 - val_acc: 0.3547\n",
      "Epoch 47/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 2.8545 - acc: 0.3763 - val_loss: 3.0043 - val_acc: 0.3493\n",
      "Epoch 48/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.8438 - acc: 0.3763 - val_loss: 2.8923 - val_acc: 0.3715\n",
      "Epoch 49/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 2.8304 - acc: 0.3790 - val_loss: 2.9437 - val_acc: 0.3625\n",
      "Epoch 50/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.8129 - acc: 0.3837 - val_loss: 2.9149 - val_acc: 0.3658\n",
      "Epoch 51/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 2.8059 - acc: 0.3848 - val_loss: 2.9522 - val_acc: 0.3644\n",
      "Epoch 52/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.7954 - acc: 0.3898 - val_loss: 3.0216 - val_acc: 0.3515\n",
      "Epoch 53/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 2.7880 - acc: 0.3877 - val_loss: 2.9950 - val_acc: 0.3572\n",
      "Epoch 54/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 2.7791 - acc: 0.3898 - val_loss: 2.9978 - val_acc: 0.3580\n",
      "Epoch 55/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.7738 - acc: 0.3917 - val_loss: 2.9709 - val_acc: 0.3578\n",
      "Epoch 56/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 2.7673 - acc: 0.3929 - val_loss: 3.0368 - val_acc: 0.3540\n",
      "Epoch 57/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 2.7659 - acc: 0.3951 - val_loss: 2.9760 - val_acc: 0.3641\n",
      "Epoch 58/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.7573 - acc: 0.3976 - val_loss: 2.9776 - val_acc: 0.3576\n",
      "Epoch 59/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 2.7560 - acc: 0.3981 - val_loss: 3.0736 - val_acc: 0.3450\n",
      "Epoch 60/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 2.7576 - acc: 0.3988 - val_loss: 2.9390 - val_acc: 0.3716\n",
      "Epoch 61/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.7528 - acc: 0.3991 - val_loss: 3.0033 - val_acc: 0.3593\n",
      "Epoch 62/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.7647 - acc: 0.3992 - val_loss: 2.9664 - val_acc: 0.3631\n",
      "Epoch 63/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.7696 - acc: 0.3977 - val_loss: 3.0567 - val_acc: 0.3555\n",
      "Epoch 64/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.7736 - acc: 0.3988 - val_loss: 3.0366 - val_acc: 0.3516\n",
      "Epoch 65/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 2.7925 - acc: 0.3971 - val_loss: 3.0871 - val_acc: 0.3480\n",
      "Epoch 66/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 2.7961 - acc: 0.3955 - val_loss: 3.0598 - val_acc: 0.3532\n",
      "Epoch 67/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 2.8138 - acc: 0.3935 - val_loss: 2.9920 - val_acc: 0.3600\n",
      "Epoch 68/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.8248 - acc: 0.3935 - val_loss: 2.9283 - val_acc: 0.3707\n",
      "Epoch 69/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.8473 - acc: 0.3882 - val_loss: 3.1230 - val_acc: 0.3392\n",
      "Epoch 70/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.8550 - acc: 0.3877 - val_loss: 2.9637 - val_acc: 0.3656\n",
      "Epoch 71/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.8858 - acc: 0.3838 - val_loss: 2.9983 - val_acc: 0.3620\n",
      "Epoch 72/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.8936 - acc: 0.3817 - val_loss: 2.9701 - val_acc: 0.3629\n",
      "Epoch 73/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 2.9322 - acc: 0.3770 - val_loss: 3.0293 - val_acc: 0.3511\n",
      "Epoch 74/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 2.9487 - acc: 0.3728 - val_loss: 3.0059 - val_acc: 0.3583\n",
      "Epoch 75/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.9736 - acc: 0.3693 - val_loss: 3.0276 - val_acc: 0.3505\n",
      "Epoch 76/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.0096 - acc: 0.3627 - val_loss: 3.0515 - val_acc: 0.3473\n",
      "Epoch 77/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 3.0316 - acc: 0.3566 - val_loss: 3.0713 - val_acc: 0.3386\n",
      "Epoch 78/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.0733 - acc: 0.3512 - val_loss: 3.0653 - val_acc: 0.3499\n",
      "Epoch 79/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 3.0900 - acc: 0.3495 - val_loss: 3.0770 - val_acc: 0.3393\n",
      "Epoch 80/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 3.1401 - acc: 0.3408 - val_loss: 3.1108 - val_acc: 0.3363\n",
      "Epoch 81/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.1761 - acc: 0.3316 - val_loss: 3.1482 - val_acc: 0.3259\n",
      "Epoch 82/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.2076 - acc: 0.3277 - val_loss: 3.2045 - val_acc: 0.3277\n",
      "Epoch 83/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.2358 - acc: 0.3228 - val_loss: 3.1899 - val_acc: 0.3151\n",
      "Epoch 84/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.2544 - acc: 0.3191 - val_loss: 3.2017 - val_acc: 0.3103\n",
      "Epoch 85/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.2811 - acc: 0.3172 - val_loss: 3.2607 - val_acc: 0.3098\n",
      "Epoch 86/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.2827 - acc: 0.3145 - val_loss: 3.2352 - val_acc: 0.3190\n",
      "Epoch 87/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 3.2992 - acc: 0.3110 - val_loss: 3.3162 - val_acc: 0.3001\n",
      "Epoch 88/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.2964 - acc: 0.3131 - val_loss: 3.2354 - val_acc: 0.3141\n",
      "Epoch 89/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.3168 - acc: 0.3092 - val_loss: 3.3723 - val_acc: 0.2880\n",
      "Epoch 90/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 3.3372 - acc: 0.3078 - val_loss: 3.2484 - val_acc: 0.3097\n",
      "Epoch 91/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 3.3290 - acc: 0.3070 - val_loss: 3.1630 - val_acc: 0.3260\n",
      "Epoch 92/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 3.3422 - acc: 0.3031 - val_loss: 3.2593 - val_acc: 0.3136\n",
      "Epoch 93/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.3332 - acc: 0.3050 - val_loss: 3.2699 - val_acc: 0.3033\n",
      "Epoch 94/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.3587 - acc: 0.3036 - val_loss: 3.2130 - val_acc: 0.3203\n",
      "Epoch 95/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.3618 - acc: 0.3033 - val_loss: 3.2911 - val_acc: 0.2991\n",
      "Epoch 96/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.3883 - acc: 0.2991 - val_loss: 3.2519 - val_acc: 0.3081\n",
      "Epoch 97/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.4074 - acc: 0.2965 - val_loss: 3.2568 - val_acc: 0.3171\n",
      "Epoch 98/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.4432 - acc: 0.2927 - val_loss: 3.1682 - val_acc: 0.3221\n",
      "Epoch 99/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.4431 - acc: 0.2931 - val_loss: 3.4871 - val_acc: 0.2703\n",
      "Epoch 100/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.4654 - acc: 0.2885 - val_loss: 3.2561 - val_acc: 0.3169\n",
      "Epoch 101/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.4865 - acc: 0.2844 - val_loss: 3.2873 - val_acc: 0.3168\n",
      "Epoch 102/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.5280 - acc: 0.2784 - val_loss: 3.3587 - val_acc: 0.3069\n",
      "Epoch 103/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 3.5324 - acc: 0.2793 - val_loss: 3.2995 - val_acc: 0.3046\n",
      "Epoch 104/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.5373 - acc: 0.2794 - val_loss: 3.3116 - val_acc: 0.3043\n",
      "Epoch 105/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 3.5769 - acc: 0.2746 - val_loss: 3.2517 - val_acc: 0.3150\n",
      "Epoch 106/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.5874 - acc: 0.2702 - val_loss: 3.2958 - val_acc: 0.3083\n",
      "Epoch 107/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.6106 - acc: 0.2672 - val_loss: 3.4352 - val_acc: 0.2790\n",
      "Epoch 108/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.6261 - acc: 0.2634 - val_loss: 3.2668 - val_acc: 0.3092\n",
      "Epoch 109/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.6576 - acc: 0.2603 - val_loss: 3.3657 - val_acc: 0.2963\n",
      "Epoch 110/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 3.6477 - acc: 0.2636 - val_loss: 3.3810 - val_acc: 0.2946\n",
      "Epoch 111/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.6430 - acc: 0.2634 - val_loss: 3.2878 - val_acc: 0.3104\n",
      "Epoch 112/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 3.6653 - acc: 0.2616 - val_loss: 3.3460 - val_acc: 0.3039\n",
      "Epoch 113/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.6828 - acc: 0.2564 - val_loss: 3.6325 - val_acc: 0.2438\n",
      "Epoch 114/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 3.6889 - acc: 0.2578 - val_loss: 3.3321 - val_acc: 0.3018\n",
      "Epoch 115/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.7082 - acc: 0.2567 - val_loss: 3.4115 - val_acc: 0.2946\n",
      "Epoch 116/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.7409 - acc: 0.2470 - val_loss: 3.3786 - val_acc: 0.2958\n",
      "Epoch 117/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.7532 - acc: 0.2468 - val_loss: 3.5013 - val_acc: 0.2818\n",
      "Epoch 118/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.7402 - acc: 0.2497 - val_loss: 3.5057 - val_acc: 0.2660\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1562 [==============================] - 34s 21ms/step - loss: 3.7792 - acc: 0.2462 - val_loss: 3.4144 - val_acc: 0.2934\n",
      "Epoch 120/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.7724 - acc: 0.2445 - val_loss: 3.5115 - val_acc: 0.2794\n",
      "Epoch 121/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 3.7684 - acc: 0.2453 - val_loss: 3.3796 - val_acc: 0.3017\n",
      "Epoch 122/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 3.7820 - acc: 0.2445 - val_loss: 3.3505 - val_acc: 0.2980\n",
      "Epoch 123/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.7716 - acc: 0.2445 - val_loss: 3.4555 - val_acc: 0.2848\n",
      "Epoch 124/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.7699 - acc: 0.2448 - val_loss: 3.4234 - val_acc: 0.2915\n",
      "Epoch 125/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.7854 - acc: 0.2409 - val_loss: 3.5029 - val_acc: 0.2809\n",
      "Epoch 126/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.7931 - acc: 0.2414 - val_loss: 3.6406 - val_acc: 0.2624\n",
      "Epoch 127/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.8062 - acc: 0.2385 - val_loss: 3.3852 - val_acc: 0.2876\n",
      "Epoch 128/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.8069 - acc: 0.2369 - val_loss: 3.8612 - val_acc: 0.2310\n",
      "Epoch 129/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.8162 - acc: 0.2370 - val_loss: 3.4235 - val_acc: 0.2901\n",
      "Epoch 130/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.8044 - acc: 0.2399 - val_loss: 3.4882 - val_acc: 0.2810\n",
      "Epoch 131/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.8082 - acc: 0.2373 - val_loss: 3.5136 - val_acc: 0.2779\n",
      "Epoch 132/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.8050 - acc: 0.2396 - val_loss: 3.4221 - val_acc: 0.2928\n",
      "Epoch 133/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 3.7902 - acc: 0.2427 - val_loss: 3.3640 - val_acc: 0.2990\n",
      "Epoch 134/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.7883 - acc: 0.2410 - val_loss: 3.4694 - val_acc: 0.2835\n",
      "Epoch 135/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 3.8091 - acc: 0.2409 - val_loss: 3.4975 - val_acc: 0.2854\n",
      "Epoch 136/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.7924 - acc: 0.2419 - val_loss: 3.4576 - val_acc: 0.2806\n",
      "Epoch 137/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.7896 - acc: 0.2434 - val_loss: 3.4654 - val_acc: 0.2845\n",
      "Epoch 138/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.7998 - acc: 0.2407 - val_loss: 3.4557 - val_acc: 0.2853\n",
      "Epoch 139/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.8229 - acc: 0.2384 - val_loss: 3.4945 - val_acc: 0.2803\n",
      "Epoch 140/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.8342 - acc: 0.2366 - val_loss: 3.6056 - val_acc: 0.2727\n",
      "Epoch 141/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.8411 - acc: 0.2360 - val_loss: 3.4416 - val_acc: 0.2938\n",
      "Epoch 142/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.8334 - acc: 0.2370 - val_loss: 3.4603 - val_acc: 0.2851\n",
      "Epoch 143/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.8512 - acc: 0.2354 - val_loss: 3.5344 - val_acc: 0.2791\n",
      "Epoch 144/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.8558 - acc: 0.2321 - val_loss: 3.5143 - val_acc: 0.2800\n",
      "Epoch 145/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.8402 - acc: 0.2357 - val_loss: 3.4104 - val_acc: 0.2902\n",
      "Epoch 146/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.8317 - acc: 0.2380 - val_loss: 3.3986 - val_acc: 0.3027\n",
      "Epoch 147/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.8515 - acc: 0.2333 - val_loss: 3.5382 - val_acc: 0.2730\n",
      "Epoch 148/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.8410 - acc: 0.2353 - val_loss: 3.3887 - val_acc: 0.3022\n",
      "Epoch 149/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.8697 - acc: 0.2342 - val_loss: 3.4426 - val_acc: 0.2901\n",
      "Epoch 150/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.8672 - acc: 0.2311 - val_loss: 3.4184 - val_acc: 0.2915\n",
      "Epoch 151/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.8539 - acc: 0.2344 - val_loss: 3.4129 - val_acc: 0.2933\n",
      "Epoch 152/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.8587 - acc: 0.2335 - val_loss: 3.5411 - val_acc: 0.2857\n",
      "Epoch 153/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.8724 - acc: 0.2308 - val_loss: 3.6636 - val_acc: 0.2635\n",
      "Epoch 154/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.8819 - acc: 0.2327 - val_loss: 3.4876 - val_acc: 0.2888\n",
      "Epoch 155/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.8984 - acc: 0.2247 - val_loss: 3.4932 - val_acc: 0.2823\n",
      "Epoch 156/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.8916 - acc: 0.2288 - val_loss: 3.4895 - val_acc: 0.2806\n",
      "Epoch 157/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.9019 - acc: 0.2274 - val_loss: 3.4716 - val_acc: 0.2839\n",
      "Epoch 158/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.8952 - acc: 0.2263 - val_loss: 3.6672 - val_acc: 0.2484\n",
      "Epoch 159/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.9048 - acc: 0.2267 - val_loss: 3.4639 - val_acc: 0.2910\n",
      "Epoch 160/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.9198 - acc: 0.2266 - val_loss: 3.5923 - val_acc: 0.2684\n",
      "Epoch 161/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.9632 - acc: 0.2171 - val_loss: 3.5288 - val_acc: 0.2726\n",
      "Epoch 162/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.9383 - acc: 0.2236 - val_loss: 3.4586 - val_acc: 0.2866\n",
      "Epoch 163/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.9448 - acc: 0.2239 - val_loss: 3.5872 - val_acc: 0.2694\n",
      "Epoch 164/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.9363 - acc: 0.2215 - val_loss: 3.5148 - val_acc: 0.2865\n",
      "Epoch 165/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.9554 - acc: 0.2176 - val_loss: 3.5483 - val_acc: 0.2785\n",
      "Epoch 166/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.9457 - acc: 0.2199 - val_loss: 3.5877 - val_acc: 0.2641\n",
      "Epoch 167/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.9448 - acc: 0.2192 - val_loss: 3.5962 - val_acc: 0.2571\n",
      "Epoch 168/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 3.9637 - acc: 0.2207 - val_loss: 3.4965 - val_acc: 0.2970\n",
      "Epoch 169/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.9567 - acc: 0.2179 - val_loss: 3.5305 - val_acc: 0.2808\n",
      "Epoch 170/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.9781 - acc: 0.2162 - val_loss: 3.9689 - val_acc: 0.2165\n",
      "Epoch 171/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 3.9743 - acc: 0.2191 - val_loss: 3.7423 - val_acc: 0.2328\n",
      "Epoch 172/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.9704 - acc: 0.2183 - val_loss: 3.4769 - val_acc: 0.2897\n",
      "Epoch 173/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.9930 - acc: 0.2135 - val_loss: 3.5356 - val_acc: 0.2748\n",
      "Epoch 174/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.9971 - acc: 0.2135 - val_loss: 3.5625 - val_acc: 0.2590\n",
      "Epoch 175/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 4.0094 - acc: 0.2144 - val_loss: 3.5388 - val_acc: 0.2826\n",
      "Epoch 176/200\n",
      "1563/1562 [==============================] - 34s 21ms/step - loss: 4.0256 - acc: 0.2109 - val_loss: 3.4881 - val_acc: 0.2823\n",
      "Epoch 177/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0389 - acc: 0.2103 - val_loss: 3.5353 - val_acc: 0.2631\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0219 - acc: 0.2105 - val_loss: 3.5772 - val_acc: 0.2700\n",
      "Epoch 179/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0367 - acc: 0.2084 - val_loss: 3.5627 - val_acc: 0.2705\n",
      "Epoch 180/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0551 - acc: 0.2096 - val_loss: 3.5709 - val_acc: 0.2755\n",
      "Epoch 181/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.1054 - acc: 0.2045 - val_loss: 3.7939 - val_acc: 0.2733\n",
      "Epoch 182/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0745 - acc: 0.2052 - val_loss: 3.5694 - val_acc: 0.2693\n",
      "Epoch 183/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0852 - acc: 0.2032 - val_loss: 3.5907 - val_acc: 0.2688\n",
      "Epoch 184/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0839 - acc: 0.2036 - val_loss: 3.5897 - val_acc: 0.2704\n",
      "Epoch 185/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.1041 - acc: 0.1988 - val_loss: 3.5900 - val_acc: 0.2640\n",
      "Epoch 186/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.1112 - acc: 0.1993 - val_loss: 3.6537 - val_acc: 0.2624\n",
      "Epoch 187/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0601 - acc: 0.2061 - val_loss: 3.5798 - val_acc: 0.2720\n",
      "Epoch 188/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0687 - acc: 0.2075 - val_loss: 3.6519 - val_acc: 0.2645\n",
      "Epoch 189/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0577 - acc: 0.2081 - val_loss: 3.4755 - val_acc: 0.2780\n",
      "Epoch 190/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0833 - acc: 0.2018 - val_loss: 3.7194 - val_acc: 0.2501\n",
      "Epoch 191/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0771 - acc: 0.1990 - val_loss: 3.6485 - val_acc: 0.2514\n",
      "Epoch 192/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0796 - acc: 0.2005 - val_loss: 3.5808 - val_acc: 0.2653\n",
      "Epoch 193/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.1068 - acc: 0.1979 - val_loss: 3.5339 - val_acc: 0.2769\n",
      "Epoch 194/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.1094 - acc: 0.1977 - val_loss: 3.6463 - val_acc: 0.2591\n",
      "Epoch 195/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.1094 - acc: 0.1961 - val_loss: 3.6353 - val_acc: 0.2639\n",
      "Epoch 196/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.1223 - acc: 0.1964 - val_loss: 3.5916 - val_acc: 0.2688\n",
      "Epoch 197/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.1359 - acc: 0.1980 - val_loss: 3.5715 - val_acc: 0.2739\n",
      "Epoch 198/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.1252 - acc: 0.1943 - val_loss: 3.8185 - val_acc: 0.2494\n",
      "Epoch 199/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.1386 - acc: 0.1921 - val_loss: 3.5886 - val_acc: 0.2608\n",
      "Epoch 200/200\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.1565 - acc: 0.1924 - val_loss: 3.8348 - val_acc: 0.2278\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_base' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-535c2c4fd953>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m \u001b[0mmodel_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;31m# Score trained model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_base' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "num_classes = 200\n",
    "\n",
    "num_predictions = 20\n",
    "batch_size = 64\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "logs = \"logs/1\"\n",
    "tensorboard = TensorBoard(log_dir=logs)\n",
    "\n",
    "model_name = 'keras_imagenet200_100base.h5'\n",
    "\n",
    "#start = time()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', input_shape=train_images.shape[1:]))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(512, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False)  # randomly flip images\n",
    "\n",
    "# Compute quantities required for feature-wise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(train_images)\n",
    "\n",
    "model.fit_generator(datagen.flow(train_images, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(train_images)/batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(val_images, y_test),\n",
    "                    callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 207us/step\n",
      "Test loss: 3.834818507385254\n",
      "Test accuracy: 0.2278\n"
     ]
    }
   ],
   "source": [
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(val_images, y_test, verbose=1)\n",
    "\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "#print('Runtime:', str(end-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SGDoptimizer\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.1734 - acc: 0.0143 - val_loss: 4.9637 - val_acc: 0.0378\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 4.9299 - acc: 0.0366 - val_loss: 4.7335 - val_acc: 0.0667\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 4.7553 - acc: 0.0574 - val_loss: 4.5957 - val_acc: 0.0786\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 4.6016 - acc: 0.0736 - val_loss: 4.3902 - val_acc: 0.1015\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 4.4454 - acc: 0.0919 - val_loss: 4.1839 - val_acc: 0.1312\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 4.3163 - acc: 0.1087 - val_loss: 4.1917 - val_acc: 0.1282\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 4.2085 - acc: 0.1221 - val_loss: 4.0011 - val_acc: 0.1534\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 4.1180 - acc: 0.1333 - val_loss: 3.9453 - val_acc: 0.1555\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 4.0396 - acc: 0.1442 - val_loss: 3.9148 - val_acc: 0.1693\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.9737 - acc: 0.1554 - val_loss: 3.7752 - val_acc: 0.1846\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.9112 - acc: 0.1633 - val_loss: 3.7740 - val_acc: 0.1890\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.8509 - acc: 0.1714 - val_loss: 3.7557 - val_acc: 0.1879\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.7995 - acc: 0.1814 - val_loss: 3.6331 - val_acc: 0.2041\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.7460 - acc: 0.1906 - val_loss: 3.5265 - val_acc: 0.2251\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.7018 - acc: 0.1954 - val_loss: 3.4928 - val_acc: 0.2308\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.6573 - acc: 0.2031 - val_loss: 3.4223 - val_acc: 0.2421\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.6133 - acc: 0.2088 - val_loss: 3.4383 - val_acc: 0.2348\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.5787 - acc: 0.2165 - val_loss: 3.4249 - val_acc: 0.2379\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.5283 - acc: 0.2239 - val_loss: 3.3013 - val_acc: 0.2605\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.4983 - acc: 0.2295 - val_loss: 3.3942 - val_acc: 0.2517\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.4586 - acc: 0.2346 - val_loss: 3.2715 - val_acc: 0.2682\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.4283 - acc: 0.2398 - val_loss: 3.2714 - val_acc: 0.2609\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.3912 - acc: 0.2458 - val_loss: 3.2162 - val_acc: 0.2781\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.3605 - acc: 0.2508 - val_loss: 3.1493 - val_acc: 0.2966\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.3218 - acc: 0.2577 - val_loss: 3.1259 - val_acc: 0.2962\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.2887 - acc: 0.2642 - val_loss: 3.1250 - val_acc: 0.2958\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.2523 - acc: 0.2704 - val_loss: 3.0452 - val_acc: 0.3154\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.2235 - acc: 0.2765 - val_loss: 3.1124 - val_acc: 0.2984\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.1854 - acc: 0.2814 - val_loss: 3.0729 - val_acc: 0.3092\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.1554 - acc: 0.2876 - val_loss: 3.0176 - val_acc: 0.3165\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.1289 - acc: 0.2911 - val_loss: 3.1348 - val_acc: 0.3041\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.0991 - acc: 0.2960 - val_loss: 2.9569 - val_acc: 0.3313\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.0660 - acc: 0.3015 - val_loss: 2.9634 - val_acc: 0.3287\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.0380 - acc: 0.3069 - val_loss: 2.9919 - val_acc: 0.3223\n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.0010 - acc: 0.3135 - val_loss: 2.9694 - val_acc: 0.3256\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 2.9690 - acc: 0.3202 - val_loss: 2.9704 - val_acc: 0.3306\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 2.9534 - acc: 0.3238 - val_loss: 2.8950 - val_acc: 0.3398\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 2.9160 - acc: 0.3289 - val_loss: 2.8321 - val_acc: 0.3485\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 2.8909 - acc: 0.3342 - val_loss: 2.8894 - val_acc: 0.3393\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 2.8578 - acc: 0.3390 - val_loss: 2.8742 - val_acc: 0.3469\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 2.8322 - acc: 0.3435 - val_loss: 2.7998 - val_acc: 0.3594\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 2.8136 - acc: 0.3456 - val_loss: 2.7955 - val_acc: 0.3546\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 2.7806 - acc: 0.3529 - val_loss: 2.7680 - val_acc: 0.3694\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 2.7561 - acc: 0.3557 - val_loss: 2.7555 - val_acc: 0.3695\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 2.7260 - acc: 0.3619 - val_loss: 2.8035 - val_acc: 0.3590\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 2.7042 - acc: 0.3662 - val_loss: 2.7650 - val_acc: 0.3670\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 2.6824 - acc: 0.3720 - val_loss: 2.7556 - val_acc: 0.3687\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 2.6532 - acc: 0.3751 - val_loss: 2.7383 - val_acc: 0.3743\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 2.6289 - acc: 0.3813 - val_loss: 2.6910 - val_acc: 0.3827\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 2.6056 - acc: 0.3839 - val_loss: 2.6995 - val_acc: 0.3789\n",
      "10000/10000 [==============================] - 2s 214us/step\n",
      "Test loss: 2.6994822227478026\n",
      "Test accuracy: 0.3789\n",
      "Runtime: 1591.073058128357\n",
      "\n",
      "\n",
      "\n",
      "Training RMSpropoptimizer\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.8899 - acc: 0.0436 - val_loss: 4.4244 - val_acc: 0.1021\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.5408 - acc: 0.0853 - val_loss: 4.2048 - val_acc: 0.1371\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.4024 - acc: 0.1065 - val_loss: 4.0625 - val_acc: 0.1499\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.2941 - acc: 0.1228 - val_loss: 3.9350 - val_acc: 0.1709\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.2141 - acc: 0.1349 - val_loss: 3.7940 - val_acc: 0.1952\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.1340 - acc: 0.1489 - val_loss: 3.6946 - val_acc: 0.2143\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0666 - acc: 0.1582 - val_loss: 3.6666 - val_acc: 0.2119\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.9878 - acc: 0.1694 - val_loss: 3.5781 - val_acc: 0.2272\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.9297 - acc: 0.1793 - val_loss: 3.5860 - val_acc: 0.2258\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.8577 - acc: 0.1906 - val_loss: 3.4230 - val_acc: 0.2570\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.7909 - acc: 0.2025 - val_loss: 3.4205 - val_acc: 0.2567\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.7293 - acc: 0.2117 - val_loss: 3.3212 - val_acc: 0.2732\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.6707 - acc: 0.2216 - val_loss: 3.3023 - val_acc: 0.2758\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.6090 - acc: 0.2320 - val_loss: 3.2302 - val_acc: 0.2916\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.5643 - acc: 0.2378 - val_loss: 3.2214 - val_acc: 0.2897\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.5044 - acc: 0.2494 - val_loss: 3.1773 - val_acc: 0.3081\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.4522 - acc: 0.2579 - val_loss: 3.1673 - val_acc: 0.3083\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.4197 - acc: 0.2649 - val_loss: 3.1138 - val_acc: 0.3158\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.3721 - acc: 0.2718 - val_loss: 3.1578 - val_acc: 0.3073\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.3349 - acc: 0.2799 - val_loss: 3.0919 - val_acc: 0.3170\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.2999 - acc: 0.2844 - val_loss: 3.0522 - val_acc: 0.3218\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.2693 - acc: 0.2900 - val_loss: 3.0502 - val_acc: 0.3240\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.2391 - acc: 0.2959 - val_loss: 3.0106 - val_acc: 0.3359\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.2042 - acc: 0.3037 - val_loss: 3.0231 - val_acc: 0.3315\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.1845 - acc: 0.3064 - val_loss: 3.0118 - val_acc: 0.3339\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.1717 - acc: 0.3105 - val_loss: 2.9796 - val_acc: 0.3417\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.1377 - acc: 0.3150 - val_loss: 3.0414 - val_acc: 0.3349\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.1272 - acc: 0.3177 - val_loss: 3.0179 - val_acc: 0.3337\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.1083 - acc: 0.3229 - val_loss: 2.9734 - val_acc: 0.3472\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.0887 - acc: 0.3258 - val_loss: 3.0091 - val_acc: 0.3407\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.0721 - acc: 0.3298 - val_loss: 3.0034 - val_acc: 0.3422\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.0532 - acc: 0.3337 - val_loss: 2.9543 - val_acc: 0.3432\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.0363 - acc: 0.3363 - val_loss: 3.0137 - val_acc: 0.3425\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.0268 - acc: 0.3392 - val_loss: 2.9577 - val_acc: 0.3476\n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.0056 - acc: 0.3444 - val_loss: 3.0286 - val_acc: 0.3442\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.9930 - acc: 0.3475 - val_loss: 2.9212 - val_acc: 0.3601\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.9823 - acc: 0.3485 - val_loss: 2.9810 - val_acc: 0.3538\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.9652 - acc: 0.3521 - val_loss: 2.9655 - val_acc: 0.3505\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.9499 - acc: 0.3559 - val_loss: 2.9258 - val_acc: 0.3608\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.9373 - acc: 0.3585 - val_loss: 2.9554 - val_acc: 0.3553\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.9143 - acc: 0.3620 - val_loss: 2.9501 - val_acc: 0.3505\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.8983 - acc: 0.3654 - val_loss: 3.0194 - val_acc: 0.3487\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.8916 - acc: 0.3666 - val_loss: 2.9376 - val_acc: 0.3601\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.8808 - acc: 0.3696 - val_loss: 2.9701 - val_acc: 0.3591\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.8686 - acc: 0.3738 - val_loss: 2.9754 - val_acc: 0.3543\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.8517 - acc: 0.3741 - val_loss: 2.9691 - val_acc: 0.3540\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.8370 - acc: 0.3792 - val_loss: 2.9909 - val_acc: 0.3529\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.8215 - acc: 0.3805 - val_loss: 2.9727 - val_acc: 0.3591\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.8148 - acc: 0.3829 - val_loss: 2.9138 - val_acc: 0.3708\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 2.8034 - acc: 0.3841 - val_loss: 2.9347 - val_acc: 0.3651\n",
      "10000/10000 [==============================] - 2s 214us/step\n",
      "Test loss: 2.934705940246582\n",
      "Test accuracy: 0.3651\n",
      "Runtime: 1694.8043329715729\n",
      "\n",
      "\n",
      "\n",
      "Training Adagradoptimizer\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0311 - acc: 0.0049 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0372 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "10000/10000 [==============================] - 2s 214us/step\n",
      "Test loss: 16.0375048828125\n",
      "Test accuracy: 0.005\n",
      "Runtime: 1670.5442538261414\n",
      "\n",
      "\n",
      "\n",
      "Training Adadeltaoptimizer\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 15.9774 - acc: 0.0048 - val_loss: 16.0375 - val_acc: 0.0050loss: 15.7984 - acc: - ETA: 27s - l - ETA: 25s - loss: 15.8150 - acc: 0.004 - - ETA: 20s - loss: 15.8866 - acc: 0.005 - ETA: 20s - loss: 15.8873 - acc: 0.0 - ETA: 19s -  - ETA: 1s - loss: 15.9749 - acc:  - ETA: 1s - loss: 15.9754 - acc: 0. - ETA: 1s - loss: 15.9755 - acc:  - E\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 15.9975 - acc: 0.0048 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0139 - acc: 0.0049 - val_loss: 16.0375 - val_acc: 0.0050.0137 - acc: \n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050TA: 29s - loss: 16.0174 - acc:  - ETA: 25s  - ETA: 23s - loss:   - ETA: 19s - loss: 16.0326 - acc: 0.005 - ETA: 19s - loss: 16.0326 - acc: - ET - ETA: 17s - loss: 16.0340 - acc: 0.0 - ETA: 16s - loss: 16.0337 - acc: 0.00 - \n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050s - loss: 16.0413  - ETA: 32s - ETA: 24s \n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.00501 - acc:  - ETA: 22s - loss: 16 - ETA: 13s \n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050s: 16.0371 - a\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050 acc: 0. - ETA: 1s - loss: 16.0362 - ETA: 1s - loss: 16.0362 - acc:  - E\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0373 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0376 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0392 - acc: 0.0048 - val_loss: 16.0375 - val_acc: 0.0050cc:  - ETA: 0s - loss: 16.03\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0340 - acc: 0.0051 - val_loss: 16.0375 - val_acc: 0.0050: 16.0315 - acc: 0.0 - ETA: 24s - loss: 16.0304 - a - ETA: 18s - loss: 16 - ETA: 17s -  - ETA: 15s - loss: 16.0366 - acc: 0.005 - ETA: 15s - loss: 16.0369 - acc: 0.0 - ETA: - ETA: 7s - loss:\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0377 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050- ETA: 3s - loss: 16.0375 - - ETA: 2s - loss: 16.0379 - ETA: \n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0376 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.00500 - ETA: 20s  - ETA - ETA: 3s - loss: 16.0352 - acc: 0. - ETA: 3s\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.005074 - acc: \n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050 ETA: 27s - loss: 16.0393 - ac - ETA: 26s - loss: 16.0403 - ETA: 0s - loss: 16.0376 - acc: \n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050 - acc: 0. - ETA: 0s - l\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050- loss: 16.0370 - acc: 0.005 - ETA: 20s - loss: 16.0370 - acc: - ETA: 19s - loss: 16.0377 - acc: - ETA:\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "10000/10000 [==============================] - 2s 215us/step\n",
      "Test loss: 16.0375048828125\n",
      "Test accuracy: 0.005\n",
      "Runtime: 1842.5969245433807\n",
      "\n",
      "\n",
      "\n",
      "Training Adamoptimizer\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 7.2864 - acc: 0.0235 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 35s 22ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 35s 22ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 35s 22ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 35s 22ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 35s 22ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 35s 22ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 35s 22ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 35s 22ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 35s 22ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 35s 22ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 35s 22ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 35s 22ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1562 [==============================] - 35s 22ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 35s 22ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 35s 22ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 35s 22ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 35s 22ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 35s 22ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 35s 22ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 35s 22ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 35s 22ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 35s 22ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 35s 22ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "10000/10000 [==============================] - 2s 219us/step\n",
      "Test loss: 16.0375048828125\n",
      "Test accuracy: 0.005\n",
      "Runtime: 1761.8552310466766\n",
      "\n",
      "\n",
      "\n",
      "Training Adamaxoptimizer\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.7945 - acc: 0.0522 - val_loss: 4.3812 - val_acc: 0.0934\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.4819 - acc: 0.0876 - val_loss: 4.2742 - val_acc: 0.1182\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.3617 - acc: 0.1048 - val_loss: 4.1567 - val_acc: 0.1301\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.2958 - acc: 0.1147 - val_loss: 4.0428 - val_acc: 0.1489\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.2493 - acc: 0.1210 - val_loss: 4.0846 - val_acc: 0.1399\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.1998 - acc: 0.1280 - val_loss: 3.9358 - val_acc: 0.1633\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.1663 - acc: 0.1332 - val_loss: 4.0081 - val_acc: 0.1585\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.1418 - acc: 0.1373 - val_loss: 3.8319 - val_acc: 0.1724\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.1165 - acc: 0.1419 - val_loss: 3.8502 - val_acc: 0.1757\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0940 - acc: 0.1452 - val_loss: 3.8373 - val_acc: 0.1855\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0757 - acc: 0.1471 - val_loss: 3.7702 - val_acc: 0.1873\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0663 - acc: 0.1503 - val_loss: 3.7788 - val_acc: 0.1859\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0413 - acc: 0.1534 - val_loss: 3.6350 - val_acc: 0.2110\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0270 - acc: 0.1557 - val_loss: 3.6840 - val_acc: 0.1974\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0169 - acc: 0.1575 - val_loss: 3.6817 - val_acc: 0.2012\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0148 - acc: 0.1560 - val_loss: 3.7429 - val_acc: 0.1852\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0073 - acc: 0.1592 - val_loss: 3.7910 - val_acc: 0.1815\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0084 - acc: 0.1583 - val_loss: 3.6584 - val_acc: 0.2049\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0036 - acc: 0.1594 - val_loss: 3.8040 - val_acc: 0.1863\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0035 - acc: 0.1584 - val_loss: 3.7515 - val_acc: 0.1929\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.9998 - acc: 0.1585 - val_loss: 3.6361 - val_acc: 0.2100\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0001 - acc: 0.1591 - val_loss: 3.9080 - val_acc: 0.1638\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0042 - acc: 0.1609 - val_loss: 3.6977 - val_acc: 0.2003\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0010 - acc: 0.1595 - val_loss: 3.7697 - val_acc: 0.1908\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.9902 - acc: 0.1611 - val_loss: 3.7066 - val_acc: 0.1967\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.9940 - acc: 0.1598 - val_loss: 3.7459 - val_acc: 0.1947\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 3.9961 - acc: 0.1619 - val_loss: 3.7179 - val_acc: 0.1928\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0055 - acc: 0.1607 - val_loss: 3.6922 - val_acc: 0.1962\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0021 - acc: 0.1608 - val_loss: 3.5972 - val_acc: 0.2139\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0087 - acc: 0.1616 - val_loss: 3.6861 - val_acc: 0.2039\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0134 - acc: 0.1594 - val_loss: 3.7423 - val_acc: 0.1932\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0126 - acc: 0.1604 - val_loss: 3.7663 - val_acc: 0.1974\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0127 - acc: 0.1601 - val_loss: 3.6866 - val_acc: 0.1979\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0140 - acc: 0.1596 - val_loss: 3.6990 - val_acc: 0.1995\n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0285 - acc: 0.1590 - val_loss: 3.6959 - val_acc: 0.2000\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0281 - acc: 0.1603 - val_loss: 3.6730 - val_acc: 0.2044\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0247 - acc: 0.1586 - val_loss: 3.6780 - val_acc: 0.2021\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0202 - acc: 0.1593 - val_loss: 3.8473 - val_acc: 0.1743\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0372 - acc: 0.1567 - val_loss: 3.7285 - val_acc: 0.1886\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0351 - acc: 0.1591 - val_loss: 3.8977 - val_acc: 0.1661\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0510 - acc: 0.1567 - val_loss: 3.6892 - val_acc: 0.1999\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0440 - acc: 0.1557 - val_loss: 3.7553 - val_acc: 0.1905\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0575 - acc: 0.1549 - val_loss: 3.8911 - val_acc: 0.1722\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0549 - acc: 0.1556 - val_loss: 3.7131 - val_acc: 0.1956\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0615 - acc: 0.1540 - val_loss: 3.8442 - val_acc: 0.1728\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0592 - acc: 0.1567 - val_loss: 3.6931 - val_acc: 0.1913\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0623 - acc: 0.1572 - val_loss: 3.7434 - val_acc: 0.1937\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0577 - acc: 0.1544 - val_loss: 3.7356 - val_acc: 0.1918\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0633 - acc: 0.1554 - val_loss: 3.7570 - val_acc: 0.1856\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 34s 22ms/step - loss: 4.0675 - acc: 0.1554 - val_loss: 3.7469 - val_acc: 0.1958\n",
      "10000/10000 [==============================] - 2s 224us/step\n",
      "Test loss: 3.7469262130737304\n",
      "Test accuracy: 0.1958\n",
      "Runtime: 1715.1234188079834\n",
      "\n",
      "\n",
      "\n",
      "Training Nadamoptimizer\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0248 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050oss: 16.0141 - acc: 0.005 - ETA: 14s - loss: 16.0139 - acc: 0.0 - ETA: 14s - loss: 16.0141 - acc: 0. - ETA: 13s - loss: 16.0138 - acc: 0.005 - ETA: 13s - loss: 16.0141 - ETA: 12s - loss: 16.0155 - acc: 0.0 - ETA: 12s - loss: 16.0154 - ETA: 11s - loss: 16.0159 - acc: 0.005 - ETA: 11s - loss: 16.0159 - acc: - ETA: 11s - los - ETA: 9s - loss: 16.0159 - acc:  - ETA: 9s - loss: 16.0161 - acc - ETA: 9s - loss: 16.0165 - - ETA: 8s - loss: 16.0174 - ETA: 8s - - ETA - ETA: 2s - loss: 16. - ETA: 0s - loss: 16.0249 - acc:  - ETA: 0s - loss: 16.0248 - acc: 0.00\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050.0052 - acc:  - ETA: 32s - loss: 16.0078 - - ETA: 31s - loss: 16.0181 - acc: - ETA: 31s - loss: 16.023 - ETA: 27s - loss: 16.0288 - acc: 0.0 - ETA: 27s - loss: 16.0282 - acc: - ETA: 26s - loss: 16.0292 - acc: 0 - ETA: 26s - loss: 16.0301 -  - ETA: 25s - loss: 16.0304 - ac - ETA: 25s - loss: 16.0301 - acc - ETA: 24s - loss: 16.030 - ETA: 23s -  - ETA: 21s - loss: 16.0372 - ETA: 20s - loss: 16.0358 - acc: 0.00 - ETA: 20s - loss: 16.0357 - acc: 0.0 - E - ETA: 18s - loss: 16.0385 - a - ETA: 17s - loss:  - ETA: 16s - loss: 16.0392 - acc - ETA: 15s - loss: 16 - ETA: 14s - loss: 16.0374 - - ETA: 13s - loss: 1  - E - ETA: 4s - loss: 16.0378 -\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.00506.0397 - a - ETA: 32s - loss: 16.0488 - acc: 0. - ETA: 32s - loss: 16.0513 - a - ETA: 31s - loss: 16.0512 -  - ETA: 27s - loss: 16.0381 -  - ETA: 27s - loss: 16.0399 -  - ETA: 26s - loss: 16.0400 - - ETA: 25s - loss: 16.0370 - a - ETA: 24s - loss: 16.0373 - acc: - ETA: 24s - - ETA: 22s - loss: - ETA: 21s - loss: 16.0381 -  - ETA: 20s - loss: 16.0402 - acc:  - ETA: 19s - loss: 16.0400 - acc: 0. - ETA: 19s - loss: 16.0392 -  - ETA: 18s - \n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.005030s - loss: 16.0410 - a - ETA: 29s - loss: 16.0372 - acc - ETA:  - ETA: 26s - loss: 16.0409 - acc: 0.0 - ETA: 26s - loss: 16.0414 - acc:  - ETA: 25s - loss: 16.0398 - acc: 0.004 - ET - ETA: 23s - loss: 16.040 - ETA: 22s - loss: 16.0378 - acc: 0.0 - ETA: 22s - loss: 16.0377 - acc: 0 - ETA: 21s - loss: 16.0376 -  - ETA: 21s - loss: 16.0374 - acc: 0.0 - ETA: 21s - loss: 16.0382 - acc: - ETA: 20s - loss:  - ETA: 19s - loss: 16.0402 - a - ETA: 18s - loss: 16.0410 - acc: 0.00 - ETA: 18s - loss: 16.040 - ETA: 17s - loss: 16.0409 - acc: 0. - ETA: 17s - loss: 16.0405 - - ETA: 16s - loss: 16.0390 - ac - ETA: 15s - loss: 16.0391 - ETA: 14s - loss: 16.0400 -  - ETA: 2s - loss: 16.03 - ETA:  - ETA: 0s - l\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050 ETA: 30s - loss: 16.0368 - acc: 0 - ETA: 30s - los - ETA: 28s - loss: 16.0414 - acc: 0.004 - ETA: 28s - loss: 16.0413 - acc: - ETA: 28s - loss: 16.0425 - acc: 0. - ETA: 27s - loss: 16.0421 - acc - ETA: 27s - loss: 16.0393  - ETA: 26s - loss: 16.0401 - acc:  - ETA: 26s - loss: 16.0399 - acc: 0. - ETA: 25s - loss: 16.0 - ETA: 24s - loss: 16.0380 - acc: - ETA: 24s - loss: 16.0 - ETA: 23s - loss - ETA: 21s - loss: - ETA: 20s - loss: 16.0387 - acc: 0.004 - ETA: 19s - loss: 16.0383 - acc: 0. - ETA: 19s - loss: 16.0386 - acc: 0.00 - ETA: 19s - lo - ETA: 17s - loss: 16.04 - ETA: 16s - loss: 16.0410 - ac - ETA: 16s - loss: 16.0426 - acc: 0.004 - ETA: 16s - loss: 16.0425 - acc: 0.004 - ETA: 16s - loss: 16.0428 - acc: 0 - ETA: 15s - loss: 16. - ETA:  - ETA: 12s - loss: 16.0369 -  - ETA: 2s - loss: 16.0371 - acc - ETA: \n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050 - loss: 16.0254 - a - ETA: 29s - loss: 16.0254 - a - ETA: 29s - loss: 16.0274 - acc: - ETA: 28s - loss: 16.0270 - a - ETA: 27s - loss: 16.0309 - acc: 0.005 - ET - ETA: 22s - loss: 16.0351 - - ETA: 21s - loss: 16.0 - ETA: 20s - loss: 16.0345 - a - ETA: 20s - loss: 16.0 - ETA: 18s - loss: 16.0331 - acc: 0.005 - ETA: 18s - lo - ETA: 17s - loss: 16.0310  - ETA: 16s - loss: 16.0313 - acc - ETA: 1 - ETA: 13s - loss: 16.0327 - acc: 0.0 - ETA: 13s - loss: 16.0327 - acc: 0.005 - E - ETA: - E - ETA: 5s - loss: 16.0350 - ETA: 4s - loss: 16. - ETA: 4s - los - ETA: 3s - loss: 16.03 - ETA: 2s - loss: 16.0371 - a\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.00506.0115 - - ETA: 26s - loss: 16.0303 - acc: 0. - ETA: 25s - loss: 16.0317 - acc: 0.00 - ETA: 25s - loss: 16.0317 - acc - ETA: 25s - loss: 16.0347 - acc: 0.0 - ETA: 25s - loss: 16.0353 - acc: 0.005 - ETA: 24s - loss: 16.0358 - acc: 0. - ETA: 24s - loss: 16.0352 -  - ETA: 23s - loss: 16.034 - ETA: 22s - loss: 16.0 - ETA: 21s - loss: 16.0354 - acc:  - ETA: 21s - loss: 16.0354  - ETA: 20s -  - ETA: 18s - loss: 16.0358 - acc: - ETA: 18s - loss: - ETA: 16s - loss: 16.0350 - acc: 0 - ETA: 16s - loss: 16.0356 - - ETA: 15s - loss: 16.0358 - acc:  - ETA: 15s - loss: 16.0360 - acc: 0.005 - ETA: 15s - loss: 16.0363 - acc: 0.005 - ETA: 15s - loss: 16 - ETA: 13s - loss: 16.0359 - acc: - ETA: 13s - loss: 16.0372  - ETA: 12s - loss: 16.0367 - acc: 0.0 - ETA: 12s - loss: 16.0370 - acc: 0 - ETA: 11s - loss: 16.0369 - acc: 0.005 - ETA: 11s - loss: 16.0372 - ac - ETA:  - ETA: 9s - loss: 16.0373 - ETA: 9s - loss: 16.0379 - - ETA: 8s - loss: 16.0376 - a - ETA: 8s - loss: 1 - ETA: 7s - l - ETA: 6s - loss: 16.0388 - acc: 0.00 - ETA: 6s - loss: - ETA: 5s - los - ETA\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050 - loss: 16. - ETA: 32s - loss: 16.0321 - acc - ETA: 31s - l - ETA: 29s - loss: 16.03 - ETA: 28s - loss: - ETA: 27s - loss: 16.0327 - ac - ETA: 26s - loss: 16.0355 - - ETA: 17s - loss: - ETA: 16s - loss: 16.0337 - acc: 0.00 - ETA: 16s - loss: 1 - ETA: 14s - loss: 16.0360 - acc: - ETA: 14s - lo - ETA: 12s -  - ETA: 10s - loss: 16.0385 - acc: 0 - ETA: 10s - loss: 16.0396 - - ETA: 9s - loss: 16.0381 - acc:  - ETA: 0s - loss: 16.0377 - acc\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050 - ETA: 30s - loss - ETA: 29s - loss: 16.0351  - ETA: 28s - loss: 16.0317 - acc: 0.005 - ETA: 28s - loss: 16.0309 - acc - ETA: 27s - loss: 16.0250 - a - ETA: 26s - loss: 16.0258 - ac - ETA: 26s - loss: 16 - ETA: 25s - loss: 16.0353 -  - ETA: 24s -  - ETA: 22s - loss: 16. - ETA: 21s - loss: 16.0416 - ETA: 17s - loss: 16.0406 - acc: 0.00 - ETA: 17s - los - ETA: 15s - loss: 16.0409 - acc: 0.  - ETA: 12s - loss: 16.0403 - acc - ETA: 12s - loss: 1 - ETA: 10s - loss: 16.0393 - acc: 0.004 - ETA: 10s - loss: 16.0393 - acc: 0.0 - ETA: 10s - loss: 16.0395 - acc: 0.0 - ETA: 6s - loss: 16.0375 - acc: 0. - ETA: 6s - loss: 16.0373 - acc:  - ETA: 5s - los - ETA - E - - ETA: 0s - loss: 16.0375 - acc: 0.00\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.00503s - loss: 16.0274 - acc: 0. - ETA: 33s - loss: 16.0284 - acc: 0 - ETA: 32s - loss: 16.0317 - - ETA: 31s - loss: 16. - ETA: 30s - loss: 16.0368 - acc: 0. - ETA: 30s - loss: 16. - ETA: 29s - loss: 16.0 - ETA: 25s - loss: 16.0359 - ETA: 24s - loss: - ETA: 22s - loss: 16.0379 - acc: 0.00 - ETA: 22s - loss: 16.0378 - acc: 0.005 - ETA: 22s - loss: 16.0369 - acc: 0.0 - ETA: 22s - loss: 16.037 - ETA: 21s - loss: 16.0 - ETA: 20s - loss: 16.0380 - acc: 0.0 - ETA: 20s - loss: 16.0383 - acc: 0.0 - ETA: 19s - loss: 16 - ETA: 18s - loss: 16 - ETA: 17s - loss: 16.0412 - acc: 0.004 - ETA: 17s - loss: 16.0415 - acc: 0.00 - ETA: 17s - loss: 16.0414 - a - ETA: 16s - loss: 16.0409 - acc: - ETA: 16s - loss: 16.0413 - acc: 0. - ETA: 15s - l - ETA: 1 - ETA: 11s - los - ETA: 6s - loss: 16.0388 - ETA: 5s - loss: 1 - ETA: 4s - l\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050 acc: 0. - ETA: 31s - loss: 16.0506 - acc - ETA: 31s - loss: 16.0 - ETA - ETA: 27s - loss: 16.0 - ETA: 23s - loss: 16.0434 - acc: 0.004 - ETA: 23s - loss: 16.0433 - acc: 0. - ETA: 23s - loss: 16.0451 - acc:  - ETA: 23s - loss - ETA: 21s - loss: 16.0456 - acc: 0.004 - ETA: 21s - loss: 16.0455 -  - ETA: 20s - loss: 16.046 - ETA: 19 - ETA: 17s - loss: 16.0445 - acc: 0.004 - ETA: 17s - loss - - ETA: 13s - loss: 16.0443 - ET - ETA: 10s - loss: 16.0393 - acc: 0.0 - ETA: 9s - loss: 16.0 - ETA: 9s - loss: 16. - ETA: 8s - ETA: 7s - loss: 16. - ETA: 7s - loss: 16. - ETA: 6s - loss: 16.0388 - acc: 0.00 - ETA:  - ETA: 0s - loss: 16.0375 - acc: 0.\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050: 34s - loss: 16.0341 - acc: 0.005 - ETA: 33s - loss: 16.0299 - ac - ETA: 33s - lo - ETA: 31s - loss: 16.032 - ETA: 30s - loss: 16.0350 - acc:  - ETA: 29s - l - ETA: 28s - loss: 16.0347 - ac - ETA: 27s - loss: 16.0347 - acc: 0.00 - ETA: 27s - loss:  - ETA: 26s - loss: 16.0358 - acc: 0. - ETA: 25s - loss: 16.0346 - acc: 0. - ETA: 25s - loss: 16.0357 - acc: 0.005 - ETA: 25s - lo  - ETA: 21s - loss:  - ETA: 19s - loss: 16.0 - ETA: 18s - ETA: 16s - loss: 16 - ETA: 15s - loss: 16.0394 - acc: - ETA: 14s - l - ETA: 13s - loss: 16.0381 - acc - ETA: 12s - los - ETA: 10s - loss: 16.0396 - acc: 0.0 - ETA: 10s - loss: 16.0393 - acc: 0. - ETA: 10s - loss: 16.0388 - acc: 0.004 - ETA: 10s - loss: 16.0386 - acc - ETA: 9s - loss: 16.0380 - acc: 0.00 - ETA: 9s - loss: 16.0383 - ETA: 6s - loss: 16.0364 - acc:  - ETA: 6s - loss: 1 - ETA: 4s - loss: 16.0370 - a - - ETA: 2s - loss: 16.0379 - acc: \n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.00500382 - acc: 0.00 - ETA: 25s - loss - ETA: 23s - loss: 16.0376 - acc:  - ETA: 23s - loss: 16.0384 - - ETA: 22s - loss: 16. - ETA: 21s - loss: 16.0382 - a - ETA: 20s - los - ETA: 18s - loss: 16.0429 - ETA: 17s - loss - ETA: 2s - loss: 16.0386 - acc: 0. - ETA: 2s - los\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050TA: 29s - loss: 16.0210 - a - ETA: 29s - loss: 16.0255 - acc: - ETA: 28s - loss: 16.0253 - acc: 0.005 - ETA: 28s -  - ETA: 26s - loss: 16.0327 - ac - ETA: 26s - loss: 16.0322 - a - ETA: 25 - ETA: 23s - loss: 16.0292 - ac - ETA: 23s - loss: - ETA: 21s - loss: 16.0302 - acc: - ETA: 21s - loss: 16.0299 - acc: 0 - ETA: 20s - loss: 16.0304 - acc: - ETA: 20s - loss: 16.0306 - acc: 0.005 - ETA: 20s - loss: 16.0302 - acc - ETA: 19s - lo - ETA: 1s - loss: - ETA: 1s - loss: 16.0364 - - ETA: 0s - loss: 16.0372 - acc: 0. - ETA: 0s - loss: 16.03\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050 loss: 16.0341 - acc: 0. - ETA: 30s - loss: 16.0381 - acc: 0.00 - ETA: 30s - loss - ETA: - ETA: 26s - loss: 1 - ETA: 25s - loss: 16.0424 - acc:  - ETA: 25s - loss: 16.0421 - acc: 0.00 - ETA: 24s - loss: 16.0420 - ETA: 23s - loss: 16.0413 - acc:  - ETA: 23s - loss: 16. - ETA: 22s - ETA: 20s - loss: 16.0421 -  - ETA: 19s - loss - ETA: 18s - loss: 16.0360 - acc:  - ETA: 17s - loss: 16.0363 - acc: 0.00 - ETA: 17s - loss: 16.0366 - - ETA: 16s - loss: 16.0371 -  - ETA: 15s - loss: 16.0373 - a - ETA: 1 - ETA: 13s - loss: 16.0361 - acc: 0 - ETA: 12s - loss: 16.0364 - acc: 0. - ET - ETA: 10s - loss: 16.0386 - acc: 0.004 - ETA: 10s - loss: \n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050A: 30s - loss: 16.0463 - acc: 0.00 - ETA: 30s - - ETA: 28s - loss: 16.0442 - acc: 0.004 - ETA: 28s - loss: 16.0 - ETA: 27s - loss: 16.0425 - acc - ETA: 16s - loss: 16.0365 - ETA: 15s - loss: 16.0361 - acc:  - ETA: 14s - lo - ETA: 12s - loss: 16.0352 - acc: 0. - ETA: 12s - loss: 16.0349 - acc: 0.0 - ETA: 12s - loss: 16.0349 - acc: 0.0 - ETA: 12s - loss: 16.0351 -  - ETA: 11s - loss: 16. - ETA: 10s - loss: 16.0353 - acc: 0.005 - ETA: 10s - loss: 16 - ETA: 8s - loss: 16.03 - - ETA: 6s - loss: 16. - ETA: 0s - loss: 16.0372 - acc:  - ETA: 0s - loss: 16.0373 - acc\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050A: 30s -  - ETA: 28s - loss: 16. - ETA: 27s - loss: - ETA: 23s - loss: 16.0402 - acc: - ETA: - ETA: 20s - lo - ETA: 18s - loss: 16.0384 - acc:  - ETA: 18s - loss: 16. - ETA: 17s - loss: 16.0387 - acc: 0. - ETA: 16s - los - ETA: 15s - loss: 16.04 -  - ETA: 11s - loss: 16.0370 - acc: 0.00 - ETA: 11s - loss: 16.0370 - acc:  - ETA: 11s - loss: 16.0367  - ETA: 10s - loss: 16.0355 - acc: 0.00 - ETA: 10s - loss: 16.0355  - ETA: 9s - los - ETA: 8s - loss: 16.03 - ETA: 8s - loss: 16.0377 - ETA: 7s - loss: 16.03 - ETA: 7s - loss: 16.0374 - acc:  - ETA: 7s - loss: 1 - ETA: 5s - ETA: 0s - loss: 16.0375 - acc: 0.00\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050- loss: 16.0461 - acc: 0 - ETA: 30s - loss: 16.0465 - a - ETA: 30s - loss: 16.0483 - acc: 0.0 - ETA: 30s - loss: 16.0432 - acc: - ETA: 29s - loss: 16.0 - ETA: 28s - loss: 16. - ETA: 21s - loss: 16.0414 - acc: 0. - ETA: 21s  - ETA: 16s - loss: 16.0400 - acc: 0 - ETA: 16s - loss: 16.0396 - acc: - ETA: 15s - loss: 16.0404 - acc - ETA: 15s - loss: 16.0399  - ETA: 14s - loss: 16.0377 - acc: 0.005 - ETA: 14s - loss: 16.0374 -  - ETA: 13s - loss: 16.0365 - acc: 0.005 - ETA: 13s - loss: 16.0360 - - ETA: 12s -  - ETA: 0s - loss: 16.03 - ETA: 0s - loss: 16.0378 - acc: 0.00 - ETA: 0s - loss: 16.0377 -\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050 - loss: 16.0217 - acc - ETA: 29s - loss: 16.0397 - acc: 0 - ETA: 29s - loss: 16.0362 - acc:  - ETA: 29s - loss: 16.0370 - acc: 0.0 - ETA: 28s - loss: 16.0369 - acc: 0.00 - ETA: 28s - loss: 16.0332 - acc - ETA: 28s - loss: 16.0383 - acc: 0.00 - ETA: 28s - loss: 16.0366 - a - ETA: 27s - loss: 16.0 - ETA: 26s - loss: 16.0328 - a - ETA - ETA: 20s - loss: 16.036 - ETA: 16s - loss: 16.0410 - acc:  - ETA: 16s - loss: 16.0417 - acc: 0.00 - ETA: 16s - loss: 16.042 - ETA: 15s - loss: 16. - ETA: 13s - loss: 16.0419 - acc: 0.0 - ETA: 13s - loss: 1 - ETA: 12s - loss: 16.0422 - acc: 0. - ETA: 12s - loss: 16.0428 - acc:  - ETA: 11s - loss: 16.0432 - acc: 0 - ETA: 11s - loss: 16.0428 - acc - ETA: 10s - loss:  - ETA - ETA: 5s - loss: 16.0404 - ETA: 5s - loss: 16.0393 - acc - E - ETA: 1s - loss: 16.0368 - acc: 0. - ETA: 1s - loss: 16.0369 - a - ETA: 0s - l\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050oss: 16.0165 - acc: 0 - ETA: 33s - loss - ETA: 31s - - ETA: 29s - loss: 16.0353 - acc:  - ETA: 29s - loss: 16.0341 - acc: 0.0 - ETA: 29s - loss: 16.0341 - ETA: 28s - loss: 16.0350 - acc: - ETA: 27s - loss: 16.0373 - acc: - ETA: 27s - loss: 16.0386 - acc: 0.004 - ETA: 27s - loss: 16.0386 - acc: 0.004 - ETA: 27s - loss: 16.0393 - acc: 0.004 - ETA: 27s - loss: 16.0385 -  - ETA: 26s - loss: 16 - ETA: 19s - lo - ETA: 18s - loss: 16.0315 - a - ETA: 17s - loss: 16.0325 - ETA: 16s - loss: 16.0345 - acc:  - ETA: 16s - loss: 16.0347 - acc: 0 - ETA: 15s - loss: - ETA: 14s - loss: 16.0370 - - ETA: 13s - loss: 16. - ETA: 12s - loss: 16.03 - ETA: 11s - ETA: 9s - l - ETA: 8s - l - ETA: 6s - loss: 16.03 - ETA - ETA: 0s - los\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050- ETA: 31s - loss: 16.0347 - acc: 0.0 - ETA: 31s - loss: 16.0361 - acc: - ETA: - ETA: - ETA: 26s - loss: 16.0388 - acc: 0.00 - ETA: 26s - loss: 16.0388 - acc:  - ETA: 25s - loss: 16.0404 - acc: 0.004 - ETA: 25s - loss: 16.0397 - acc: - ETA: 25s - loss: 16.0389 - acc: 0.0 - ETA: 24s - loss: 16.0399 - acc: 0.00 - ETA: 24s - los - ETA: 20s - loss: 16.0393 - acc: - ETA: 19s - loss: 16.038 - ETA: 18s - loss: 16.0385 - acc: 0. - ETA: 18s - loss: 16.0377 - acc: - ETA: 18s - loss: 16.0386 - a - ETA: 17s - loss: 16.0404 - acc: 0. - ETA: 17s - loss: 16.0390 -  - ETA: 16s - loss: 16.03 - ETA: 12s - loss: 16.0349 - ETA: 11s - ETA: 8s - loss: 16.0350 - acc: 0.00 - ETA: 8s - loss: 16.0348 - acc:  - ETA: 8s - l - ETA: 7s - E - ETA: 3s - ETA: 1s - loss: 16.0375 - a - ETA: 1s - - ETA: 0s - loss: 16.0374 - acc: \n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050s - lo - ETA: 29s - loss: 16.0432 - acc: 0.00 - ETA: 29s - loss: 16.0397 - acc: 0 - ETA: 29s - loss: 16.0383 - acc: 0 - ETA: 29s - loss: 16.0361 - acc: 0.0 - ETA: 28s - loss: 16.0370 - acc: - ETA: 28s - los - ETA: 26s - loss - ETA: 25s - loss: 16.0300 - acc: 0. - ETA: 25s - loss: 16.0301 - acc:  - ETA: 24s - loss: - ETA: 23s - loss: 16.02 - ETA: 22s - loss: 16.0293  - ETA: 21s - loss: 16.0309 - acc: 0.00 - - ETA: 18s - loss: 16.0351 - acc: 0.00 - ETA: 18s - loss: 16.0 - ETA: 17s - loss: 16 - ETA: 15s - loss: 16.0 - ETA: 14s - loss: 16.0327 - a - ETA: 14s - loss: 16.0332 - acc: 0 - ETA: 13s - loss: 16.0330 - acc:  - ETA: 13s - loss: 16.0341 - ETA: 12s - loss: 16.033 - ETA: 11s - loss: 16.0343 - acc: - ETA: 10s - loss: 16.0350 - acc - ETA: 10s  - ETA - ETA: 6s - - ETA: 1s - loss: 16. - ETA: 1s - l - ETA: 0s - loss: 16.0369 - acc - ETA: 0s - loss: 16.0373 - acc: 0.\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050loss: 16 - ETA: 29s - loss: 16.0526 - acc: 0 - ETA: 29s - loss: 16.0546 - ETA: 28s - loss: 16.050 - ETA: 27s - loss: 16.0507 - acc: 0.00 - ETA: 27s - loss: 16.0512 - acc: 0.00 - ETA: 27s - loss: 16.0501 - acc - ETA: 26s - loss: 16.0505 - acc: 0.0 - ETA: 26s - loss: 16.0501 - acc: 0.004 - ETA: 26s - loss: 16.0506 - a - ETA: 25s - loss: 16.0480 - acc: 0 - ETA: 25s - loss:  - ETA: 24 - ETA: 22s - loss: 16.0426  - ETA: 21s - loss: 16.0429 - acc: 0.004 - ETA: 21s - loss: 16.04 - ETA: 20s - loss: 16.0377 - acc - ETA: 19s - loss: 16.0375 - acc: 0.005 - ETA: 19s - loss: 16.0372 - ac - ETA: 18s - loss: 16.0378 - ac - ETA: 18s - loss: 16.0373 - a - ETA: 17s - loss:  - ETA: 16s - loss: 16. - ETA: 12s - loss: 16.0379 - acc: 0.005 - ETA: 12s - loss: 16.0376 - - ETA: 11s - loss: 16.0 - ETA: 10s - loss: 16.038 - ETA: 9s - loss: 16.0386 - acc:  - ETA: 5s - - ETA: 4s - ETA: 3s - ETA: 1s - loss: 16.0388 - acc:  - ETA: 0s - l\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050: 26s - loss: 16 - ETA: 25s - loss: 16.0324 - acc:  - ETA: 24s - loss: 16.0341 - acc: 0. - ETA: 24s - loss: 16.0347 - acc: 0. - ETA: 24s - loss: 16.0341 - acc - ET - ETA: 21s - loss: 16.0329 - acc: 0.00 - ETA: 21s - loss: 16.0337 - a - ETA: 20s - loss: 16.0349 - acc: - ETA: 20s - loss: 16.0349 - acc: 0.0 - ETA: 19s - loss: 16.0345 - a - ETA: 19s - loss: 16.0334 - ac - ETA: 18s - loss: 16.0335 - acc: 0.005 - ETA: 18s - loss: 16.0338 - acc: 0. - ETA: 18s - loss: 16.0341 - acc: 0.005 - ETA: 18s - - - ETA: 13s - loss: 16.0347 - acc: 0. - ETA: 13s - loss: 16.0355 - acc: - ETA - ETA: 8s - l\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050ETA: 29s - loss:  - ETA: 28s - - ETA: 26s - loss: 16.0335 - acc - ETA: 26s - loss: 16.0354 - acc:  - ETA: 25s - loss: 16.0354 - acc - ETA: 25s - loss: 16.0364 - acc: - ETA: 24s - loss: 16.0369 - acc: 0.005 - ETA: 24s - loss: 16.0374 - ETA: 23s - loss: 16.0346 - acc: 0.0 - ETA: 23s - loss: 16.0346 - acc: 0.00 - ETA: 23s - loss: 16.0351 -  - ETA: 22s - loss: 16.0351 - acc: 0.00 - ETA: 22s - loss: 16.0350 - ac - ETA: 21s - loss: 16.0353 - acc - ETA: 21s - loss: 16.0361 - acc: 0. - ETA: 21s - loss: 16.0348 - acc - ETA: 20s - loss: 16.0340 - acc: -  - ETA: 17s - loss: 16.03 - ETA: 16s - loss: 16.0 - ETA: 15s - loss:  - ETA: 11s - loss:  - ETA: 9s - - ETA: 8s - loss: 1 - ETA: 8s - loss: 16.0381 - acc: 0.00 - ETA: 8s - loss: 16.0383 - acc - ETA: 7s - loss: 16.0382 - a - ETA: 7s - loss: 16.0390 - a - ETA: 7s - loss: 1 - ETA: 6s - loss: 16. - ETA: 5s - loss: 16.0382 - acc: 0.00 - ETA: 5s - ETA: 4s - loss: 16.0378 - a - ETA: 4s - loss: 1 - ETA: 3s - loss: 16.0384 - acc - ETA: 3s - loss: 16.0384 - acc - ETA: 3s - loss: - ETA: 2s - loss: 16.0377 - acc:  - ETA: 2s - loss: 16.0375 - acc:  - ETA: 2s - loss: 16.0374 - acc: 0. - ETA: 2s - loss: 16.0373 - ETA: 1s - ETA: 0s - loss: 16.\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050s - ETA: 31s - loss: 16.0270 - acc: 0. - ETA:  - ETA: 29s - loss: 16 - ETA: 28s - loss: 16.0284 - ETA: 27s - loss: 16.0291 - acc: 0.0 - ETA: 26s - loss: 16.0286 - a - ETA: 26s - loss: 16.0270 - acc: 0 - ETA: 25s - loss: 16.02 - ETA: 24s - loss: 16.0 - ETA: 23s - loss: 16.0311 - acc: 0.0 - ETA: 23s - loss - ETA: 21s - loss: 16.0316 - acc:  - ETA: 21s - loss: 16.0304 -  - ETA: 20s - loss: 16.0345 - acc: 0.005 - ETA: 20s - loss: 16.0349 - acc: - ETA: 20s - loss: 16.0330  - ETA: 19s - loss: 16.0313 - acc: - ETA: 18s - loss: 16.0317 - acc: 0. - ETA: 18s - loss: 16.031 - ETA: 17s - loss: 16. - ETA: 16s - loss: - ETA: 14s - loss: 16.03 - ETA: 13s - loss: 16.0351 - - ETA: - ETA: 10s - loss: 16.0345 - acc: - ETA: 10s - loss: - ETA: 9s - loss: 16.0347 - a - ETA: \n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0372 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050 ETA: 30s - loss: 16.0307 - acc - ETA: 29s - loss: 16.0290 - ac - ETA: 28s - loss: 16.034 - ETA:  - ETA: 22s - loss: 16.0355 - acc: 0.00 - ETA: 22s - loss: 16.0355 - acc:  - ETA: 22s - l - ETA: 20s - loss: 16.039 - ETA: 19s - loss: 16.0389 - acc: 0 - ETA: 19s - loss: 16.0381  - ETA: 18s - loss: 16.0382 - acc:  - ETA: 17s - loss: 16.038 - ETA: 16s - loss: 16. - ETA: 15s - loss: 16.0388 - acc:  - ETA: 15s - loss: 16.0382 - acc: 0.00 - ETA: 15s - loss: 16.0379 - acc: 0.0 - ETA: 15s - loss: 16.0384 - acc: 0. - ETA: 14s - loss: 16.0386 - acc: 0.00 - ETA: 14s - loss: 16.0391 - acc: 0.0 - ETA: 14s - - ETA: 12s - loss: 16.0397 - acc: 0.00 - ETA: 12s - loss: 16.0396 - acc: 0.004 - ETA: 12s - loss: 16.0386 - - E - ETA: 8s - loss: 16.0389 - acc - ETA:  - ETA:  - ETA: 0s - loss: 16.0378 -\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.00501 - acc: 0 - ETA: 32s - loss: 16.0541 - acc: - ETA: 31s - loss: 16.0530 - acc: 0. - ETA: 31 - ETA: 29s - loss: 16.0481 - acc - ETA: 28s - loss: 16.0439 - acc - ETA: 28s - l - ETA: 26s - loss: 16.0373 - acc:  - ETA: 26s - loss: 16.0378 - acc:  - ETA: 25s - loss: 16.0388 - acc: 0.004 - ETA: 25s - loss: 16.0388 - acc: - ETA: 25s - loss: 16.0397 - ac - E - ETA: 22s - loss: 16.0401 - acc - ETA: 21s  - ETA: 19s - loss: 16.0410 - acc: 0. - ETA: 19s - loss: 16.0412 - ETA: 18s - loss: 16.0405 - ac - ETA: 17s - loss: 16.0413 - acc: 0.0 - ETA: 17s - loss: 16.0409 - acc - ETA: 17s - loss: 16.0410 -  - ETA: 16s - loss: 16.0389 - acc: 0.0 - ETA: 16s - loss: 16.0388  - ETA: 15s - loss: 16.0386 - a - ETA: 14s - loss: 16. - ETA: 10s - loss: 16.0392 - E - ETA: 4s - loss: 16.0393 - ETA:  - ETA: 3s - loss: 16.0396 -\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050 34s - loss: 16.0341 - acc: 0.005 - ETA: 34s - loss: 16.0237 - ac - ETA: - ETA: 31s - loss: 16.0384 - acc: 0.00 - ETA: 30s - loss: 16.0383 - ETA: 29s - loss: 16.0386 - - ETA: 29s - loss: 16 - ETA: 27s - loss: 16.0302 - acc: 0.0 - ETA: 27s - loss: 16 - ETA: 26s - loss: 16.0328  - ETA: 25s - los - ETA: 23s - loss - ETA: 22s - -  - ETA:  - ETA: 1 - ETA: 13s - loss: 16.0338 - acc: 0 - ETA: 13s - loss\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050 16.0664 - acc: 0.003 - ETA: 32s - loss: 16.0635 - acc:  - ETA: 31s - loss: 16.0524  - ETA: 31s - loss: 16.0555 - acc: 0.0 - ETA: 30s - los - ETA: 29s - loss: 16.0400 - ac - ETA: 28s - loss: 16.04 - ETA: 27s  - ETA: 25s - loss: 16.0430 - acc: 0.0 - ETA: 25s - loss: 16.0434 - acc: 0.004 - ETA: 25s - loss: 16.0439 - acc: 0.0 - ETA: 25s - loss: 16.04 - ETA: 21s - loss:  - ETA: 17s - loss: 16.0416 - ETA: 16s - loss: 16.0416 - acc: 0. - ETA: 15s - loss: 16.0406 - acc: - ETA: 15s - loss: 16.0407 - acc: 0.00 - ETA: 15s - loss: 16.0404 - acc: 0.004 - ETA: 15s - loss: 16.0406 - acc: 0 - ETA: 12s - loss: 16 - ETA: 10s - loss: 16.0378 - acc: 0 - ETA: 10s - loss: 16.0 - ETA: 9s - - ETA: 8s - loss: 16.0384 - a - ETA: 8s - loss: - ETA: 4s - loss: 16.0388 - a - ETA: 4s - loss: 1 - ETA: 3s - loss: 16.03 - ETA: 3s - loss: 16. - ETA: 1s - loss: 16.0378 - acc: \n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050 16.0607 - ETA: 31s - loss: 16.0535 - a - ETA: 30s - loss: 16.0558 - acc:  - ETA: 30s - loss: 16.0477 - acc: 0 - ETA: 30s - loss: 16 - ETA: 28s - loss: 1 - ETA: 27s - los - ETA: 25s - loss: 16.0403 - acc: - ETA: 25s - loss: 16.0412 - ac - ETA: 24s - loss: 16.0402 - acc: 0.00 - ETA: 24s - loss: 16.0396 - acc: 0. - ETA: 24s - loss: 16.0400 - acc - ETA: 23s - loss: 16.0422 - acc: - ETA: 20s -  - ETA: 18s - loss: 16.043 - ETA: 1s - loss: 16.03 - ETA: 0s - - ETA: 0s - loss: 16.0374 - acc: 0.00\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.00507s - loss: 16.0305 - acc - ETA: 26s - loss: 16.03 - ETA: 2 - ETA: 0s - loss: 16.0380 - acc\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050: 30s -  - ETA: 28 - ETA: 26s - loss: 16.0420 -  - ETA: 26s - l - ETA: 24s - loss\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050l - ETA - ETA: 29s - loss: 16.0436 - acc - ETA: 28s - loss: 16 - ETA - ETA: 5s - loss: 16.0345 - acc: 0. - ETA: 4s - l - ETA: 4s - loss: 16.0350 - acc:  - ETA: 3s - loss: 16.0355 - acc - E - ETA: \n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050loss: 16.0503 - acc: 0.00 - ETA - E - ETA: 23s - loss: 16.0434 - acc: 0.0 - ETA: 23s - - ETA: - ETA: 19s - loss: 16.04 - ETA: 17s - loss - ETA: 0s\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.005098 - acc:  - ETA: 30s - loss: 16.0302 - acc: 0.005 - ETA: 30s - loss: 16.0316 - a - ETA:  - ETA: 27s - loss: 16.0388 - - ETA: 26s - loss: 16.03 - ETA: 25s - loss: 16.0354 - acc: 0.005 - ETA: 25s - loss: 16.0360 - acc: 0 - - ETA: 22s - loss: 16.0332  - ETA: 2 - ETA: 19s - loss - ETA: 18s - loss: 16.0321 - acc - ETA: 17s - loss:  - ETA: 16s - loss: 16.0335 - acc: 0.00 - ETA: 16s - l - ETA: 14s - loss: 16.0 - ETA: 13s - loss: 16.0326 - ETA: 0s - loss: 16.0376 - a\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050- ETA: 29s - loss: 16 - ETA: 27s - loss: 16. - ETA: 26s - loss: 16.0362 - acc:  - ETA: 2 - ETA: 24s - loss: 16.0326  - ETA: 23s - loss: 16.0351 - acc: 0 - ETA: 22s - loss: - ETA: 18s - loss:  - ETA: 17s - loss: 16.0356 - acc: 0.005 - ET - ETA: 14s - loss: 16. - ETA: 13s - loss: 16.0367 - acc: 0.0 - ETA: 13s - loss: 16.0372 - ETA: 12s - loss: 16.0378 - acc: 0. - ETA: 12s - loss: 16.037 - ETA: 11s - loss: - ETA: 8s - loss: 16.0375 - acc: 0.00 - ETA: 8s - loss: - ETA: 2s - loss: 16.0363 - ETA: 1s - loss: 16.0366 - acc: 0.00 - ETA: 1s - loss: 16.0366 -\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050.0 - ETA: 29s - loss - ETA: 27s - loss: 1 - ETA: 26s - loss: 16.0374 - ETA: 25s - loss: 16.0365 - acc: 0.00 - ETA: 25s - loss: 16.0365 - acc: 0 - ETA: 2 - ETA: 22s - loss: 16.0341 - a - ETA: 22s - loss: 16.03 - ETA: 20s - loss: 16.0350 - acc: 0.0 - ETA: 20s - loss: 16.0357 - acc:  - ETA - ETA: 18s - loss: 16.0388 - acc: 0.004 - ETA: 17s - loss: 16.0385  - ETA: 17s - loss: 16.03 - ETA: 16s - loss: 16 - ETA: 14s - lo - ETA: 13s - loss\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050oss: 16.0366 - acc: 0.0 - ETA: 30s  - ETA: 28s - loss: 1 - ET - ETA: 24s - - ETA: 22s -  - ETA: 20s - loss: 16.0376 - acc: 0.00 - ETA: 20s - loss: 16. - ETA: 19s - loss: 16.0387 - acc: 0.004 - ETA: 19s - loss: 16. - ETA: 3s - loss: 16. - ETA: 2s - loss: 16.0367 - acc: 0. - ETA: 2s - loss: 16.0367 - a - ETA: 2s - loss:\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050.034 - ETA: 32s - loss: 16.0505 - ac - ETA: 31s - ETA: 29s - loss: 16.0488 - acc: 0.0 - ETA: 29s - loss: 16.0513 - acc: - ETA: 29 - ETA: 26s - loss: 16.0569 - acc: 0. - ETA: 26s - l - ETA -\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050 28s - loss: 16.0341 - acc: 0. - ETA: 28s - loss: 16.0358 - ETA: 27s - loss: 16.0371 - acc: 0.00 - ETA: 24s - loss: 16.0368 - acc: 0.005 - ETA: 24s - loss: 16.0363 - acc: - ETA: 23s - loss: 16.0362 -  - ETA: 23s - l - ETA: 21s - l - ETA: 19s - loss: 1 - ETA: 18s - loss: 16.0358 - acc - ETA: 17s - loss: 16. - ETA: 16s - loss: 16.036 - ETA: 15s - loss: 16.0 - ETA: 14s - loss: 16.0363 - acc: 0.00 - ETA: 14s - loss: 16. - ETA: 12s - lo - E - ETA: 6s - loss: 16.0381 - - ETA: 6s - l - ETA: 5s - loss: 16.0387 - a - ETA: 5s - loss: 16.0387 - - ETA: 4s - loss: 16.0388 - - ETA: 4s - loss: 16.0384 - acc: 0.00 - ETA: 4s - loss: 16.0385 - - ETA\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050A: 32s - loss: 16.0439 - acc: - ETA: 32s - loss: 16.0386 - acc:   - ETA: 17s - los - ETA: 13s - loss: 16.038 - ETA: 12s - loss: 16.0 - ETA: 11s - loss:  - ETA: 9s - loss: 16.0401 - acc: 0.0 - ETA: 1s - loss: 16.0393 - acc: 0.00 - ETA: 1s - loss: 16.0391 - acc: 0. - ETA: 1s - loss: 16.0393 - acc - ETA: 1s - loss: 16.0391 - acc - ETA: \n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050 loss: 16.0573 - ac - ETA: 30s - loss: 16.0530 - acc: 0.0 - ETA: 30s - loss:  - ETA: 28s - loss: 16.0417 - acc: 0. - ETA - ETA: 26s - loss: 16.0420 - acc: 0. - ETA: 25s - loss - ETA: 21s - loss: 16.0410 - ETA: 20s - loss: 16.0406 - acc:  -  - ETA: 17s - loss: 16.0398 - acc:\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050- - E - ETA: 23s - loss: 16.0380 - acc: - ETA: 22s - loss: 16.0369 -  - E - ETA: 19s - loss: 16.0382 - acc:  - ETA: 19s - loss: 16.0366 - acc:  - ETA: 18s - ETA: 16s - loss: 16.0388 - acc: - ETA: 16s - loss: 1 - ETA: 14s  - ETA: 13s - loss: 16.0359 - acc: - ETA: 12s - loss: 16.0358 - ac - ETA: 11s - loss:  - ETA: 2s - l - ETA: 1s - loss: 16.0384 - ETA: 0s - l\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050 - loss: 16.0283 - - ETA: 11s - loss: 16.0385 - acc: 0.0 - ETA: 11s - loss: 16.0383 - acc: 0. - ETA: 11s - loss: 16.0377 - a -  - ETA: 7s - loss: 1 - ETA: 7s - loss: 16.03 - E\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050: 16.0482 - - ETA: 26s - loss: 16.0461 - acc: 0.00 - ETA: 26s - loss:  - ETA: 22s - loss: 16.0416 - acc: 0.004 - ETA: 22s  - ETA: 20s - los - ETA: 13s - loss: 16.0368  - ETA: 8s - loss: 16.0366 -\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050s: 16.054 - ETA: 29s  - ETA: 27s - loss: 16.0 - ETA: 26s - loss: 16.0579 - ETA: 25s  - ETA: 23s - loss: 16.0542 - acc: 0 - ETA: 23s - loss: 16.0551 - ac - ETA: 1s - loss: 16.03 - ETA: 0s - loss: 16.0372 - acc: 0.00 - ETA: 0s - l\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 37s 24ms/step - loss: 16.0375 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050s: 16.0368 - acc: 0 - ETA: 26s - loss: 16 - ETA: 25s - loss: 16.03 - ETA: 24s - loss: 16.0329 - acc: - ETA: 24s - loss: 16.035 - ETA: 23s - loss: 16 - ETA: 16s - lo - ETA: 14s - loss: 16.0307 - acc: 0. - ETA: 14s - loss: 16.0310 - a - ETA: 13s - loss: 16.0319 - acc: 0.005 - ETA: 13s - los - ETA: 12s - loss: 16.03 - ETA: 11s - loss: 16.0340 - acc: 0.005 - ETA: 10s -  - ETA: 9s - loss: 16.0347 - ETA: 9s - loss: 16.03 - ETA: 8s - loss: - - ETA: 1s - loss: 16.0375 - acc:  - ETA: 0s - l - ETA: 0s - loss: 16.0374 - acc: 0.\n",
      "10000/10000 [==============================] - 2s 223us/step\n",
      "Test loss: 16.0375048828125\n",
      "Test accuracy: 0.005\n",
      "Runtime: 1858.8441054821014\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opts = [('SGD', SGD()), ('RMSprop', RMSprop(lr=0.0001, decay=1e-6)), ('Adagrad', Adagrad()), ('Adadelta', Adadelta()), \n",
    "        ('Adam', Adam()), ('Adamax', Adamax()), ('Nadam', Nadam())]\n",
    "\n",
    "for name, opt in opts:\n",
    "    \n",
    "    print('Training ' + name + 'optimizer')\n",
    "    epochs = 50\n",
    "    num_classes = 200\n",
    "\n",
    "    num_predictions = 20\n",
    "    batch_size = 64\n",
    "\n",
    "    save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "    logs = \"logs/opt_100/\" + name\n",
    "    tensorboard = TensorBoard(log_dir=logs)\n",
    "\n",
    "    model_name = name+'keras_imagenet200_100base.h5'\n",
    "\n",
    "    start = time()\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', input_shape=train_images.shape[1:]))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Conv2D(128, (3, 3)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Conv2D(256, (3, 3)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Conv2D(512, (3, 3)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # Let's train the model using RMSprop\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "                featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "                samplewise_center=False,  # set each sample mean to 0\n",
    "                featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "                samplewise_std_normalization=False,  # divide each input by its std\n",
    "                zca_whitening=False,  # apply ZCA whitening\n",
    "                rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "                height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "                horizontal_flip=True,  # randomly flip images\n",
    "                vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(train_images)\n",
    "\n",
    "    model.fit_generator(datagen.flow(train_images, y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=len(train_images)/batch_size,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(val_images, y_test),\n",
    "                        callbacks=[tensorboard])\n",
    "    \n",
    "    # Save model and weights\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    model_path = os.path.join(save_dir, model_name)\n",
    "    model.save(model_path)\n",
    "\n",
    "    # Score trained model.\n",
    "    scores = model.evaluate(val_images, y_test, verbose=1)\n",
    "    end = time()\n",
    "    \n",
    "    print('Test loss:', scores[0])\n",
    "    print('Test accuracy:', scores[1])\n",
    "    print('Runtime:', str(end-start))\n",
    "    \n",
    "    print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training elu activation\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 35s 22ms/step - loss: 5.1833 - acc: 0.0137 - val_loss: 5.0204 - val_acc: 0.0317\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 4.9327 - acc: 0.0365 - val_loss: 4.7328 - val_acc: 0.0683\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 4.7518 - acc: 0.0559 - val_loss: 4.5724 - val_acc: 0.0761\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 4.5858 - acc: 0.0739 - val_loss: 4.4181 - val_acc: 0.0959\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 4.4525 - acc: 0.0913 - val_loss: 4.3197 - val_acc: 0.1116\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 4.3320 - acc: 0.1058 - val_loss: 4.1341 - val_acc: 0.1321\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 4.2220 - acc: 0.1197 - val_loss: 3.9974 - val_acc: 0.1539\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 4.1260 - acc: 0.1331 - val_loss: 3.9313 - val_acc: 0.1615\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 4.0468 - acc: 0.1452 - val_loss: 3.8805 - val_acc: 0.1637\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.9761 - acc: 0.1547 - val_loss: 3.7437 - val_acc: 0.1887\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.9185 - acc: 0.1644 - val_loss: 3.9832 - val_acc: 0.1630\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.8589 - acc: 0.1725 - val_loss: 3.8175 - val_acc: 0.1851\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.8045 - acc: 0.1803 - val_loss: 3.7102 - val_acc: 0.1950\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.7587 - acc: 0.1882 - val_loss: 3.5452 - val_acc: 0.2233\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.7124 - acc: 0.1939 - val_loss: 3.5217 - val_acc: 0.2279\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.6680 - acc: 0.2006 - val_loss: 3.5471 - val_acc: 0.2251\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.6216 - acc: 0.2091 - val_loss: 3.5097 - val_acc: 0.2254\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.5793 - acc: 0.2159 - val_loss: 3.4262 - val_acc: 0.2471\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.5420 - acc: 0.2202 - val_loss: 3.4549 - val_acc: 0.2372\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.5072 - acc: 0.2279 - val_loss: 3.2909 - val_acc: 0.2639\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.4640 - acc: 0.2347 - val_loss: 3.2791 - val_acc: 0.2696\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.4391 - acc: 0.2392 - val_loss: 3.2728 - val_acc: 0.2651\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.4003 - acc: 0.2448 - val_loss: 3.2297 - val_acc: 0.2781\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.3655 - acc: 0.2508 - val_loss: 3.2128 - val_acc: 0.2810\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.3330 - acc: 0.2580 - val_loss: 3.1491 - val_acc: 0.2937\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.3043 - acc: 0.2622 - val_loss: 3.1478 - val_acc: 0.2943\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.2702 - acc: 0.2657 - val_loss: 3.1297 - val_acc: 0.2981\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.2316 - acc: 0.2742 - val_loss: 3.0406 - val_acc: 0.3108\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.1987 - acc: 0.2794 - val_loss: 3.0801 - val_acc: 0.3039\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.1747 - acc: 0.2854 - val_loss: 3.0314 - val_acc: 0.3180\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.1425 - acc: 0.2904 - val_loss: 3.0013 - val_acc: 0.3200\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.1150 - acc: 0.2945 - val_loss: 2.9832 - val_acc: 0.3212\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.0874 - acc: 0.2999 - val_loss: 2.9623 - val_acc: 0.3239\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.0549 - acc: 0.3059 - val_loss: 2.9390 - val_acc: 0.3271\n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.0199 - acc: 0.3122 - val_loss: 2.9553 - val_acc: 0.3265\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 2.9926 - acc: 0.3153 - val_loss: 2.8697 - val_acc: 0.3429\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 2.9640 - acc: 0.3207 - val_loss: 2.9281 - val_acc: 0.3287\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 2.9400 - acc: 0.3247 - val_loss: 2.8650 - val_acc: 0.3440\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 2.9100 - acc: 0.3317 - val_loss: 2.9136 - val_acc: 0.3369\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 2.8847 - acc: 0.3347 - val_loss: 2.8725 - val_acc: 0.3426\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 2.8614 - acc: 0.3390 - val_loss: 2.8594 - val_acc: 0.3494\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 2.8237 - acc: 0.3463 - val_loss: 2.7902 - val_acc: 0.3530\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 2.8071 - acc: 0.3474 - val_loss: 2.7948 - val_acc: 0.3588\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 2.7762 - acc: 0.3529 - val_loss: 2.7314 - val_acc: 0.3683\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 2.7545 - acc: 0.3581 - val_loss: 2.7616 - val_acc: 0.3611\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 2.7274 - acc: 0.3614 - val_loss: 2.8028 - val_acc: 0.3552\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 2.7058 - acc: 0.3651 - val_loss: 2.7750 - val_acc: 0.3606\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 2.6813 - acc: 0.3701 - val_loss: 2.7641 - val_acc: 0.3676\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 2.6518 - acc: 0.3751 - val_loss: 2.7211 - val_acc: 0.3744\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 2.6249 - acc: 0.3822 - val_loss: 2.7276 - val_acc: 0.3725\n",
      "10000/10000 [==============================] - 2s 207us/step\n",
      "Test loss: 2.7276260360717774\n",
      "Test accuracy: 0.3725\n",
      "Runtime: 1590.7092776298523\n",
      "\n",
      "\n",
      "\n",
      "Training relu activation\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2977 - acc: 0.0062 - val_loss: 5.2950 - val_acc: 0.0151\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2657 - acc: 0.0089 - val_loss: 5.1657 - val_acc: 0.0112\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.1606 - acc: 0.0122 - val_loss: 5.0999 - val_acc: 0.0150\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.1130 - acc: 0.0151 - val_loss: 5.0608 - val_acc: 0.0214\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.0744 - acc: 0.0186 - val_loss: 4.9947 - val_acc: 0.0245\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.0343 - acc: 0.0219 - val_loss: 4.9665 - val_acc: 0.0311\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 4.9974 - acc: 0.0249 - val_loss: 4.9467 - val_acc: 0.0348\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 4.9479 - acc: 0.0304 - val_loss: 4.8586 - val_acc: 0.0427\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 4.8933 - acc: 0.0348 - val_loss: 4.7715 - val_acc: 0.0508\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 4.8094 - acc: 0.0442 - val_loss: 4.6696 - val_acc: 0.0591\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 4.7110 - acc: 0.0535 - val_loss: 4.5866 - val_acc: 0.0689\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 4.6288 - acc: 0.0624 - val_loss: 4.4538 - val_acc: 0.0844\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 4.5510 - acc: 0.0722 - val_loss: 4.3966 - val_acc: 0.0938\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 4.4761 - acc: 0.0816 - val_loss: 4.3267 - val_acc: 0.1020\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 4.4128 - acc: 0.0890 - val_loss: 4.3004 - val_acc: 0.1030\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 4.3422 - acc: 0.0992 - val_loss: 4.1568 - val_acc: 0.1246\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 4.2784 - acc: 0.1067 - val_loss: 4.1342 - val_acc: 0.1255\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 4.2157 - acc: 0.1170 - val_loss: 4.0184 - val_acc: 0.1446\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 4.1475 - acc: 0.1250 - val_loss: 3.9671 - val_acc: 0.1489\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 4.0852 - acc: 0.1340 - val_loss: 3.9566 - val_acc: 0.1520\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 4.0248 - acc: 0.1420 - val_loss: 3.8507 - val_acc: 0.1640\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.9703 - acc: 0.1495 - val_loss: 3.8578 - val_acc: 0.1702\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.9086 - acc: 0.1599 - val_loss: 3.7249 - val_acc: 0.1896\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.8594 - acc: 0.1684 - val_loss: 3.6670 - val_acc: 0.1960\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.8087 - acc: 0.1728 - val_loss: 3.6182 - val_acc: 0.2052\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.7630 - acc: 0.1796 - val_loss: 3.6240 - val_acc: 0.1994\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.7204 - acc: 0.1877 - val_loss: 3.5005 - val_acc: 0.2213\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.6765 - acc: 0.1963 - val_loss: 3.5031 - val_acc: 0.2211\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.6303 - acc: 0.2025 - val_loss: 3.5446 - val_acc: 0.2188\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.5902 - acc: 0.2088 - val_loss: 3.6835 - val_acc: 0.1965\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.5525 - acc: 0.2142 - val_loss: 3.4103 - val_acc: 0.2347\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.5156 - acc: 0.2195 - val_loss: 3.6281 - val_acc: 0.2074\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.4763 - acc: 0.2264 - val_loss: 3.3876 - val_acc: 0.2418\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.4434 - acc: 0.2331 - val_loss: 3.3626 - val_acc: 0.2436\n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.4142 - acc: 0.2366 - val_loss: 3.3706 - val_acc: 0.2473\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.3769 - acc: 0.2431 - val_loss: 3.3636 - val_acc: 0.2523\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.3470 - acc: 0.2494 - val_loss: 3.3175 - val_acc: 0.2602\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.3196 - acc: 0.2526 - val_loss: 3.3366 - val_acc: 0.2540\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.2822 - acc: 0.2589 - val_loss: 3.1504 - val_acc: 0.2846\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.2556 - acc: 0.2645 - val_loss: 3.1809 - val_acc: 0.2813\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.2233 - acc: 0.2686 - val_loss: 3.2106 - val_acc: 0.2755\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.1994 - acc: 0.2732 - val_loss: 3.2479 - val_acc: 0.2730\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.1629 - acc: 0.2770 - val_loss: 3.1344 - val_acc: 0.2948\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.1468 - acc: 0.2838 - val_loss: 3.2573 - val_acc: 0.2693\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.1204 - acc: 0.2866 - val_loss: 3.1659 - val_acc: 0.2867\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.0968 - acc: 0.2906 - val_loss: 3.0849 - val_acc: 0.3034\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.0637 - acc: 0.2963 - val_loss: 3.0589 - val_acc: 0.3035\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.0408 - acc: 0.2999 - val_loss: 3.0751 - val_acc: 0.3038\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 3.0193 - acc: 0.3024 - val_loss: 2.9942 - val_acc: 0.3127\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 2.9916 - acc: 0.3095 - val_loss: 3.0069 - val_acc: 0.3167\n",
      "10000/10000 [==============================] - 2s 206us/step\n",
      "Test loss: 3.0069093120574952\n",
      "Test accuracy: 0.3167\n",
      "Runtime: 1591.945300579071\n",
      "\n",
      "\n",
      "\n",
      "Training softplus activation\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.3530 - acc: 0.0052 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2997 - acc: 0.0047 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2990 - acc: 0.0047 - val_loss: 5.2983 - val_acc: 0.0044\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2988 - acc: 0.0052 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2987 - acc: 0.0050 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2987 - acc: 0.0045 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2986 - acc: 0.0049 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2985 - acc: 0.0047 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2984 - acc: 0.0049 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2985 - acc: 0.0052 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2985 - acc: 0.0049 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2984 - acc: 0.0047 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2985 - acc: 0.0046 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2985 - acc: 0.0047 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2985 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2984 - acc: 0.0048 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2985 - acc: 0.0047 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2984 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2985 - acc: 0.0048 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2984 - acc: 0.0043 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2984 - acc: 0.0046 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2985 - acc: 0.0042 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2984 - acc: 0.0045 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2984 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2984 - acc: 0.0045 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2984 - acc: 0.0046 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2984 - acc: 0.0043 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2984 - acc: 0.0046 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2984 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2985 - acc: 0.0043 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2984 - acc: 0.0045 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2984 - acc: 0.0042 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2984 - acc: 0.0043 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2984 - acc: 0.0048 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2984 - acc: 0.0045 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2984 - acc: 0.0046 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2984 - acc: 0.0045 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2984 - acc: 0.0046 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2984 - acc: 0.0041 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2984 - acc: 0.0042 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2984 - acc: 0.0049 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2984 - acc: 0.0047 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2984 - acc: 0.0045 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2985 - acc: 0.0045 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2984 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2984 - acc: 0.0045 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2984 - acc: 0.0045 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2984 - acc: 0.0042 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2984 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 32s 20ms/step - loss: 5.2984 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "10000/10000 [==============================] - 2s 211us/step\n",
      "Test loss: 5.298317443084716\n",
      "Test accuracy: 0.005\n",
      "Runtime: 1600.0740542411804\n",
      "\n",
      "\n",
      "\n",
      "Training softsign activation\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 5.2269 - acc: 0.0099 - val_loss: 5.1050 - val_acc: 0.0171\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 5.0810 - acc: 0.0189 - val_loss: 4.9458 - val_acc: 0.0370\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 4.9394 - acc: 0.0335 - val_loss: 4.8228 - val_acc: 0.0482\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 4.8294 - acc: 0.0448 - val_loss: 4.7498 - val_acc: 0.0563\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 4.7316 - acc: 0.0567 - val_loss: 4.6577 - val_acc: 0.0694\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 4.6472 - acc: 0.0661 - val_loss: 4.5253 - val_acc: 0.0825\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 4.5719 - acc: 0.0753 - val_loss: 4.4528 - val_acc: 0.0940\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 4.4981 - acc: 0.0832 - val_loss: 4.4177 - val_acc: 0.0925\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 4.4164 - acc: 0.0940 - val_loss: 4.2879 - val_acc: 0.1104\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 4.3449 - acc: 0.1016 - val_loss: 4.2514 - val_acc: 0.1179\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 4.2755 - acc: 0.1106 - val_loss: 4.1354 - val_acc: 0.1334\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 4.2060 - acc: 0.1207 - val_loss: 4.0917 - val_acc: 0.1368\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 4.1378 - acc: 0.1288 - val_loss: 4.0004 - val_acc: 0.1510\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 4.0773 - acc: 0.1369 - val_loss: 3.9611 - val_acc: 0.1529\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 4.0211 - acc: 0.1455 - val_loss: 3.9255 - val_acc: 0.1598\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.9763 - acc: 0.1520 - val_loss: 3.8230 - val_acc: 0.1751\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.9343 - acc: 0.1574 - val_loss: 3.8460 - val_acc: 0.1709\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.8951 - acc: 0.1630 - val_loss: 3.7540 - val_acc: 0.1828\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.8515 - acc: 0.1699 - val_loss: 3.8080 - val_acc: 0.1764\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.8177 - acc: 0.1761 - val_loss: 3.7747 - val_acc: 0.1814\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.7850 - acc: 0.1796 - val_loss: 3.7787 - val_acc: 0.1806\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.7553 - acc: 0.1841 - val_loss: 3.6547 - val_acc: 0.2015\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.7233 - acc: 0.1875 - val_loss: 3.6865 - val_acc: 0.1978\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.6964 - acc: 0.1939 - val_loss: 3.5612 - val_acc: 0.2180\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.6642 - acc: 0.1988 - val_loss: 3.5783 - val_acc: 0.2152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.6416 - acc: 0.2027 - val_loss: 3.5609 - val_acc: 0.2121\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.6165 - acc: 0.2057 - val_loss: 3.5496 - val_acc: 0.2169\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.5948 - acc: 0.2093 - val_loss: 3.4918 - val_acc: 0.2270\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.5743 - acc: 0.2137 - val_loss: 3.4910 - val_acc: 0.2244\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.5529 - acc: 0.2159 - val_loss: 3.4278 - val_acc: 0.2389\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.5318 - acc: 0.2193 - val_loss: 3.4306 - val_acc: 0.2390\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.5098 - acc: 0.2240 - val_loss: 3.4433 - val_acc: 0.2350\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.4926 - acc: 0.2262 - val_loss: 3.4107 - val_acc: 0.2387\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.4739 - acc: 0.2282 - val_loss: 3.3711 - val_acc: 0.2490\n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.4549 - acc: 0.2321 - val_loss: 3.4141 - val_acc: 0.2434\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.4420 - acc: 0.2351 - val_loss: 3.3466 - val_acc: 0.2517\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.4225 - acc: 0.2378 - val_loss: 3.3439 - val_acc: 0.2539\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.4037 - acc: 0.2429 - val_loss: 3.3333 - val_acc: 0.2575\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.3909 - acc: 0.2441 - val_loss: 3.3284 - val_acc: 0.2570\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.3725 - acc: 0.2470 - val_loss: 3.3519 - val_acc: 0.2568\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.3562 - acc: 0.2491 - val_loss: 3.2810 - val_acc: 0.2629\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.3436 - acc: 0.2524 - val_loss: 3.2855 - val_acc: 0.2640\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.3239 - acc: 0.2552 - val_loss: 3.2778 - val_acc: 0.2651\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.3088 - acc: 0.2589 - val_loss: 3.3153 - val_acc: 0.2561\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.2972 - acc: 0.2593 - val_loss: 3.2299 - val_acc: 0.2761\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.2871 - acc: 0.2625 - val_loss: 3.2126 - val_acc: 0.2771\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.2691 - acc: 0.2641 - val_loss: 3.2451 - val_acc: 0.2726\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.2581 - acc: 0.2673 - val_loss: 3.2404 - val_acc: 0.2776\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.2393 - acc: 0.2694 - val_loss: 3.2211 - val_acc: 0.2746\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 35s 23ms/step - loss: 3.2304 - acc: 0.2714 - val_loss: 3.1926 - val_acc: 0.2779\n",
      "10000/10000 [==============================] - 2s 229us/step\n",
      "Test loss: 3.1925647941589355\n",
      "Test accuracy: 0.2779\n",
      "Runtime: 1770.70454454422\n",
      "\n",
      "\n",
      "\n",
      "Training softmax activation\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 51s 33ms/step - loss: 5.2984 - acc: 0.0042 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0043 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0046 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0039 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0047 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0042 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0042 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0048 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0049 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0045 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0046 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0049 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 51s 33ms/step - loss: 5.2984 - acc: 0.0041 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0043 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0045 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0046 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0043 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0040 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0042 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0045 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0047 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0043 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0043 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0045 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0046 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0047 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0048 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0046 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0046 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0043 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0047 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0046 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0042 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0043 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 51s 33ms/step - loss: 5.2984 - acc: 0.0043 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 51s 32ms/step - loss: 5.2984 - acc: 0.0042 - val_loss: 5.2983 - val_acc: 0.0050\n",
      "10000/10000 [==============================] - 2s 249us/step\n",
      "Test loss: 5.2983174362182615\n",
      "Test accuracy: 0.005\n",
      "Runtime: 2542.6959092617035\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "activations = ['elu', 'relu', 'softplus', 'softsign', 'softmax']\n",
    "\n",
    "for act in activations:\n",
    "    \n",
    "    print('Training ' + act + ' activation')\n",
    "    epochs = 50\n",
    "    num_classes = 200\n",
    "\n",
    "    num_predictions = 20\n",
    "    batch_size = 64\n",
    "\n",
    "    save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "    logs = \"logs/activations/\" + act\n",
    "    tensorboard = TensorBoard(log_dir=logs)\n",
    "    #earlystopping = EarlyStopping(monitor='val_loss')\n",
    "\n",
    "    model_name = act+'_keras_imagenet200_100base.h5'\n",
    "\n",
    "    start = time()\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', input_shape=train_images.shape[1:]))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Conv2D(128, (3, 3)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Conv2D(256, (3, 3)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Conv2D(512, (3, 3)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # Let's train the model using RMSprop\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=SGD(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "                featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "                samplewise_center=False,  # set each sample mean to 0\n",
    "                featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "                samplewise_std_normalization=False,  # divide each input by its std\n",
    "                zca_whitening=False,  # apply ZCA whitening\n",
    "                rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "                height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "                horizontal_flip=True,  # randomly flip images\n",
    "                vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(train_images)\n",
    "\n",
    "    model.fit_generator(datagen.flow(train_images, y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=len(train_images)/batch_size,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(val_images, y_test),\n",
    "                        callbacks=[tensorboard])\n",
    "    \n",
    "    # Save model and weights\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    model_path = os.path.join(save_dir, model_name)\n",
    "    model.save(model_path)\n",
    "\n",
    "    # Score trained model.\n",
    "    scores = model.evaluate(val_images, y_test, verbose=1)\n",
    "    end = time()\n",
    "    \n",
    "    print('Test loss:', scores[0])\n",
    "    print('Test accuracy:', scores[1])\n",
    "    print('Runtime:', str(end-start))\n",
    "    \n",
    "    print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 32.0 batch size\n",
      "Epoch 1/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 5.0717 - acc: 0.0236 - val_loss: 4.7841 - val_acc: 0.0560\n",
      "Epoch 2/50\n",
      "3125/3125 [==============================] - 41s 13ms/step - loss: 4.7298 - acc: 0.0585 - val_loss: 4.4558 - val_acc: 0.0913\n",
      "Epoch 3/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 4.4747 - acc: 0.0874 - val_loss: 4.2086 - val_acc: 0.1255\n",
      "Epoch 4/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 4.2673 - acc: 0.1146 - val_loss: 4.0656 - val_acc: 0.1445\n",
      "Epoch 5/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 4.1261 - acc: 0.1351 - val_loss: 3.8248 - val_acc: 0.1811\n",
      "Epoch 6/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 4.0172 - acc: 0.1495 - val_loss: 3.8329 - val_acc: 0.1741\n",
      "Epoch 7/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 3.9256 - acc: 0.1623 - val_loss: 3.6853 - val_acc: 0.1974\n",
      "Epoch 8/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 3.8476 - acc: 0.1752 - val_loss: 3.6649 - val_acc: 0.2053\n",
      "Epoch 9/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 3.7740 - acc: 0.1850 - val_loss: 3.5515 - val_acc: 0.2141\n",
      "Epoch 10/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 3.7088 - acc: 0.1953 - val_loss: 3.5129 - val_acc: 0.2237\n",
      "Epoch 11/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 3.6543 - acc: 0.2044 - val_loss: 3.3820 - val_acc: 0.2440\n",
      "Epoch 12/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 3.6001 - acc: 0.2127 - val_loss: 3.3805 - val_acc: 0.2473\n",
      "Epoch 13/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 3.5477 - acc: 0.2221 - val_loss: 3.2915 - val_acc: 0.2621\n",
      "Epoch 14/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 3.4980 - acc: 0.2290 - val_loss: 3.3111 - val_acc: 0.2606\n",
      "Epoch 15/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 3.4530 - acc: 0.2369 - val_loss: 3.3153 - val_acc: 0.2585\n",
      "Epoch 16/50\n",
      "3125/3125 [==============================] - 41s 13ms/step - loss: 3.4031 - acc: 0.2458 - val_loss: 3.2240 - val_acc: 0.2726\n",
      "Epoch 17/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 3.3623 - acc: 0.2530 - val_loss: 3.1118 - val_acc: 0.2931\n",
      "Epoch 18/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 3.3120 - acc: 0.2626 - val_loss: 3.0952 - val_acc: 0.3025\n",
      "Epoch 19/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 3.2706 - acc: 0.2677 - val_loss: 3.0442 - val_acc: 0.3107\n",
      "Epoch 20/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 3.2285 - acc: 0.2751 - val_loss: 3.0283 - val_acc: 0.3152\n",
      "Epoch 21/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 3.1897 - acc: 0.2834 - val_loss: 3.0288 - val_acc: 0.3106\n",
      "Epoch 22/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 3.1468 - acc: 0.2886 - val_loss: 2.9814 - val_acc: 0.3187\n",
      "Epoch 23/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 3.1065 - acc: 0.2945 - val_loss: 2.9191 - val_acc: 0.3315\n",
      "Epoch 24/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 3.0681 - acc: 0.3022 - val_loss: 2.8783 - val_acc: 0.3388\n",
      "Epoch 25/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 3.0371 - acc: 0.3070 - val_loss: 2.8640 - val_acc: 0.3411\n",
      "Epoch 26/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 2.9968 - acc: 0.3133 - val_loss: 2.8421 - val_acc: 0.3493\n",
      "Epoch 27/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 2.9652 - acc: 0.3187 - val_loss: 2.8226 - val_acc: 0.3492\n",
      "Epoch 28/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 2.9256 - acc: 0.3260 - val_loss: 2.8124 - val_acc: 0.3519\n",
      "Epoch 29/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 2.9012 - acc: 0.3309 - val_loss: 2.7929 - val_acc: 0.3579\n",
      "Epoch 30/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 2.8610 - acc: 0.3376 - val_loss: 2.7897 - val_acc: 0.3597\n",
      "Epoch 31/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 2.8390 - acc: 0.3419 - val_loss: 2.7931 - val_acc: 0.3600\n",
      "Epoch 32/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 2.8016 - acc: 0.3474 - val_loss: 2.7455 - val_acc: 0.3662\n",
      "Epoch 33/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 2.7778 - acc: 0.3520 - val_loss: 2.7571 - val_acc: 0.3657\n",
      "Epoch 34/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 2.7487 - acc: 0.3570 - val_loss: 2.7257 - val_acc: 0.3757\n",
      "Epoch 35/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 2.7174 - acc: 0.3640 - val_loss: 2.7021 - val_acc: 0.3728\n",
      "Epoch 36/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 2.6913 - acc: 0.3683 - val_loss: 2.7222 - val_acc: 0.3700\n",
      "Epoch 37/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 2.6638 - acc: 0.3739 - val_loss: 2.7211 - val_acc: 0.3784\n",
      "Epoch 38/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 2.6448 - acc: 0.3769 - val_loss: 2.6519 - val_acc: 0.3884\n",
      "Epoch 39/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 2.6188 - acc: 0.3797 - val_loss: 2.6518 - val_acc: 0.3897\n",
      "Epoch 40/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 2.5984 - acc: 0.3853 - val_loss: 2.7436 - val_acc: 0.3730\n",
      "Epoch 41/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 2.5695 - acc: 0.3915 - val_loss: 2.6810 - val_acc: 0.3815\n",
      "Epoch 42/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 2.5478 - acc: 0.3929 - val_loss: 2.6949 - val_acc: 0.3844\n",
      "Epoch 43/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 2.5246 - acc: 0.3980 - val_loss: 2.6731 - val_acc: 0.3888\n",
      "Epoch 44/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 2.5078 - acc: 0.4007 - val_loss: 2.6333 - val_acc: 0.3937\n",
      "Epoch 45/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 2.4846 - acc: 0.4069 - val_loss: 2.7004 - val_acc: 0.3798\n",
      "Epoch 46/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 2.4518 - acc: 0.4099 - val_loss: 2.6634 - val_acc: 0.3945\n",
      "Epoch 47/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 2.4342 - acc: 0.4149 - val_loss: 2.6600 - val_acc: 0.3936\n",
      "Epoch 48/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 2.4142 - acc: 0.4171 - val_loss: 2.6813 - val_acc: 0.3948\n",
      "Epoch 49/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 2.3937 - acc: 0.4211 - val_loss: 2.6576 - val_acc: 0.3925\n",
      "Epoch 50/50\n",
      "3125/3125 [==============================] - 42s 13ms/step - loss: 2.3777 - acc: 0.4258 - val_loss: 2.6572 - val_acc: 0.3901\n",
      "10000/10000 [==============================] - 2s 228us/step\n",
      "Test loss: 2.657164493560791\n",
      "Test accuracy: 0.3901\n",
      "Runtime: 2085.029150247574\n",
      "\n",
      "\n",
      "\n",
      "Training 64 batch size\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 5.1845 - acc: 0.0133 - val_loss: 4.9995 - val_acc: 0.0286\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 4.9406 - acc: 0.0349 - val_loss: 4.7532 - val_acc: 0.0618\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 4.7604 - acc: 0.0558 - val_loss: 4.5646 - val_acc: 0.0809\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 4.6058 - acc: 0.0732 - val_loss: 4.3942 - val_acc: 0.0983\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 4.4622 - acc: 0.0896 - val_loss: 4.2519 - val_acc: 0.1209\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 4.3343 - acc: 0.1063 - val_loss: 4.1402 - val_acc: 0.1348\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 4.2221 - acc: 0.1197 - val_loss: 4.1474 - val_acc: 0.1300\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 4.1301 - acc: 0.1312 - val_loss: 3.9490 - val_acc: 0.1572\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 4.0521 - acc: 0.1428 - val_loss: 3.9271 - val_acc: 0.1644\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.9824 - acc: 0.1535 - val_loss: 3.8389 - val_acc: 0.1801\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.9145 - acc: 0.1634 - val_loss: 3.7866 - val_acc: 0.1835\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.8591 - acc: 0.1716 - val_loss: 3.6585 - val_acc: 0.1990\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.8122 - acc: 0.1790 - val_loss: 3.6169 - val_acc: 0.2076\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.7568 - acc: 0.1873 - val_loss: 3.5791 - val_acc: 0.2157\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.7075 - acc: 0.1934 - val_loss: 3.5451 - val_acc: 0.2232\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.6632 - acc: 0.2017 - val_loss: 3.4725 - val_acc: 0.2331\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.6209 - acc: 0.2086 - val_loss: 3.4675 - val_acc: 0.2356\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.5760 - acc: 0.2151 - val_loss: 3.3701 - val_acc: 0.2531\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.5418 - acc: 0.2205 - val_loss: 3.3319 - val_acc: 0.2610\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.5042 - acc: 0.2267 - val_loss: 3.3633 - val_acc: 0.2555\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.4651 - acc: 0.2327 - val_loss: 3.2415 - val_acc: 0.2759\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.4334 - acc: 0.2384 - val_loss: 3.3616 - val_acc: 0.2562\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.3923 - acc: 0.2473 - val_loss: 3.1494 - val_acc: 0.2935\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.3583 - acc: 0.2509 - val_loss: 3.1832 - val_acc: 0.2879\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.3298 - acc: 0.2555 - val_loss: 3.2247 - val_acc: 0.2815\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.2955 - acc: 0.2614 - val_loss: 3.1258 - val_acc: 0.2954\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.2626 - acc: 0.2697 - val_loss: 3.1067 - val_acc: 0.3022\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.2318 - acc: 0.2743 - val_loss: 3.1142 - val_acc: 0.2937\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.2001 - acc: 0.2808 - val_loss: 3.0506 - val_acc: 0.3134\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.1771 - acc: 0.2846 - val_loss: 2.9859 - val_acc: 0.3229\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.1345 - acc: 0.2930 - val_loss: 2.9952 - val_acc: 0.3195\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.1078 - acc: 0.2955 - val_loss: 2.9553 - val_acc: 0.3271\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.0779 - acc: 0.3006 - val_loss: 2.9503 - val_acc: 0.3236\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.0535 - acc: 0.3047 - val_loss: 2.9441 - val_acc: 0.3312\n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.0225 - acc: 0.3106 - val_loss: 2.9628 - val_acc: 0.3260\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 2.9914 - acc: 0.3148 - val_loss: 2.9173 - val_acc: 0.3288\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 2.9663 - acc: 0.3206 - val_loss: 2.9120 - val_acc: 0.3437\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 2.9345 - acc: 0.3254 - val_loss: 2.8974 - val_acc: 0.3428\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 2.9030 - acc: 0.3306 - val_loss: 2.8455 - val_acc: 0.3454\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 2.8825 - acc: 0.3341 - val_loss: 2.8079 - val_acc: 0.3510\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 2.8517 - acc: 0.3405 - val_loss: 2.8085 - val_acc: 0.3545\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 2.8248 - acc: 0.3435 - val_loss: 2.7916 - val_acc: 0.3540\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 2.8014 - acc: 0.3492 - val_loss: 2.7958 - val_acc: 0.3599\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 2.7749 - acc: 0.3552 - val_loss: 2.7999 - val_acc: 0.3574\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 2.7497 - acc: 0.3587 - val_loss: 2.7699 - val_acc: 0.3643\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 2.7164 - acc: 0.3646 - val_loss: 2.7320 - val_acc: 0.3669\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 2.6986 - acc: 0.3684 - val_loss: 2.7413 - val_acc: 0.3707\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 2.6737 - acc: 0.3704 - val_loss: 2.7222 - val_acc: 0.3735\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 2.6508 - acc: 0.3754 - val_loss: 2.7180 - val_acc: 0.3741\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 2.6322 - acc: 0.3797 - val_loss: 2.7422 - val_acc: 0.3709\n",
      "10000/10000 [==============================] - 2s 230us/step\n",
      "Test loss: 2.742211350631714\n",
      "Test accuracy: 0.3709\n",
      "Runtime: 1615.150042295456\n",
      "\n",
      "\n",
      "\n",
      "Training 128 batch size\n",
      "Epoch 1/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 5.2369 - acc: 0.0094 - val_loss: 5.1064 - val_acc: 0.0183\n",
      "Epoch 2/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 5.1024 - acc: 0.0192 - val_loss: 4.9703 - val_acc: 0.0391\n",
      "Epoch 3/50\n",
      "782/781 [==============================] - 26s 33ms/step - loss: 4.9742 - acc: 0.0315 - val_loss: 4.8205 - val_acc: 0.0564\n",
      "Epoch 4/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 4.8641 - acc: 0.0444 - val_loss: 4.7052 - val_acc: 0.0696\n",
      "Epoch 5/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 4.7731 - acc: 0.0551 - val_loss: 4.6612 - val_acc: 0.0713\n",
      "Epoch 6/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 4.6894 - acc: 0.0641 - val_loss: 4.5486 - val_acc: 0.0816\n",
      "Epoch 7/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 4.6011 - acc: 0.0738 - val_loss: 4.3934 - val_acc: 0.1050\n",
      "Epoch 8/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 4.5179 - acc: 0.0838 - val_loss: 4.3485 - val_acc: 0.1054\n",
      "Epoch 9/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 4.4413 - acc: 0.0924 - val_loss: 4.3648 - val_acc: 0.1014\n",
      "Epoch 10/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 4.3719 - acc: 0.1025 - val_loss: 4.2822 - val_acc: 0.1144\n",
      "Epoch 11/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 4.3023 - acc: 0.1110 - val_loss: 4.1933 - val_acc: 0.1249\n",
      "Epoch 12/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 4.2376 - acc: 0.1187 - val_loss: 4.1233 - val_acc: 0.1348\n",
      "Epoch 13/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 4.1794 - acc: 0.1258 - val_loss: 4.0460 - val_acc: 0.1458\n",
      "Epoch 14/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 4.1217 - acc: 0.1329 - val_loss: 4.1175 - val_acc: 0.1375\n",
      "Epoch 15/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 4.0727 - acc: 0.1403 - val_loss: 3.9547 - val_acc: 0.1608\n",
      "Epoch 16/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 4.0275 - acc: 0.1471 - val_loss: 3.8709 - val_acc: 0.1727\n",
      "Epoch 17/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 3.9864 - acc: 0.1527 - val_loss: 3.9427 - val_acc: 0.1560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 3.9516 - acc: 0.1588 - val_loss: 3.8648 - val_acc: 0.1702\n",
      "Epoch 19/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 3.9127 - acc: 0.1636 - val_loss: 3.7915 - val_acc: 0.1808\n",
      "Epoch 20/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 3.8727 - acc: 0.1698 - val_loss: 3.8207 - val_acc: 0.1851\n",
      "Epoch 21/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 3.8370 - acc: 0.1749 - val_loss: 3.8104 - val_acc: 0.1822\n",
      "Epoch 22/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 3.8047 - acc: 0.1800 - val_loss: 3.7731 - val_acc: 0.1825\n",
      "Epoch 23/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 3.7751 - acc: 0.1844 - val_loss: 3.7348 - val_acc: 0.1899\n",
      "Epoch 24/50\n",
      "782/781 [==============================] - 26s 33ms/step - loss: 3.7421 - acc: 0.1908 - val_loss: 3.6351 - val_acc: 0.2069\n",
      "Epoch 25/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 3.7164 - acc: 0.1925 - val_loss: 3.6231 - val_acc: 0.2126\n",
      "Epoch 26/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 3.6795 - acc: 0.1987 - val_loss: 3.5510 - val_acc: 0.2201\n",
      "Epoch 27/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 3.6530 - acc: 0.2026 - val_loss: 3.5239 - val_acc: 0.2267\n",
      "Epoch 28/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 3.6262 - acc: 0.2096 - val_loss: 3.5199 - val_acc: 0.2270\n",
      "Epoch 29/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 3.5945 - acc: 0.2123 - val_loss: 3.4472 - val_acc: 0.2414\n",
      "Epoch 30/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 3.5706 - acc: 0.2176 - val_loss: 3.4919 - val_acc: 0.2337\n",
      "Epoch 31/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 3.5479 - acc: 0.2214 - val_loss: 3.4499 - val_acc: 0.2420\n",
      "Epoch 32/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 3.5223 - acc: 0.2236 - val_loss: 3.3670 - val_acc: 0.2533\n",
      "Epoch 33/50\n",
      "782/781 [==============================] - 26s 33ms/step - loss: 3.4963 - acc: 0.2293 - val_loss: 3.4387 - val_acc: 0.2428\n",
      "Epoch 34/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 3.4733 - acc: 0.2326 - val_loss: 3.3349 - val_acc: 0.2568\n",
      "Epoch 35/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 3.4504 - acc: 0.2372 - val_loss: 3.3594 - val_acc: 0.2543\n",
      "Epoch 36/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 3.4285 - acc: 0.2393 - val_loss: 3.2820 - val_acc: 0.2701\n",
      "Epoch 37/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 3.4019 - acc: 0.2453 - val_loss: 3.3266 - val_acc: 0.2634\n",
      "Epoch 38/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 3.3837 - acc: 0.2474 - val_loss: 3.2329 - val_acc: 0.2767\n",
      "Epoch 39/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 3.3560 - acc: 0.2527 - val_loss: 3.2849 - val_acc: 0.2652\n",
      "Epoch 40/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 3.3392 - acc: 0.2539 - val_loss: 3.2809 - val_acc: 0.2656\n",
      "Epoch 41/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 3.3179 - acc: 0.2593 - val_loss: 3.1756 - val_acc: 0.2872\n",
      "Epoch 42/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 3.2906 - acc: 0.2616 - val_loss: 3.1834 - val_acc: 0.2898\n",
      "Epoch 43/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 3.2723 - acc: 0.2676 - val_loss: 3.1804 - val_acc: 0.2875\n",
      "Epoch 44/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 3.2454 - acc: 0.2717 - val_loss: 3.1354 - val_acc: 0.2936\n",
      "Epoch 45/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 3.2345 - acc: 0.2737 - val_loss: 3.1711 - val_acc: 0.2912\n",
      "Epoch 46/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 3.2122 - acc: 0.2789 - val_loss: 3.0910 - val_acc: 0.3004\n",
      "Epoch 47/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 3.1901 - acc: 0.2815 - val_loss: 3.1088 - val_acc: 0.3006\n",
      "Epoch 48/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 3.1693 - acc: 0.2860 - val_loss: 3.0590 - val_acc: 0.3144\n",
      "Epoch 49/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 3.1469 - acc: 0.2882 - val_loss: 3.0521 - val_acc: 0.3127\n",
      "Epoch 50/50\n",
      "782/781 [==============================] - 26s 34ms/step - loss: 3.1271 - acc: 0.2917 - val_loss: 3.0709 - val_acc: 0.3085\n",
      "10000/10000 [==============================] - 2s 231us/step\n",
      "Test loss: 3.0708569107055665\n",
      "Test accuracy: 0.3085\n",
      "Runtime: 1316.0907578468323\n",
      "\n",
      "\n",
      "\n",
      "Training 192 batch size\n",
      "Epoch 1/50\n",
      "521/520 [==============================] - 24s 46ms/step - loss: 5.2719 - acc: 0.0077 - val_loss: 5.1714 - val_acc: 0.0119\n",
      "Epoch 2/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 5.1521 - acc: 0.0131 - val_loss: 5.0751 - val_acc: 0.0240\n",
      "Epoch 3/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 5.0799 - acc: 0.0217 - val_loss: 4.9591 - val_acc: 0.0412\n",
      "Epoch 4/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 4.9750 - acc: 0.0319 - val_loss: 4.8369 - val_acc: 0.0547\n",
      "Epoch 5/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 4.8957 - acc: 0.0403 - val_loss: 4.7482 - val_acc: 0.0685\n",
      "Epoch 6/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 4.8266 - acc: 0.0481 - val_loss: 4.7085 - val_acc: 0.0662\n",
      "Epoch 7/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 4.7633 - acc: 0.0548 - val_loss: 4.6557 - val_acc: 0.0681\n",
      "Epoch 8/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 4.7079 - acc: 0.0619 - val_loss: 4.6104 - val_acc: 0.0748\n",
      "Epoch 9/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 4.6603 - acc: 0.0676 - val_loss: 4.5101 - val_acc: 0.0915\n",
      "Epoch 10/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 4.6062 - acc: 0.0735 - val_loss: 4.4642 - val_acc: 0.0964\n",
      "Epoch 11/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 4.5496 - acc: 0.0807 - val_loss: 4.3826 - val_acc: 0.1028\n",
      "Epoch 12/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 4.4918 - acc: 0.0863 - val_loss: 4.3566 - val_acc: 0.1049\n",
      "Epoch 13/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 4.4405 - acc: 0.0938 - val_loss: 4.2918 - val_acc: 0.1097\n",
      "Epoch 14/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 4.3900 - acc: 0.0990 - val_loss: 4.2266 - val_acc: 0.1184\n",
      "Epoch 15/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 4.3449 - acc: 0.1058 - val_loss: 4.2148 - val_acc: 0.1165\n",
      "Epoch 16/50\n",
      "521/520 [==============================] - 24s 46ms/step - loss: 4.3032 - acc: 0.1098 - val_loss: 4.1473 - val_acc: 0.1303\n",
      "Epoch 17/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 4.2638 - acc: 0.1153 - val_loss: 4.1878 - val_acc: 0.1233\n",
      "Epoch 18/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 4.2255 - acc: 0.1201 - val_loss: 4.0291 - val_acc: 0.1475\n",
      "Epoch 19/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 4.1818 - acc: 0.1249 - val_loss: 4.0334 - val_acc: 0.1420\n",
      "Epoch 20/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 4.1401 - acc: 0.1310 - val_loss: 3.9850 - val_acc: 0.1533\n",
      "Epoch 21/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 4.1005 - acc: 0.1372 - val_loss: 3.9634 - val_acc: 0.1580\n",
      "Epoch 22/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 4.0672 - acc: 0.1402 - val_loss: 3.9626 - val_acc: 0.1577\n",
      "Epoch 23/50\n",
      "521/520 [==============================] - 24s 46ms/step - loss: 4.0274 - acc: 0.1478 - val_loss: 3.8852 - val_acc: 0.1632\n",
      "Epoch 24/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 4.0025 - acc: 0.1493 - val_loss: 3.9090 - val_acc: 0.1599\n",
      "Epoch 25/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 3.9668 - acc: 0.1556 - val_loss: 3.8131 - val_acc: 0.1735\n",
      "Epoch 26/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 3.9406 - acc: 0.1596 - val_loss: 3.8413 - val_acc: 0.1753\n",
      "Epoch 27/50\n",
      "521/520 [==============================] - 24s 46ms/step - loss: 3.9157 - acc: 0.1641 - val_loss: 3.7257 - val_acc: 0.1913\n",
      "Epoch 28/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 3.8845 - acc: 0.1675 - val_loss: 3.7530 - val_acc: 0.1868\n",
      "Epoch 29/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 3.8596 - acc: 0.1700 - val_loss: 3.6862 - val_acc: 0.1950\n",
      "Epoch 30/50\n",
      "521/520 [==============================] - 24s 46ms/step - loss: 3.8367 - acc: 0.1731 - val_loss: 3.6756 - val_acc: 0.2009\n",
      "Epoch 31/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 3.8128 - acc: 0.1775 - val_loss: 3.6448 - val_acc: 0.2049\n",
      "Epoch 32/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 3.7850 - acc: 0.1819 - val_loss: 3.6365 - val_acc: 0.2035\n",
      "Epoch 33/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 3.7657 - acc: 0.1843 - val_loss: 3.5906 - val_acc: 0.2131\n",
      "Epoch 34/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 3.7432 - acc: 0.1888 - val_loss: 3.5790 - val_acc: 0.2155\n",
      "Epoch 35/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 3.7232 - acc: 0.1930 - val_loss: 3.5548 - val_acc: 0.2158\n",
      "Epoch 36/50\n",
      "521/520 [==============================] - 24s 46ms/step - loss: 3.6973 - acc: 0.1965 - val_loss: 3.5522 - val_acc: 0.2219\n",
      "Epoch 37/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 3.6840 - acc: 0.1972 - val_loss: 3.5147 - val_acc: 0.2280\n",
      "Epoch 38/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 3.6554 - acc: 0.2022 - val_loss: 3.4755 - val_acc: 0.2303\n",
      "Epoch 39/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 3.6399 - acc: 0.2041 - val_loss: 3.4891 - val_acc: 0.2323\n",
      "Epoch 40/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 3.6185 - acc: 0.2084 - val_loss: 3.4632 - val_acc: 0.2305\n",
      "Epoch 41/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 3.5973 - acc: 0.2112 - val_loss: 3.4908 - val_acc: 0.2324\n",
      "Epoch 42/50\n",
      "521/520 [==============================] - 24s 46ms/step - loss: 3.5808 - acc: 0.2146 - val_loss: 3.4667 - val_acc: 0.2289\n",
      "Epoch 43/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 3.5588 - acc: 0.2185 - val_loss: 3.3712 - val_acc: 0.2504\n",
      "Epoch 44/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 3.5426 - acc: 0.2210 - val_loss: 3.4014 - val_acc: 0.2375\n",
      "Epoch 45/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 3.5218 - acc: 0.2231 - val_loss: 3.4117 - val_acc: 0.2469\n",
      "Epoch 46/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 3.4989 - acc: 0.2275 - val_loss: 3.3314 - val_acc: 0.2595\n",
      "Epoch 47/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 3.4816 - acc: 0.2311 - val_loss: 3.3231 - val_acc: 0.2612\n",
      "Epoch 48/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 3.4662 - acc: 0.2335 - val_loss: 3.2743 - val_acc: 0.2713\n",
      "Epoch 49/50\n",
      "521/520 [==============================] - 24s 45ms/step - loss: 3.4508 - acc: 0.2355 - val_loss: 3.2836 - val_acc: 0.2687\n",
      "Epoch 50/50\n",
      "521/520 [==============================] - 24s 46ms/step - loss: 3.4325 - acc: 0.2381 - val_loss: 3.2878 - val_acc: 0.2633\n",
      "10000/10000 [==============================] - 2s 229us/step\n",
      "Test loss: 3.28779499130249\n",
      "Test accuracy: 0.2633\n",
      "Runtime: 1189.6476228237152\n",
      "\n",
      "\n",
      "\n",
      "Training 256 batch size\n",
      "Epoch 1/50\n",
      "391/390 [==============================] - 24s 62ms/step - loss: 5.2803 - acc: 0.0082 - val_loss: 5.2094 - val_acc: 0.0123\n",
      "Epoch 2/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 5.1744 - acc: 0.0125 - val_loss: 5.0998 - val_acc: 0.0225\n",
      "Epoch 3/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 5.1149 - acc: 0.0176 - val_loss: 5.0351 - val_acc: 0.0332\n",
      "Epoch 4/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 5.0417 - acc: 0.0253 - val_loss: 4.9209 - val_acc: 0.0446\n",
      "Epoch 5/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 4.9623 - acc: 0.0334 - val_loss: 4.8319 - val_acc: 0.0540\n",
      "Epoch 6/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 4.9058 - acc: 0.0375 - val_loss: 4.7722 - val_acc: 0.0616\n",
      "Epoch 7/50\n",
      "391/390 [==============================] - 23s 60ms/step - loss: 4.8514 - acc: 0.0453 - val_loss: 4.7390 - val_acc: 0.0661\n",
      "Epoch 8/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 4.8026 - acc: 0.0515 - val_loss: 4.7103 - val_acc: 0.0683\n",
      "Epoch 9/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 4.7590 - acc: 0.0556 - val_loss: 4.6209 - val_acc: 0.0779\n",
      "Epoch 10/50\n",
      "391/390 [==============================] - 23s 60ms/step - loss: 4.7174 - acc: 0.0607 - val_loss: 4.5926 - val_acc: 0.0800\n",
      "Epoch 11/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 4.6756 - acc: 0.0658 - val_loss: 4.5959 - val_acc: 0.0742\n",
      "Epoch 12/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 4.6340 - acc: 0.0698 - val_loss: 4.4941 - val_acc: 0.0882\n",
      "Epoch 13/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 4.5906 - acc: 0.0752 - val_loss: 4.4752 - val_acc: 0.0896\n",
      "Epoch 14/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 4.5467 - acc: 0.0793 - val_loss: 4.3801 - val_acc: 0.1029\n",
      "Epoch 15/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 4.4955 - acc: 0.0866 - val_loss: 4.3835 - val_acc: 0.0989\n",
      "Epoch 16/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 4.4518 - acc: 0.0908 - val_loss: 4.3007 - val_acc: 0.1088\n",
      "Epoch 17/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 4.4095 - acc: 0.0980 - val_loss: 4.3166 - val_acc: 0.1097\n",
      "Epoch 18/50\n",
      "391/390 [==============================] - 23s 60ms/step - loss: 4.3735 - acc: 0.1019 - val_loss: 4.2357 - val_acc: 0.1164\n",
      "Epoch 19/50\n",
      "391/390 [==============================] - 23s 60ms/step - loss: 4.3370 - acc: 0.1053 - val_loss: 4.1872 - val_acc: 0.1273\n",
      "Epoch 20/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 4.3039 - acc: 0.1096 - val_loss: 4.2242 - val_acc: 0.1189\n",
      "Epoch 21/50\n",
      "391/390 [==============================] - 23s 60ms/step - loss: 4.2706 - acc: 0.1140 - val_loss: 4.1322 - val_acc: 0.1344\n",
      "Epoch 22/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 4.2397 - acc: 0.1169 - val_loss: 4.1121 - val_acc: 0.1371\n",
      "Epoch 23/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 4.2058 - acc: 0.1225 - val_loss: 4.0950 - val_acc: 0.1375\n",
      "Epoch 24/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 4.1761 - acc: 0.1261 - val_loss: 4.1107 - val_acc: 0.1356\n",
      "Epoch 25/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 4.1470 - acc: 0.1306 - val_loss: 4.0036 - val_acc: 0.1502\n",
      "Epoch 26/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 4.1113 - acc: 0.1357 - val_loss: 3.9984 - val_acc: 0.1543\n",
      "Epoch 27/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 4.0813 - acc: 0.1382 - val_loss: 4.0162 - val_acc: 0.1479\n",
      "Epoch 28/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 4.0577 - acc: 0.1422 - val_loss: 3.9759 - val_acc: 0.1549\n",
      "Epoch 29/50\n",
      "391/390 [==============================] - 23s 60ms/step - loss: 4.0289 - acc: 0.1452 - val_loss: 3.8950 - val_acc: 0.1701\n",
      "Epoch 30/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 4.0053 - acc: 0.1491 - val_loss: 3.9271 - val_acc: 0.1636\n",
      "Epoch 31/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 3.9832 - acc: 0.1539 - val_loss: 3.8974 - val_acc: 0.1671\n",
      "Epoch 32/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 3.9571 - acc: 0.1575 - val_loss: 3.8219 - val_acc: 0.1810\n",
      "Epoch 33/50\n",
      "391/390 [==============================] - 23s 60ms/step - loss: 3.9352 - acc: 0.1609 - val_loss: 3.8190 - val_acc: 0.1786\n",
      "Epoch 34/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 3.9098 - acc: 0.1639 - val_loss: 3.7536 - val_acc: 0.1868\n",
      "Epoch 35/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 3.8863 - acc: 0.1672 - val_loss: 3.7516 - val_acc: 0.1920\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/390 [==============================] - 23s 60ms/step - loss: 3.8710 - acc: 0.1706 - val_loss: 3.7838 - val_acc: 0.1855\n",
      "Epoch 37/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 3.8470 - acc: 0.1725 - val_loss: 3.7597 - val_acc: 0.1936\n",
      "Epoch 38/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 3.8346 - acc: 0.1751 - val_loss: 3.6915 - val_acc: 0.1993\n",
      "Epoch 39/50\n",
      "391/390 [==============================] - 23s 60ms/step - loss: 3.8131 - acc: 0.1781 - val_loss: 3.6655 - val_acc: 0.2025\n",
      "Epoch 40/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 3.7898 - acc: 0.1803 - val_loss: 3.6567 - val_acc: 0.2018\n",
      "Epoch 41/50\n",
      "391/390 [==============================] - 23s 60ms/step - loss: 3.7768 - acc: 0.1842 - val_loss: 3.6105 - val_acc: 0.2085\n",
      "Epoch 42/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 3.7548 - acc: 0.1872 - val_loss: 3.5967 - val_acc: 0.2094\n",
      "Epoch 43/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 3.7373 - acc: 0.1886 - val_loss: 3.6297 - val_acc: 0.2033\n",
      "Epoch 44/50\n",
      "391/390 [==============================] - 23s 60ms/step - loss: 3.7169 - acc: 0.1935 - val_loss: 3.5557 - val_acc: 0.2230\n",
      "Epoch 45/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 3.6995 - acc: 0.1960 - val_loss: 3.5913 - val_acc: 0.2140\n",
      "Epoch 46/50\n",
      "391/390 [==============================] - 23s 60ms/step - loss: 3.6859 - acc: 0.1959 - val_loss: 3.5678 - val_acc: 0.2203\n",
      "Epoch 47/50\n",
      "391/390 [==============================] - 23s 60ms/step - loss: 3.6697 - acc: 0.2010 - val_loss: 3.5060 - val_acc: 0.2298\n",
      "Epoch 48/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 3.6549 - acc: 0.2020 - val_loss: 3.5355 - val_acc: 0.2237\n",
      "Epoch 49/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 3.6324 - acc: 0.2056 - val_loss: 3.5103 - val_acc: 0.2250\n",
      "Epoch 50/50\n",
      "391/390 [==============================] - 24s 60ms/step - loss: 3.6197 - acc: 0.2084 - val_loss: 3.4658 - val_acc: 0.2383\n",
      "10000/10000 [==============================] - 2s 223us/step\n",
      "Test loss: 3.4658179504394533\n",
      "Test accuracy: 0.2383\n",
      "Runtime: 1182.1382217407227\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "factor = [0.5, 1, 2, 3, 4]\n",
    "\n",
    "for f in factor:\n",
    "    \n",
    "    print('Training ' + str(f * 64) + ' batch size')\n",
    "    epochs = 50\n",
    "    num_classes = 200\n",
    "\n",
    "    num_predictions = 20\n",
    "    batch_size = int(64 * f)\n",
    "\n",
    "    save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "    logs = \"logs/batch_size/factor\"+str(f) \n",
    "    tensorboard = TensorBoard(log_dir=logs)\n",
    "    #earlystopping = EarlyStopping(monitor='val_loss')\n",
    "\n",
    "    model_name = \"batchsize\"+str(f)+'_keras_imagenet200_100base.h5'\n",
    "\n",
    "    start = time()\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', input_shape=train_images.shape[1:]))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Conv2D(128, (3, 3)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Conv2D(256, (3, 3)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Conv2D(512, (3, 3)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # Let's train the model using RMSprop\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=SGD(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "                featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "                samplewise_center=False,  # set each sample mean to 0\n",
    "                featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "                samplewise_std_normalization=False,  # divide each input by its std\n",
    "                zca_whitening=False,  # apply ZCA whitening\n",
    "                rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "                height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "                horizontal_flip=True,  # randomly flip images\n",
    "                vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(train_images)\n",
    "\n",
    "    model.fit_generator(datagen.flow(train_images, y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=len(train_images)/batch_size,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(val_images, y_test),\n",
    "                        callbacks=[tensorboard])\n",
    "    \n",
    "    # Save model and weights\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    model_path = os.path.join(save_dir, model_name)\n",
    "    model.save(model_path)\n",
    "\n",
    "    # Score trained model.\n",
    "    scores = model.evaluate(val_images, y_test, verbose=1)\n",
    "    end = time()\n",
    "    \n",
    "    print('Test loss:', scores[0])\n",
    "    print('Test accuracy:', scores[1])\n",
    "    print('Runtime:', str(end-start))\n",
    "    \n",
    "    print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture: Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 0.5 neurons\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 26s 16ms/step - loss: 5.2226 - acc: 0.0107 - val_loss: 5.0565 - val_acc: 0.0231\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 5.0295 - acc: 0.0264 - val_loss: 4.8572 - val_acc: 0.0508\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 4.8874 - acc: 0.0397 - val_loss: 4.7200 - val_acc: 0.0658\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 4.7603 - acc: 0.0528 - val_loss: 4.5763 - val_acc: 0.0818\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 4.6388 - acc: 0.0667 - val_loss: 4.4498 - val_acc: 0.0993\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 4.5243 - acc: 0.0814 - val_loss: 4.2980 - val_acc: 0.1126\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 4.4199 - acc: 0.0920 - val_loss: 4.2146 - val_acc: 0.1247\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 4.3266 - acc: 0.1024 - val_loss: 4.1279 - val_acc: 0.1294\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 4.2407 - acc: 0.1148 - val_loss: 4.1265 - val_acc: 0.1328\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 4.1674 - acc: 0.1248 - val_loss: 3.9505 - val_acc: 0.1542\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 4.1049 - acc: 0.1330 - val_loss: 3.8798 - val_acc: 0.1675\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 4.0460 - acc: 0.1418 - val_loss: 3.8455 - val_acc: 0.1728\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.9960 - acc: 0.1478 - val_loss: 3.8257 - val_acc: 0.1717\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.9489 - acc: 0.1536 - val_loss: 3.7663 - val_acc: 0.1835\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.8997 - acc: 0.1627 - val_loss: 3.6663 - val_acc: 0.2018\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.8567 - acc: 0.1690 - val_loss: 3.7309 - val_acc: 0.1905\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.8144 - acc: 0.1752 - val_loss: 3.6119 - val_acc: 0.2101\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.7785 - acc: 0.1790 - val_loss: 3.5890 - val_acc: 0.2090\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.7379 - acc: 0.1865 - val_loss: 3.5775 - val_acc: 0.2129\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.7069 - acc: 0.1926 - val_loss: 3.5025 - val_acc: 0.2253\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.6718 - acc: 0.1984 - val_loss: 3.6222 - val_acc: 0.2107\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.6377 - acc: 0.2034 - val_loss: 3.4560 - val_acc: 0.2389\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.6088 - acc: 0.2082 - val_loss: 3.4153 - val_acc: 0.2392\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.5740 - acc: 0.2137 - val_loss: 3.3843 - val_acc: 0.2458\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.5448 - acc: 0.2176 - val_loss: 3.3211 - val_acc: 0.2576\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.5165 - acc: 0.2218 - val_loss: 3.3674 - val_acc: 0.2503\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.4882 - acc: 0.2267 - val_loss: 3.2487 - val_acc: 0.2677\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.4604 - acc: 0.2327 - val_loss: 3.2093 - val_acc: 0.2793\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.4340 - acc: 0.2373 - val_loss: 3.2432 - val_acc: 0.2702\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.4082 - acc: 0.2427 - val_loss: 3.2095 - val_acc: 0.2759\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.3769 - acc: 0.2464 - val_loss: 3.1672 - val_acc: 0.2886\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.3534 - acc: 0.2495 - val_loss: 3.1459 - val_acc: 0.2915\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.3334 - acc: 0.2536 - val_loss: 3.1382 - val_acc: 0.2870\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.3030 - acc: 0.2579 - val_loss: 3.0747 - val_acc: 0.3054\n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.2791 - acc: 0.2624 - val_loss: 3.1064 - val_acc: 0.2954\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.2571 - acc: 0.2672 - val_loss: 3.1322 - val_acc: 0.2939\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.2403 - acc: 0.2697 - val_loss: 3.0625 - val_acc: 0.3049\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.2141 - acc: 0.2740 - val_loss: 3.0386 - val_acc: 0.3092\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.1920 - acc: 0.2790 - val_loss: 3.0487 - val_acc: 0.3081\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.1757 - acc: 0.2805 - val_loss: 2.9956 - val_acc: 0.3096\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.1483 - acc: 0.2863 - val_loss: 2.9721 - val_acc: 0.3209\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.1263 - acc: 0.2878 - val_loss: 2.9616 - val_acc: 0.3230\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.1111 - acc: 0.2926 - val_loss: 2.9661 - val_acc: 0.3242\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.0934 - acc: 0.2954 - val_loss: 2.9443 - val_acc: 0.3278\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.0727 - acc: 0.3002 - val_loss: 2.9302 - val_acc: 0.3265\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.0614 - acc: 0.3000 - val_loss: 2.9163 - val_acc: 0.3284\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.0420 - acc: 0.3035 - val_loss: 2.8917 - val_acc: 0.3368\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.0233 - acc: 0.3069 - val_loss: 2.9407 - val_acc: 0.3264\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 3.0041 - acc: 0.3109 - val_loss: 2.8931 - val_acc: 0.3355\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 25s 16ms/step - loss: 2.9913 - acc: 0.3135 - val_loss: 2.8771 - val_acc: 0.3369\n",
      "10000/10000 [==============================] - 2s 164us/step\n",
      "Test loss: 2.8771364974975584\n",
      "Test accuracy: 0.3369\n",
      "Runtime: 1260.4316952228546\n",
      "\n",
      "\n",
      "\n",
      "Training 1 neurons\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 5.1695 - acc: 0.0149 - val_loss: 4.9602 - val_acc: 0.0335\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 4.9329 - acc: 0.0362 - val_loss: 4.7606 - val_acc: 0.0608\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 4.7569 - acc: 0.0567 - val_loss: 4.5649 - val_acc: 0.0806\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 4.6009 - acc: 0.0740 - val_loss: 4.4279 - val_acc: 0.0974\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 4.4625 - acc: 0.0911 - val_loss: 4.2676 - val_acc: 0.1149\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 4.3438 - acc: 0.1055 - val_loss: 4.1332 - val_acc: 0.1363\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 4.2278 - acc: 0.1196 - val_loss: 4.0626 - val_acc: 0.1464\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 4.1348 - acc: 0.1323 - val_loss: 3.9473 - val_acc: 0.1637\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 4.0527 - acc: 0.1437 - val_loss: 3.8346 - val_acc: 0.1800\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 33s 21ms/step - loss: 3.9847 - acc: 0.1531 - val_loss: 3.9129 - val_acc: 0.1636\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.9246 - acc: 0.1628 - val_loss: 3.7422 - val_acc: 0.1886\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.8699 - acc: 0.1698 - val_loss: 3.7213 - val_acc: 0.1909\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.8118 - acc: 0.1784 - val_loss: 3.6017 - val_acc: 0.2120\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.7569 - acc: 0.1865 - val_loss: 3.5576 - val_acc: 0.2185\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.7102 - acc: 0.1961 - val_loss: 3.4902 - val_acc: 0.2284\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.6678 - acc: 0.1998 - val_loss: 3.4534 - val_acc: 0.2366\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.6270 - acc: 0.2073 - val_loss: 3.4390 - val_acc: 0.2365\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.5877 - acc: 0.2136 - val_loss: 3.3925 - val_acc: 0.2449\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.5424 - acc: 0.2223 - val_loss: 3.3279 - val_acc: 0.2565\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.5118 - acc: 0.2270 - val_loss: 3.3020 - val_acc: 0.2645\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.4718 - acc: 0.2330 - val_loss: 3.3400 - val_acc: 0.2577\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.4364 - acc: 0.2380 - val_loss: 3.2434 - val_acc: 0.2726\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.4008 - acc: 0.2439 - val_loss: 3.1900 - val_acc: 0.2848\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.3716 - acc: 0.2512 - val_loss: 3.2114 - val_acc: 0.2818\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.3343 - acc: 0.2560 - val_loss: 3.1961 - val_acc: 0.2880\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.2984 - acc: 0.2636 - val_loss: 3.1316 - val_acc: 0.2944\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.2693 - acc: 0.2672 - val_loss: 3.0731 - val_acc: 0.3060\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.2382 - acc: 0.2734 - val_loss: 3.0717 - val_acc: 0.3114\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.1969 - acc: 0.2793 - val_loss: 3.0713 - val_acc: 0.3084\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.1711 - acc: 0.2854 - val_loss: 3.0248 - val_acc: 0.3162\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.1470 - acc: 0.2894 - val_loss: 2.9827 - val_acc: 0.3207\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.1140 - acc: 0.2937 - val_loss: 2.9755 - val_acc: 0.3177\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.0816 - acc: 0.3015 - val_loss: 2.9409 - val_acc: 0.3291\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.0468 - acc: 0.3061 - val_loss: 2.9514 - val_acc: 0.3325\n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 3.0239 - acc: 0.3102 - val_loss: 2.9313 - val_acc: 0.3365\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 2.9891 - acc: 0.3143 - val_loss: 2.8907 - val_acc: 0.3400\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 2.9652 - acc: 0.3208 - val_loss: 2.8966 - val_acc: 0.3414\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 2.9339 - acc: 0.3272 - val_loss: 2.8579 - val_acc: 0.3475\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 2.9084 - acc: 0.3308 - val_loss: 2.8362 - val_acc: 0.3498\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 2.8780 - acc: 0.3356 - val_loss: 2.8077 - val_acc: 0.3503\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 2.8495 - acc: 0.3403 - val_loss: 2.8136 - val_acc: 0.3547\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 2.8210 - acc: 0.3451 - val_loss: 2.8140 - val_acc: 0.3571\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 2.7987 - acc: 0.3506 - val_loss: 2.7734 - val_acc: 0.3566\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 2.7664 - acc: 0.3564 - val_loss: 2.7894 - val_acc: 0.3603\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 2.7483 - acc: 0.3596 - val_loss: 2.7963 - val_acc: 0.3593\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 2.7194 - acc: 0.3646 - val_loss: 2.7126 - val_acc: 0.3758\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 2.6888 - acc: 0.3685 - val_loss: 2.7033 - val_acc: 0.3778\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 2.6694 - acc: 0.3732 - val_loss: 2.7572 - val_acc: 0.3643\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 2.6451 - acc: 0.3768 - val_loss: 2.7389 - val_acc: 0.3727\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 32s 21ms/step - loss: 2.6208 - acc: 0.3803 - val_loss: 2.7446 - val_acc: 0.3702\n",
      "10000/10000 [==============================] - 2s 232us/step\n",
      "Test loss: 2.744611309814453\n",
      "Test accuracy: 0.3702\n",
      "Runtime: 1629.467943429947\n",
      "\n",
      "\n",
      "\n",
      "Training 2 neurons\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 91s 58ms/step - loss: 5.1379 - acc: 0.0167 - val_loss: 4.8916 - val_acc: 0.0442\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 4.8490 - acc: 0.0457 - val_loss: 4.6497 - val_acc: 0.0786\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 4.6665 - acc: 0.0696 - val_loss: 4.4645 - val_acc: 0.0941\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 4.4847 - acc: 0.0902 - val_loss: 4.3037 - val_acc: 0.1115\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 4.3345 - acc: 0.1090 - val_loss: 4.2517 - val_acc: 0.1137\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 4.2063 - acc: 0.1254 - val_loss: 4.0713 - val_acc: 0.1424\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 4.0945 - acc: 0.1405 - val_loss: 3.9887 - val_acc: 0.1557\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 4.0090 - acc: 0.1521 - val_loss: 3.8335 - val_acc: 0.1781\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 3.9292 - acc: 0.1638 - val_loss: 3.7764 - val_acc: 0.1866\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 3.8586 - acc: 0.1753 - val_loss: 3.7557 - val_acc: 0.1928\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 3.7995 - acc: 0.1836 - val_loss: 3.5854 - val_acc: 0.2134\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 3.7422 - acc: 0.1923 - val_loss: 3.6106 - val_acc: 0.2186\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 3.6850 - acc: 0.2010 - val_loss: 3.5886 - val_acc: 0.2182\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 3.6337 - acc: 0.2090 - val_loss: 3.4622 - val_acc: 0.2407\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 3.5876 - acc: 0.2166 - val_loss: 3.3857 - val_acc: 0.2555\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 3.5362 - acc: 0.2258 - val_loss: 3.4137 - val_acc: 0.2495\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 3.4917 - acc: 0.2327 - val_loss: 3.4080 - val_acc: 0.2473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 3.4515 - acc: 0.2403 - val_loss: 3.2785 - val_acc: 0.2721\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 3.4093 - acc: 0.2475 - val_loss: 3.2564 - val_acc: 0.2717\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 3.3688 - acc: 0.2530 - val_loss: 3.2711 - val_acc: 0.2711\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 3.3283 - acc: 0.2596 - val_loss: 3.2450 - val_acc: 0.2777\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 3.2921 - acc: 0.2649 - val_loss: 3.1916 - val_acc: 0.2873\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 3.2530 - acc: 0.2734 - val_loss: 3.1145 - val_acc: 0.2976\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 3.2156 - acc: 0.2782 - val_loss: 3.0817 - val_acc: 0.3116\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 3.1771 - acc: 0.2860 - val_loss: 3.0432 - val_acc: 0.3166\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 3.1460 - acc: 0.2905 - val_loss: 3.0727 - val_acc: 0.3073\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 3.1086 - acc: 0.2994 - val_loss: 3.0234 - val_acc: 0.3206\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 3.0635 - acc: 0.3063 - val_loss: 2.9770 - val_acc: 0.3268\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 3.0324 - acc: 0.3091 - val_loss: 2.9928 - val_acc: 0.3237\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 2.9943 - acc: 0.3188 - val_loss: 2.9949 - val_acc: 0.3278\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 2.9652 - acc: 0.3222 - val_loss: 2.9766 - val_acc: 0.3320\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 2.9317 - acc: 0.3283 - val_loss: 2.9306 - val_acc: 0.3352\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 2.8935 - acc: 0.3341 - val_loss: 2.8655 - val_acc: 0.3470\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 2.8531 - acc: 0.3438 - val_loss: 2.9101 - val_acc: 0.3440\n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 2.8177 - acc: 0.3493 - val_loss: 2.9012 - val_acc: 0.3466\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 2.7905 - acc: 0.3533 - val_loss: 2.8752 - val_acc: 0.3509\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 2.7473 - acc: 0.3612 - val_loss: 2.8518 - val_acc: 0.3541\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 2.7115 - acc: 0.3686 - val_loss: 2.7786 - val_acc: 0.3645\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 2.6796 - acc: 0.3749 - val_loss: 2.7867 - val_acc: 0.3665\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 2.6450 - acc: 0.3790 - val_loss: 2.7747 - val_acc: 0.3664\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 2.6103 - acc: 0.3862 - val_loss: 2.7561 - val_acc: 0.3718\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 2.5729 - acc: 0.3948 - val_loss: 2.7845 - val_acc: 0.3667\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 2.5427 - acc: 0.3976 - val_loss: 2.7279 - val_acc: 0.3725\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 2.5026 - acc: 0.4067 - val_loss: 2.7115 - val_acc: 0.3773\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 2.4640 - acc: 0.4143 - val_loss: 2.7475 - val_acc: 0.3724\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 2.4306 - acc: 0.4178 - val_loss: 2.7293 - val_acc: 0.3843\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 2.4060 - acc: 0.4235 - val_loss: 2.7158 - val_acc: 0.3808\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 2.3735 - acc: 0.4290 - val_loss: 2.7397 - val_acc: 0.3822\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 2.3238 - acc: 0.4371 - val_loss: 2.6915 - val_acc: 0.3876\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 90s 57ms/step - loss: 2.2955 - acc: 0.4425 - val_loss: 2.7087 - val_acc: 0.3875\n",
      "10000/10000 [==============================] - 4s 427us/step\n",
      "Test loss: 2.7086598266601563\n",
      "Test accuracy: 0.3875\n",
      "Runtime: 4491.671914815903\n",
      "\n",
      "\n",
      "\n",
      "Training 3 neurons\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 188s 120ms/step - loss: 5.1080 - acc: 0.0192 - val_loss: 4.8668 - val_acc: 0.0443\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 4.8067 - acc: 0.0521 - val_loss: 4.5980 - val_acc: 0.0809\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 4.5997 - acc: 0.0764 - val_loss: 4.3748 - val_acc: 0.1065\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 4.4156 - acc: 0.1007 - val_loss: 4.2987 - val_acc: 0.1116\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 4.2687 - acc: 0.1190 - val_loss: 4.0909 - val_acc: 0.1435\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 4.1370 - acc: 0.1337 - val_loss: 4.0044 - val_acc: 0.1547\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 4.0371 - acc: 0.1527 - val_loss: 3.8556 - val_acc: 0.1817\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 3.9424 - acc: 0.1645 - val_loss: 3.9029 - val_acc: 0.1729\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 3.8640 - acc: 0.1762 - val_loss: 3.7112 - val_acc: 0.2008\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 3.7970 - acc: 0.1853 - val_loss: 3.6622 - val_acc: 0.2037\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 3.7284 - acc: 0.1949 - val_loss: 3.6210 - val_acc: 0.2176\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 3.6706 - acc: 0.2063 - val_loss: 3.5578 - val_acc: 0.2295\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 3.6120 - acc: 0.2145 - val_loss: 3.5249 - val_acc: 0.2391\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 3.5564 - acc: 0.2234 - val_loss: 3.3873 - val_acc: 0.2556\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 3.5126 - acc: 0.2305 - val_loss: 3.4077 - val_acc: 0.2525\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 3.4612 - acc: 0.2393 - val_loss: 3.3579 - val_acc: 0.2623\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 3.4082 - acc: 0.2481 - val_loss: 3.3088 - val_acc: 0.2702\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 3.3715 - acc: 0.2559 - val_loss: 3.3243 - val_acc: 0.2660\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 3.3281 - acc: 0.2605 - val_loss: 3.2215 - val_acc: 0.2785\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 3.2868 - acc: 0.2692 - val_loss: 3.2320 - val_acc: 0.2817\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 3.2447 - acc: 0.2763 - val_loss: 3.1751 - val_acc: 0.2905\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 3.2045 - acc: 0.2825 - val_loss: 3.0897 - val_acc: 0.3041\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 3.1593 - acc: 0.2920 - val_loss: 3.1340 - val_acc: 0.2985\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 3.1257 - acc: 0.2977 - val_loss: 3.0713 - val_acc: 0.3103\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 3.0871 - acc: 0.3028 - val_loss: 3.1007 - val_acc: 0.3079\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 3.0524 - acc: 0.3078 - val_loss: 3.0231 - val_acc: 0.3140\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 3.0178 - acc: 0.3138 - val_loss: 3.0026 - val_acc: 0.3348\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 2.9809 - acc: 0.3230 - val_loss: 3.0349 - val_acc: 0.3273\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 2.9372 - acc: 0.3309 - val_loss: 3.0154 - val_acc: 0.3212\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 2.9061 - acc: 0.3361 - val_loss: 3.0073 - val_acc: 0.3232\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 2.8700 - acc: 0.3442 - val_loss: 2.9422 - val_acc: 0.3430\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 2.8230 - acc: 0.3513 - val_loss: 2.9523 - val_acc: 0.3396\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 2.7897 - acc: 0.3572 - val_loss: 2.9193 - val_acc: 0.3417\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 2.7562 - acc: 0.3627 - val_loss: 2.8765 - val_acc: 0.3553\n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 2.7138 - acc: 0.3707 - val_loss: 2.8610 - val_acc: 0.3596\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 2.6756 - acc: 0.3782 - val_loss: 2.8372 - val_acc: 0.3596\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 2.6407 - acc: 0.3830 - val_loss: 2.8342 - val_acc: 0.3646\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 2.5979 - acc: 0.3893 - val_loss: 2.8251 - val_acc: 0.3667\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 2.5620 - acc: 0.3958 - val_loss: 2.8334 - val_acc: 0.3674\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 2.5245 - acc: 0.4051 - val_loss: 2.7538 - val_acc: 0.3775\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 2.4837 - acc: 0.4126 - val_loss: 2.8424 - val_acc: 0.3607\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 2.4416 - acc: 0.4185 - val_loss: 2.7840 - val_acc: 0.3732\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 2.4033 - acc: 0.4239 - val_loss: 2.7661 - val_acc: 0.3793\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 2.3664 - acc: 0.4331 - val_loss: 2.8203 - val_acc: 0.3748\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 2.3212 - acc: 0.4391 - val_loss: 2.8012 - val_acc: 0.3811\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 2.2944 - acc: 0.4478 - val_loss: 2.7615 - val_acc: 0.3810\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 2.2510 - acc: 0.4537 - val_loss: 2.7891 - val_acc: 0.3840\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 2.2017 - acc: 0.4623 - val_loss: 2.8278 - val_acc: 0.3896\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 2.1700 - acc: 0.4689 - val_loss: 2.7402 - val_acc: 0.3938\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 186s 119ms/step - loss: 2.1259 - acc: 0.4770 - val_loss: 2.8587 - val_acc: 0.3806\n",
      "10000/10000 [==============================] - 8s 757us/step\n",
      "Test loss: 2.858679216003418\n",
      "Test accuracy: 0.3806\n",
      "Runtime: 9300.539827823639\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "factor = [0.5, 1, 2, 3]\n",
    "\n",
    "for f in factor:\n",
    "    \n",
    "    print('Training ' + str(f) + ' neurons')\n",
    "    epochs = 50\n",
    "    num_classes = 200\n",
    "\n",
    "    num_predictions = 20\n",
    "    batch_size = 64\n",
    "\n",
    "    save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "    logs = \"logs/neurons/factor\" + str(f)\n",
    "    tensorboard = TensorBoard(log_dir=logs)\n",
    "    #earlystopping = EarlyStopping(monitor='val_loss')\n",
    "\n",
    "    model_name = 'neurons'+str(f)+'_keras_imagenet200_100base.h5'\n",
    "\n",
    "    start = time()\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(int(128*f), (3, 3), padding='same', input_shape=train_images.shape[1:]))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Conv2D(int(128*f), (3, 3)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(int(256*f), (3, 3), padding='same'))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Conv2D(int(256*f), (3, 3)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(int(512*f), (3, 3), padding='same'))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Conv2D(int(512*f), (3, 3)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(int(1024*f)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # Let's train the model using RMSprop\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=SGD(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "                featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "                samplewise_center=False,  # set each sample mean to 0\n",
    "                featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "                samplewise_std_normalization=False,  # divide each input by its std\n",
    "                zca_whitening=False,  # apply ZCA whitening\n",
    "                rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "                height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "                horizontal_flip=True,  # randomly flip images\n",
    "                vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(train_images)\n",
    "\n",
    "    model.fit_generator(datagen.flow(train_images, y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=len(train_images)/batch_size,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(val_images, y_test),\n",
    "                        callbacks=[tensorboard])\n",
    "    \n",
    "    # Save model and weights\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    model_path = os.path.join(save_dir, model_name)\n",
    "    model.save(model_path)\n",
    "\n",
    "    # Score trained model.\n",
    "    scores = model.evaluate(val_images, y_test, verbose=1)\n",
    "    end = time()\n",
    "    \n",
    "    print('Test loss:', scores[0])\n",
    "    print('Test accuracy:', scores[1])\n",
    "    print('Runtime:', str(end-start))\n",
    "    \n",
    "    print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture: Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 3 hidden layers 1024 neurons\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 5.2448 - acc: 0.0084 - val_loss: 5.1384 - val_acc: 0.0135\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 5.0902 - acc: 0.0190 - val_loss: 4.9090 - val_acc: 0.0417\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 4.9021 - acc: 0.0372 - val_loss: 4.7288 - val_acc: 0.0578\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 4.7566 - acc: 0.0520 - val_loss: 4.5934 - val_acc: 0.0669\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 4.6098 - acc: 0.0690 - val_loss: 4.4480 - val_acc: 0.0872\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 4.4591 - acc: 0.0858 - val_loss: 4.2706 - val_acc: 0.1085\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 4.3334 - acc: 0.1023 - val_loss: 4.1222 - val_acc: 0.1282\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 4.2215 - acc: 0.1166 - val_loss: 4.0343 - val_acc: 0.1419\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 4.1146 - acc: 0.1308 - val_loss: 3.9441 - val_acc: 0.1559\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 4.0157 - acc: 0.1450 - val_loss: 3.8260 - val_acc: 0.1765\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 3.9312 - acc: 0.1576 - val_loss: 3.7336 - val_acc: 0.1892\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 3.8542 - acc: 0.1666 - val_loss: 3.6585 - val_acc: 0.1985\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 3.7880 - acc: 0.1776 - val_loss: 3.5757 - val_acc: 0.2140\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 3.7197 - acc: 0.1885 - val_loss: 3.4919 - val_acc: 0.2250\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 3.6569 - acc: 0.1999 - val_loss: 3.5144 - val_acc: 0.2222\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 3.6044 - acc: 0.2079 - val_loss: 3.4275 - val_acc: 0.2409\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 3.5478 - acc: 0.2160 - val_loss: 3.3960 - val_acc: 0.2411\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 3.4978 - acc: 0.2243 - val_loss: 3.3547 - val_acc: 0.2529\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 3.4458 - acc: 0.2341 - val_loss: 3.2664 - val_acc: 0.2663\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 3.3963 - acc: 0.2407 - val_loss: 3.2920 - val_acc: 0.2655\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 3.3533 - acc: 0.2474 - val_loss: 3.2123 - val_acc: 0.2807\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 3.3074 - acc: 0.2569 - val_loss: 3.1914 - val_acc: 0.2800\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 3.2653 - acc: 0.2634 - val_loss: 3.1829 - val_acc: 0.2858\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 3.2219 - acc: 0.2716 - val_loss: 3.0875 - val_acc: 0.2985\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 3.1865 - acc: 0.2769 - val_loss: 3.1202 - val_acc: 0.2911\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 3.1468 - acc: 0.2863 - val_loss: 3.0697 - val_acc: 0.3015\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 3.1055 - acc: 0.2920 - val_loss: 3.0964 - val_acc: 0.3026\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 3.0725 - acc: 0.2985 - val_loss: 3.0065 - val_acc: 0.3169\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 3.0362 - acc: 0.3042 - val_loss: 2.9888 - val_acc: 0.3171\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 2.9987 - acc: 0.3102 - val_loss: 2.9071 - val_acc: 0.3364\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 2.9721 - acc: 0.3158 - val_loss: 2.9342 - val_acc: 0.3267\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 2.9289 - acc: 0.3238 - val_loss: 3.0135 - val_acc: 0.3195\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 2.8961 - acc: 0.3291 - val_loss: 2.8599 - val_acc: 0.3457\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 2.8711 - acc: 0.3339 - val_loss: 2.9618 - val_acc: 0.3259\n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 2.8394 - acc: 0.3394 - val_loss: 2.8717 - val_acc: 0.3446\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 2.8058 - acc: 0.3464 - val_loss: 2.8333 - val_acc: 0.3490\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 2.7676 - acc: 0.3519 - val_loss: 2.9015 - val_acc: 0.3388\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 2.7423 - acc: 0.3558 - val_loss: 2.8473 - val_acc: 0.3521\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 2.7105 - acc: 0.3615 - val_loss: 2.8332 - val_acc: 0.3547\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 2.6832 - acc: 0.3688 - val_loss: 2.7933 - val_acc: 0.3636\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 2.6557 - acc: 0.3729 - val_loss: 2.8025 - val_acc: 0.3619\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 2.6214 - acc: 0.3779 - val_loss: 2.7751 - val_acc: 0.3652\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 2.5911 - acc: 0.3837 - val_loss: 2.7900 - val_acc: 0.3639\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 2.5645 - acc: 0.3895 - val_loss: 2.7867 - val_acc: 0.3694\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 2.5332 - acc: 0.3939 - val_loss: 2.7574 - val_acc: 0.3687\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 2.5155 - acc: 0.3973 - val_loss: 2.7624 - val_acc: 0.3717\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 2.4901 - acc: 0.4034 - val_loss: 2.7293 - val_acc: 0.3794\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 2.4633 - acc: 0.4093 - val_loss: 2.7397 - val_acc: 0.3750\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 2.4284 - acc: 0.4139 - val_loss: 2.7773 - val_acc: 0.3728\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 40s 26ms/step - loss: 2.4049 - acc: 0.4167 - val_loss: 2.7543 - val_acc: 0.3759\n",
      "10000/10000 [==============================] - 2s 224us/step\n",
      "Test loss: 2.754299264526367\n",
      "Test accuracy: 0.3759\n",
      "Runtime: 2016.6608624458313\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training 3 hidden layers 1024 neurons')\n",
    "epochs = 50\n",
    "num_classes = 200\n",
    "\n",
    "num_predictions = 20\n",
    "batch_size = 64\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "logs = \"logs/layers/3_1024\"\n",
    "tensorboard = TensorBoard(log_dir=logs)\n",
    "#earlystopping = EarlyStopping(monitor='val_loss')\n",
    "\n",
    "model_name = '1024hiddenlayer_keras_imagenet200_100base.h5'\n",
    "\n",
    "start = time()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', input_shape=train_images.shape[1:]))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(512, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(1024, (3, 3), padding='same'))\n",
    "model.add(Activation('elu'))\n",
    "#model.add(Conv2D(1024, (3, 3)))\n",
    "#model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False)  # randomly flip images\n",
    "\n",
    "# Compute quantities required for feature-wise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(train_images)\n",
    "\n",
    "model.fit_generator(datagen.flow(train_images, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(train_images)/batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(val_images, y_test),\n",
    "                    callbacks=[tensorboard])\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(val_images, y_test, verbose=1)\n",
    "end = time()\n",
    "\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "print('Runtime:', str(end-start))\n",
    "\n",
    "print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 3 hidden layers 1024 & 2048 neurons\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 5.2341 - acc: 0.0092 - val_loss: 5.1013 - val_acc: 0.0195\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 5.0788 - acc: 0.0195 - val_loss: 4.8950 - val_acc: 0.0446\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 4.8670 - acc: 0.0402 - val_loss: 4.7467 - val_acc: 0.0525\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 4.7192 - acc: 0.0554 - val_loss: 4.5468 - val_acc: 0.0763\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 4.5735 - acc: 0.0733 - val_loss: 4.4107 - val_acc: 0.0899\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 4.4235 - acc: 0.0896 - val_loss: 4.2801 - val_acc: 0.1037\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 4.2890 - acc: 0.1085 - val_loss: 4.2306 - val_acc: 0.1186\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 4.1752 - acc: 0.1221 - val_loss: 3.9570 - val_acc: 0.1548\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 4.0669 - acc: 0.1373 - val_loss: 3.9507 - val_acc: 0.1535\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 3.9669 - acc: 0.1520 - val_loss: 3.7843 - val_acc: 0.1759\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 3.8810 - acc: 0.1645 - val_loss: 3.7970 - val_acc: 0.1817\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 3.7990 - acc: 0.1761 - val_loss: 3.6619 - val_acc: 0.2023\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 3.7289 - acc: 0.1876 - val_loss: 3.6042 - val_acc: 0.2099\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 3.6598 - acc: 0.1985 - val_loss: 3.5312 - val_acc: 0.2243\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 3.5964 - acc: 0.2090 - val_loss: 3.4632 - val_acc: 0.2360\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 3.5375 - acc: 0.2171 - val_loss: 3.4221 - val_acc: 0.2452\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 3.4782 - acc: 0.2275 - val_loss: 3.3271 - val_acc: 0.2587\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 3.4247 - acc: 0.2371 - val_loss: 3.2471 - val_acc: 0.2718\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 3.3773 - acc: 0.2449 - val_loss: 3.2656 - val_acc: 0.2713\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 3.3248 - acc: 0.2535 - val_loss: 3.2757 - val_acc: 0.2716\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 3.2779 - acc: 0.2597 - val_loss: 3.2887 - val_acc: 0.2697\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 3.2305 - acc: 0.2710 - val_loss: 3.2075 - val_acc: 0.2767\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 3.1928 - acc: 0.2764 - val_loss: 3.1408 - val_acc: 0.2922\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 3.1414 - acc: 0.2856 - val_loss: 3.0633 - val_acc: 0.3069\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 3.1041 - acc: 0.2904 - val_loss: 3.1035 - val_acc: 0.2982\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 3.0594 - acc: 0.3000 - val_loss: 3.0646 - val_acc: 0.3076\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 3.0234 - acc: 0.3057 - val_loss: 3.0249 - val_acc: 0.3150\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 2.9897 - acc: 0.3135 - val_loss: 3.0000 - val_acc: 0.3188\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 2.9490 - acc: 0.3197 - val_loss: 3.0018 - val_acc: 0.3241\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 2.9163 - acc: 0.3265 - val_loss: 2.9340 - val_acc: 0.3348\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 2.8779 - acc: 0.3328 - val_loss: 2.9256 - val_acc: 0.3391\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 2.8472 - acc: 0.3373 - val_loss: 2.9258 - val_acc: 0.3369\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 2.8078 - acc: 0.3455 - val_loss: 2.9347 - val_acc: 0.3378\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 2.7742 - acc: 0.3509 - val_loss: 2.8527 - val_acc: 0.3475\n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 2.7398 - acc: 0.3566 - val_loss: 2.9247 - val_acc: 0.3450\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 2.7064 - acc: 0.3642 - val_loss: 2.8839 - val_acc: 0.3442\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 2.6776 - acc: 0.3692 - val_loss: 2.8860 - val_acc: 0.3472\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 2.6424 - acc: 0.3751 - val_loss: 2.8296 - val_acc: 0.3611\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 2.6062 - acc: 0.3818 - val_loss: 2.8257 - val_acc: 0.3618\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 2.5907 - acc: 0.3856 - val_loss: 2.8073 - val_acc: 0.3629\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 2.5508 - acc: 0.3910 - val_loss: 2.7947 - val_acc: 0.3648\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 2.5189 - acc: 0.3976 - val_loss: 2.8240 - val_acc: 0.3658\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 2.4908 - acc: 0.4019 - val_loss: 2.7880 - val_acc: 0.3718\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 2.4544 - acc: 0.4082 - val_loss: 2.8853 - val_acc: 0.3590\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 2.4363 - acc: 0.4131 - val_loss: 2.7695 - val_acc: 0.3764\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 2.4006 - acc: 0.4207 - val_loss: 2.7843 - val_acc: 0.3781\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 2.3682 - acc: 0.4239 - val_loss: 2.7695 - val_acc: 0.3798\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 2.3453 - acc: 0.4292 - val_loss: 2.8238 - val_acc: 0.3716\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 2.3160 - acc: 0.4350 - val_loss: 2.7395 - val_acc: 0.3822\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 41s 26ms/step - loss: 2.2836 - acc: 0.4405 - val_loss: 2.7819 - val_acc: 0.3812\n",
      "10000/10000 [==============================] - 2s 237us/step\n",
      "Test loss: 2.78188376083374\n",
      "Test accuracy: 0.3812\n",
      "Runtime: 2033.3217902183533\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training 3 hidden layers 1024 & 2048 neurons')\n",
    "epochs = 50\n",
    "num_classes = 200\n",
    "\n",
    "num_predictions = 20\n",
    "batch_size = 64\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "logs = \"logs/layers/3_1024_2048\"\n",
    "tensorboard = TensorBoard(log_dir=logs)\n",
    "#earlystopping = EarlyStopping(monitor='val_loss')\n",
    "\n",
    "model_name = '1024_2048hiddenlayer_keras_imagenet200_100base.h5'\n",
    "\n",
    "start = time()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', input_shape=train_images.shape[1:]))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(512, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(1024, (3, 3), padding='same'))\n",
    "model.add(Activation('elu'))\n",
    "#model.add(Conv2D(1024, (3, 3)))\n",
    "#model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False)  # randomly flip images\n",
    "\n",
    "# Compute quantities required for feature-wise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(train_images)\n",
    "\n",
    "model.fit_generator(datagen.flow(train_images, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(train_images)/batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(val_images, y_test),\n",
    "                    callbacks=[tensorboard])\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(val_images, y_test, verbose=1)\n",
    "end = time()\n",
    "\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "print('Runtime:', str(end-start))\n",
    "\n",
    "print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training No Dropout\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 4.8530 - acc: 0.0494 - val_loss: 4.4731 - val_acc: 0.0891\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 4.3941 - acc: 0.1007 - val_loss: 4.4634 - val_acc: 0.0998\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 4.1499 - acc: 0.1306 - val_loss: 3.9271 - val_acc: 0.1655\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 3.9785 - acc: 0.1530 - val_loss: 3.9144 - val_acc: 0.1608\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 3.8350 - acc: 0.1761 - val_loss: 3.6556 - val_acc: 0.2010\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 3.7155 - acc: 0.1952 - val_loss: 3.6450 - val_acc: 0.2056\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 3.6131 - acc: 0.2098 - val_loss: 3.5921 - val_acc: 0.2151\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 3.5124 - acc: 0.2267 - val_loss: 3.4505 - val_acc: 0.2371\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 3.4205 - acc: 0.2417 - val_loss: 3.4914 - val_acc: 0.2343\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 3.3374 - acc: 0.2533 - val_loss: 3.4419 - val_acc: 0.2427\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 3.2562 - acc: 0.2696 - val_loss: 3.4584 - val_acc: 0.2434\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 3.1882 - acc: 0.2811 - val_loss: 3.2230 - val_acc: 0.2777\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 3.1178 - acc: 0.2939 - val_loss: 3.1610 - val_acc: 0.2911\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 3.0457 - acc: 0.3063 - val_loss: 3.1628 - val_acc: 0.2922\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 2.9784 - acc: 0.3168 - val_loss: 3.1472 - val_acc: 0.2949\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 2.9133 - acc: 0.3295 - val_loss: 3.0926 - val_acc: 0.3063\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 2.8469 - acc: 0.3404 - val_loss: 3.0861 - val_acc: 0.3081\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 2.7800 - acc: 0.3518 - val_loss: 2.9969 - val_acc: 0.3199\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 2.7131 - acc: 0.3624 - val_loss: 2.9752 - val_acc: 0.3252\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 2.6605 - acc: 0.3749 - val_loss: 3.0083 - val_acc: 0.3243\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 2.5880 - acc: 0.3888 - val_loss: 2.9643 - val_acc: 0.3377\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 2.5288 - acc: 0.3987 - val_loss: 3.0071 - val_acc: 0.3286\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 2.4727 - acc: 0.4094 - val_loss: 2.9214 - val_acc: 0.3361\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 2.4051 - acc: 0.4203 - val_loss: 2.9108 - val_acc: 0.3410\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 2.3483 - acc: 0.4333 - val_loss: 2.9017 - val_acc: 0.3495\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 2.2897 - acc: 0.4429 - val_loss: 2.9363 - val_acc: 0.3407\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 2.2355 - acc: 0.4527 - val_loss: 2.9551 - val_acc: 0.3404\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 2.1726 - acc: 0.4650 - val_loss: 2.9325 - val_acc: 0.3470\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 2.1108 - acc: 0.4772 - val_loss: 2.9433 - val_acc: 0.3450\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 2.0544 - acc: 0.4893 - val_loss: 2.9040 - val_acc: 0.3589\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 1.9940 - acc: 0.5003 - val_loss: 2.9101 - val_acc: 0.3543\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 1.9343 - acc: 0.5136 - val_loss: 2.9270 - val_acc: 0.3575\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 1.8704 - acc: 0.5259 - val_loss: 2.8840 - val_acc: 0.3656\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 1.8199 - acc: 0.5363 - val_loss: 2.9701 - val_acc: 0.3519\n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 1.7604 - acc: 0.5497 - val_loss: 2.9628 - val_acc: 0.3593\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 1.7031 - acc: 0.5589 - val_loss: 3.0181 - val_acc: 0.3484\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 1.6390 - acc: 0.5761 - val_loss: 2.9999 - val_acc: 0.3544\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 1.5833 - acc: 0.5865 - val_loss: 3.0229 - val_acc: 0.3552\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 1.5298 - acc: 0.5980 - val_loss: 3.0442 - val_acc: 0.3568\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 1.4713 - acc: 0.6111 - val_loss: 3.0838 - val_acc: 0.3586\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 1.4182 - acc: 0.6228 - val_loss: 3.1194 - val_acc: 0.3556\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 1.3634 - acc: 0.6347 - val_loss: 3.1506 - val_acc: 0.3471\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 1.3172 - acc: 0.6451 - val_loss: 3.1243 - val_acc: 0.3617\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 1.2579 - acc: 0.6585 - val_loss: 3.1706 - val_acc: 0.3541\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 1.2136 - acc: 0.6697 - val_loss: 3.2339 - val_acc: 0.3508\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 1.1641 - acc: 0.6796 - val_loss: 3.2066 - val_acc: 0.3498\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 1.1084 - acc: 0.6940 - val_loss: 3.2339 - val_acc: 0.3538\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 1.0631 - acc: 0.7039 - val_loss: 3.2712 - val_acc: 0.3529\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 1.0168 - acc: 0.7159 - val_loss: 3.3248 - val_acc: 0.3535\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 39s 25ms/step - loss: 0.9720 - acc: 0.7258 - val_loss: 3.3627 - val_acc: 0.3509\n",
      "10000/10000 [==============================] - 2s 235us/step\n",
      "Test loss: 3.3626818885803225\n",
      "Test accuracy: 0.3509\n",
      "Runtime: 1975.4218535423279\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training No Dropout')\n",
    "epochs = 50\n",
    "num_classes = 200\n",
    "\n",
    "num_predictions = 20\n",
    "batch_size = 64\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "logs = \"logs/layers/3_1024_2048\"\n",
    "tensorboard = TensorBoard(log_dir=logs)\n",
    "#earlystopping = EarlyStopping(monitor='val_loss')\n",
    "\n",
    "model_name = '1024_2048hiddenlayer_keras_imagenet200_100base.h5'\n",
    "\n",
    "start = time()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', input_shape=train_images.shape[1:]))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(512, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(1024, (3, 3), padding='same'))\n",
    "model.add(Activation('elu'))\n",
    "# model.add(Conv2D(1024, (3, 3)))\n",
    "# model.add(Activation('elu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False)  # randomly flip images\n",
    "\n",
    "# Compute quantities required for feature-wise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(train_images)\n",
    "\n",
    "model.fit_generator(datagen.flow(train_images, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(train_images)/batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(val_images, y_test),\n",
    "                    callbacks=[tensorboard])\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(val_images, y_test, verbose=1)\n",
    "end = time()\n",
    "\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "print('Runtime:', str(end-start))\n",
    "\n",
    "print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Batch Normalization\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 4.9609 - acc: 0.0501 - val_loss: 4.7505 - val_acc: 0.0674\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 4.3638 - acc: 0.1040 - val_loss: 4.0507 - val_acc: 0.1414\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 4.0660 - acc: 0.1423 - val_loss: 3.9561 - val_acc: 0.1588\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 3.8534 - acc: 0.1725 - val_loss: 3.6624 - val_acc: 0.2010\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 3.6907 - acc: 0.1960 - val_loss: 3.6921 - val_acc: 0.2008\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 3.5488 - acc: 0.2172 - val_loss: 3.6741 - val_acc: 0.2075\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 3.4209 - acc: 0.2393 - val_loss: 3.3190 - val_acc: 0.2589\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 3.3173 - acc: 0.2574 - val_loss: 3.3244 - val_acc: 0.2591\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 3.2107 - acc: 0.2762 - val_loss: 3.1805 - val_acc: 0.2843\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 3.1169 - acc: 0.2910 - val_loss: 3.2340 - val_acc: 0.2767\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 3.0281 - acc: 0.3067 - val_loss: 3.0972 - val_acc: 0.3035\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 2.9451 - acc: 0.3221 - val_loss: 3.0773 - val_acc: 0.3124\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 2.8656 - acc: 0.3375 - val_loss: 2.9732 - val_acc: 0.3276\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 2.7911 - acc: 0.3496 - val_loss: 2.9630 - val_acc: 0.3326\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 2.7146 - acc: 0.3638 - val_loss: 3.0688 - val_acc: 0.3185\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 2.6476 - acc: 0.3756 - val_loss: 2.9457 - val_acc: 0.3374\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 2.5911 - acc: 0.3849 - val_loss: 2.9775 - val_acc: 0.3326\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 2.5207 - acc: 0.4001 - val_loss: 2.8867 - val_acc: 0.3503\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 2.4602 - acc: 0.4116 - val_loss: 2.9444 - val_acc: 0.3384\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 2.3935 - acc: 0.4224 - val_loss: 2.9075 - val_acc: 0.3420\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 2.3374 - acc: 0.4361 - val_loss: 2.9365 - val_acc: 0.3443\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 2.2712 - acc: 0.4465 - val_loss: 2.9387 - val_acc: 0.3471\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 2.2156 - acc: 0.4579 - val_loss: 2.8746 - val_acc: 0.3594\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 2.1551 - acc: 0.4680 - val_loss: 2.9048 - val_acc: 0.3518\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 2.1037 - acc: 0.4803 - val_loss: 2.8892 - val_acc: 0.3585\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 2.0450 - acc: 0.4920 - val_loss: 2.9198 - val_acc: 0.3626\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 1.9816 - acc: 0.5043 - val_loss: 2.9115 - val_acc: 0.3530\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 1.9351 - acc: 0.5128 - val_loss: 2.9356 - val_acc: 0.3547\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 1.8805 - acc: 0.5249 - val_loss: 2.9389 - val_acc: 0.3580\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 1.8138 - acc: 0.5371 - val_loss: 3.0316 - val_acc: 0.3492\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 1.7642 - acc: 0.5471 - val_loss: 3.0034 - val_acc: 0.3571\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 1.6988 - acc: 0.5613 - val_loss: 2.9284 - val_acc: 0.3601\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 1.6615 - acc: 0.5680 - val_loss: 3.0527 - val_acc: 0.3617\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 1.5981 - acc: 0.5804 - val_loss: 2.9955 - val_acc: 0.3572\n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 1.5460 - acc: 0.5933 - val_loss: 3.0123 - val_acc: 0.3597\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 1.4993 - acc: 0.6016 - val_loss: 3.1023 - val_acc: 0.3558\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 1.4487 - acc: 0.6154 - val_loss: 3.1450 - val_acc: 0.3499\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 1.3978 - acc: 0.6265 - val_loss: 3.1565 - val_acc: 0.3603\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 1.3344 - acc: 0.6404 - val_loss: 3.1386 - val_acc: 0.3590\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 1.2974 - acc: 0.6473 - val_loss: 3.2599 - val_acc: 0.3483\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 1.2458 - acc: 0.6582 - val_loss: 3.2982 - val_acc: 0.3496\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 1.2044 - acc: 0.6692 - val_loss: 3.3172 - val_acc: 0.3492\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 1.1516 - acc: 0.6795 - val_loss: 3.3344 - val_acc: 0.3487\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 1.1063 - acc: 0.6927 - val_loss: 3.3644 - val_acc: 0.3495\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 1.0707 - acc: 0.7013 - val_loss: 3.4434 - val_acc: 0.3538\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 1.0263 - acc: 0.7099 - val_loss: 3.4696 - val_acc: 0.3473\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 0.9755 - acc: 0.7229 - val_loss: 3.5297 - val_acc: 0.3467\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 0.9401 - acc: 0.7315 - val_loss: 3.4799 - val_acc: 0.3548\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 0.8977 - acc: 0.7430 - val_loss: 3.5820 - val_acc: 0.3365\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 43s 28ms/step - loss: 0.8664 - acc: 0.7512 - val_loss: 3.5183 - val_acc: 0.3499\n",
      "10000/10000 [==============================] - 3s 252us/step\n",
      "Test loss: 3.5183061244964597\n",
      "Test accuracy: 0.3499\n",
      "Runtime: 2158.8243222236633\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training Batch Normalization')\n",
    "epochs = 50\n",
    "num_classes = 200\n",
    "\n",
    "num_predictions = 20\n",
    "batch_size = 64\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "logs = \"logs/layers/3_1024_2048\"\n",
    "tensorboard = TensorBoard(log_dir=logs)\n",
    "#earlystopping = EarlyStopping(monitor='val_loss')\n",
    "\n",
    "model_name = '1024_2048hiddenlayer_keras_imagenet200_100base.h5'\n",
    "\n",
    "start = time()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', input_shape=train_images.shape[1:]))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(512, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(1024, (3, 3), padding='same'))\n",
    "model.add(Activation('elu'))\n",
    "# model.add(Conv2D(1024, (3, 3)))\n",
    "# model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False)  # randomly flip images\n",
    "\n",
    "# Compute quantities required for feature-wise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(train_images)\n",
    "\n",
    "model.fit_generator(datagen.flow(train_images, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(train_images)/batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(val_images, y_test),\n",
    "                    callbacks=[tensorboard])\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(val_images, y_test, verbose=1)\n",
    "end = time()\n",
    "\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "print('Runtime:', str(end-start))\n",
    "\n",
    "print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Batch Normalization + Dropout\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 5.2775 - acc: 0.0280 - val_loss: 4.7801 - val_acc: 0.0525\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 4.7072 - acc: 0.0609 - val_loss: 4.5103 - val_acc: 0.0829\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 4.4249 - acc: 0.0901 - val_loss: 4.4473 - val_acc: 0.0890\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 4.2435 - acc: 0.1118 - val_loss: 4.0484 - val_acc: 0.1294\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 4.1094 - acc: 0.1306 - val_loss: 3.9311 - val_acc: 0.1570\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 4.0031 - acc: 0.1433 - val_loss: 3.8091 - val_acc: 0.1714\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.9011 - acc: 0.1596 - val_loss: 3.6980 - val_acc: 0.1893\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.8238 - acc: 0.1693 - val_loss: 3.6772 - val_acc: 0.1948\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.7469 - acc: 0.1827 - val_loss: 3.5961 - val_acc: 0.2045\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.6865 - acc: 0.1937 - val_loss: 3.4966 - val_acc: 0.2285\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.6266 - acc: 0.2031 - val_loss: 3.5740 - val_acc: 0.2127\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.5695 - acc: 0.2133 - val_loss: 3.3637 - val_acc: 0.2473\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.5201 - acc: 0.2198 - val_loss: 3.3290 - val_acc: 0.2504\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.4638 - acc: 0.2293 - val_loss: 3.4547 - val_acc: 0.2350\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.4144 - acc: 0.2384 - val_loss: 3.3307 - val_acc: 0.2545\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.3794 - acc: 0.2431 - val_loss: 3.3683 - val_acc: 0.2505\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.3316 - acc: 0.2524 - val_loss: 3.2301 - val_acc: 0.2746\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.2954 - acc: 0.2592 - val_loss: 3.1169 - val_acc: 0.2928\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.2480 - acc: 0.2678 - val_loss: 3.1079 - val_acc: 0.2903\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.2201 - acc: 0.2729 - val_loss: 3.0493 - val_acc: 0.3030\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.1797 - acc: 0.2798 - val_loss: 3.0487 - val_acc: 0.3047\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.1410 - acc: 0.2864 - val_loss: 3.1175 - val_acc: 0.2925\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.1141 - acc: 0.2908 - val_loss: 3.0446 - val_acc: 0.3049\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.0812 - acc: 0.2982 - val_loss: 2.9828 - val_acc: 0.3164\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.0542 - acc: 0.3016 - val_loss: 3.0666 - val_acc: 0.3036\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.0244 - acc: 0.3080 - val_loss: 2.9724 - val_acc: 0.3206\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.9857 - acc: 0.3149 - val_loss: 3.2481 - val_acc: 0.2718\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.9685 - acc: 0.3165 - val_loss: 2.8827 - val_acc: 0.3381\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.9404 - acc: 0.3242 - val_loss: 2.8666 - val_acc: 0.3398\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.9213 - acc: 0.3250 - val_loss: 2.8691 - val_acc: 0.3388\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.8876 - acc: 0.3336 - val_loss: 2.8789 - val_acc: 0.3363\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.8576 - acc: 0.3376 - val_loss: 2.8141 - val_acc: 0.3516\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.8473 - acc: 0.3409 - val_loss: 2.8396 - val_acc: 0.3425\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.8154 - acc: 0.3478 - val_loss: 2.8286 - val_acc: 0.3491\n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.7908 - acc: 0.3501 - val_loss: 2.7885 - val_acc: 0.3553\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.7616 - acc: 0.3553 - val_loss: 2.7826 - val_acc: 0.3600\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.7471 - acc: 0.3597 - val_loss: 2.7505 - val_acc: 0.3650\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.7147 - acc: 0.3662 - val_loss: 3.0286 - val_acc: 0.3147\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.6943 - acc: 0.3686 - val_loss: 2.7506 - val_acc: 0.3654\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.6721 - acc: 0.3711 - val_loss: 2.7742 - val_acc: 0.3613\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.6500 - acc: 0.3764 - val_loss: 2.9498 - val_acc: 0.3322\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.6316 - acc: 0.3797 - val_loss: 2.7917 - val_acc: 0.3574\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.6167 - acc: 0.3825 - val_loss: 2.7442 - val_acc: 0.3648\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.5919 - acc: 0.3863 - val_loss: 2.7359 - val_acc: 0.3726\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.5656 - acc: 0.3922 - val_loss: 2.6815 - val_acc: 0.3785\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.5419 - acc: 0.3966 - val_loss: 2.6969 - val_acc: 0.3757\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.5259 - acc: 0.3978 - val_loss: 2.6631 - val_acc: 0.3797\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.5043 - acc: 0.4025 - val_loss: 2.6896 - val_acc: 0.3779\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.4882 - acc: 0.4058 - val_loss: 2.6773 - val_acc: 0.3834\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.4623 - acc: 0.4122 - val_loss: 2.6694 - val_acc: 0.3801\n",
      "10000/10000 [==============================] - 3s 261us/step\n",
      "Test loss: 2.6694275394439697\n",
      "Test accuracy: 0.3801\n",
      "Runtime: 2227.875031709671\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training Batch Normalization + Dropout')\n",
    "epochs = 50\n",
    "num_classes = 200\n",
    "\n",
    "num_predictions = 20\n",
    "batch_size = 64\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "logs = \"logs/layers/dropout\"\n",
    "tensorboard = TensorBoard(log_dir=logs)\n",
    "#earlystopping = EarlyStopping(monitor='val_loss')\n",
    "\n",
    "model_name = '1024_2048hiddenlayer_keras_imagenet200_100base.h5'\n",
    "\n",
    "start = time()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', input_shape=train_images.shape[1:]))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(512, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(1024, (3, 3), padding='same'))\n",
    "model.add(Activation('elu'))\n",
    "# model.add(Conv2D(1024, (3, 3)))\n",
    "# model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False)  # randomly flip images\n",
    "\n",
    "# Compute quantities required for feature-wise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(train_images)\n",
    "\n",
    "model.fit_generator(datagen.flow(train_images, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(train_images)/batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(val_images, y_test),\n",
    "                    callbacks=[tensorboard])\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(val_images, y_test, verbose=1)\n",
    "end = time()\n",
    "\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "print('Runtime:', str(end-start))\n",
    "\n",
    "print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 0.0001 learning rate\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 6.8846 - acc: 0.0059 - val_loss: 5.2480 - val_acc: 0.0174\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 6.2971 - acc: 0.0087 - val_loss: 5.1117 - val_acc: 0.0249\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 6.0471 - acc: 0.0109 - val_loss: 5.0315 - val_acc: 0.0310\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 5.8862 - acc: 0.0124 - val_loss: 4.9780 - val_acc: 0.0386\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 5.7766 - acc: 0.0137 - val_loss: 4.9347 - val_acc: 0.0395\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 5.6904 - acc: 0.0148 - val_loss: 4.9049 - val_acc: 0.0428\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 5.6313 - acc: 0.0161 - val_loss: 4.8801 - val_acc: 0.0444\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 5.5792 - acc: 0.0175 - val_loss: 4.8604 - val_acc: 0.0457\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 5.5367 - acc: 0.0180 - val_loss: 4.8469 - val_acc: 0.0464\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 5.5015 - acc: 0.0192 - val_loss: 4.8265 - val_acc: 0.0495\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 5.4661 - acc: 0.0206 - val_loss: 4.8180 - val_acc: 0.0505\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 5.4278 - acc: 0.0212 - val_loss: 4.8096 - val_acc: 0.0499\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 5.4071 - acc: 0.0227 - val_loss: 4.7941 - val_acc: 0.0505\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 5.3820 - acc: 0.0220 - val_loss: 4.7935 - val_acc: 0.0511\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 5.3592 - acc: 0.0230 - val_loss: 4.7932 - val_acc: 0.0506\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 5.3352 - acc: 0.0243 - val_loss: 4.7808 - val_acc: 0.0503\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 5.3134 - acc: 0.0252 - val_loss: 4.7804 - val_acc: 0.0514\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 5.2972 - acc: 0.0252 - val_loss: 4.7696 - val_acc: 0.0520\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 5.2816 - acc: 0.0262 - val_loss: 4.7733 - val_acc: 0.0522\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 5.2549 - acc: 0.0267 - val_loss: 4.7656 - val_acc: 0.0538\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 5.2414 - acc: 0.0271 - val_loss: 4.7544 - val_acc: 0.0548\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 5.2425 - acc: 0.0275 - val_loss: 4.7554 - val_acc: 0.0544\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 5.2184 - acc: 0.0292 - val_loss: 4.7623 - val_acc: 0.0543\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 5.2002 - acc: 0.0298 - val_loss: 4.7468 - val_acc: 0.0546\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 5.1947 - acc: 0.0294 - val_loss: 4.7440 - val_acc: 0.0559\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 5.1829 - acc: 0.0309 - val_loss: 4.7635 - val_acc: 0.0538\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 5.1696 - acc: 0.0314 - val_loss: 4.7470 - val_acc: 0.0551\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 5.1604 - acc: 0.0305 - val_loss: 4.7396 - val_acc: 0.0558\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 45s 28ms/step - loss: 5.1378 - acc: 0.0331 - val_loss: 4.7409 - val_acc: 0.0550\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 5.1316 - acc: 0.0332 - val_loss: 4.7400 - val_acc: 0.0553\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 45s 28ms/step - loss: 5.1178 - acc: 0.0334 - val_loss: 4.7478 - val_acc: 0.0550\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 5.1104 - acc: 0.0335 - val_loss: 4.7442 - val_acc: 0.0545\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 5.1006 - acc: 0.0341 - val_loss: 4.7125 - val_acc: 0.0572\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 5.0848 - acc: 0.0349 - val_loss: 4.7512 - val_acc: 0.0548\n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 45s 28ms/step - loss: 5.0792 - acc: 0.0353 - val_loss: 4.7283 - val_acc: 0.0571\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 5.0717 - acc: 0.0363 - val_loss: 4.7384 - val_acc: 0.0548\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 45s 28ms/step - loss: 5.0524 - acc: 0.0372 - val_loss: 4.7366 - val_acc: 0.0552\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 45s 28ms/step - loss: 5.0487 - acc: 0.0373 - val_loss: 4.7485 - val_acc: 0.0539\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 45s 28ms/step - loss: 5.0380 - acc: 0.0385 - val_loss: 4.7341 - val_acc: 0.0556\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 5.0289 - acc: 0.0384 - val_loss: 4.7443 - val_acc: 0.0549\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 5.0159 - acc: 0.0398 - val_loss: 4.7154 - val_acc: 0.0577\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 5.0092 - acc: 0.0404 - val_loss: 4.7184 - val_acc: 0.0574\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.9946 - acc: 0.0417 - val_loss: 4.7524 - val_acc: 0.0534\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.9850 - acc: 0.0422 - val_loss: 4.7606 - val_acc: 0.0531\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.9787 - acc: 0.0418 - val_loss: 4.7767 - val_acc: 0.0530\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.9702 - acc: 0.0423 - val_loss: 4.7566 - val_acc: 0.0534\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.9615 - acc: 0.0437 - val_loss: 4.7235 - val_acc: 0.0581\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.9554 - acc: 0.0447 - val_loss: 4.7464 - val_acc: 0.0549\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.9465 - acc: 0.0450 - val_loss: 4.7253 - val_acc: 0.0574\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.9338 - acc: 0.0462 - val_loss: 4.7082 - val_acc: 0.0574\n",
      "10000/10000 [==============================] - 3s 259us/step\n",
      "Test loss: 4.708233075714111\n",
      "Test accuracy: 0.0574\n",
      "Runtime: 2231.0038397312164\n",
      "\n",
      "\n",
      "\n",
      "Training 0.0005 learning rate\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 6.1814 - acc: 0.0101 - val_loss: 4.9607 - val_acc: 0.0366\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 5.5964 - acc: 0.0170 - val_loss: 4.8442 - val_acc: 0.0463\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 5.4140 - acc: 0.0209 - val_loss: 4.8250 - val_acc: 0.0487\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 5.3136 - acc: 0.0243 - val_loss: 4.7988 - val_acc: 0.0494\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 5.2343 - acc: 0.0288 - val_loss: 4.7376 - val_acc: 0.0540\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 5.1704 - acc: 0.0313 - val_loss: 4.7439 - val_acc: 0.0545\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 5.1109 - acc: 0.0343 - val_loss: 4.7803 - val_acc: 0.0507\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 5.0705 - acc: 0.0361 - val_loss: 4.7330 - val_acc: 0.0516\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 5.0190 - acc: 0.0392 - val_loss: 4.6716 - val_acc: 0.0600\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.9792 - acc: 0.0425 - val_loss: 4.7106 - val_acc: 0.0560\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.9425 - acc: 0.0452 - val_loss: 4.7904 - val_acc: 0.0499\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.9062 - acc: 0.0487 - val_loss: 4.7229 - val_acc: 0.0577\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.8737 - acc: 0.0507 - val_loss: 4.7496 - val_acc: 0.0543\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.8472 - acc: 0.0538 - val_loss: 4.6329 - val_acc: 0.0676\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.8236 - acc: 0.0561 - val_loss: 4.6027 - val_acc: 0.0709\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.7918 - acc: 0.0586 - val_loss: 4.7100 - val_acc: 0.0658\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.7575 - acc: 0.0605 - val_loss: 4.7248 - val_acc: 0.0673\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.7327 - acc: 0.0638 - val_loss: 4.6901 - val_acc: 0.0695\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.6989 - acc: 0.0657 - val_loss: 4.8328 - val_acc: 0.0631\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.6743 - acc: 0.0678 - val_loss: 4.8163 - val_acc: 0.0673\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.6468 - acc: 0.0717 - val_loss: 4.5634 - val_acc: 0.0799\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.6237 - acc: 0.0746 - val_loss: 4.8201 - val_acc: 0.0666\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.5967 - acc: 0.0758 - val_loss: 4.6472 - val_acc: 0.0803\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.5765 - acc: 0.0784 - val_loss: 4.6970 - val_acc: 0.0742\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.5507 - acc: 0.0806 - val_loss: 4.5659 - val_acc: 0.0844\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.5291 - acc: 0.0831 - val_loss: 4.6018 - val_acc: 0.0831\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.5092 - acc: 0.0856 - val_loss: 4.4532 - val_acc: 0.0941\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.4926 - acc: 0.0876 - val_loss: 4.4518 - val_acc: 0.0923\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.4730 - acc: 0.0891 - val_loss: 4.6737 - val_acc: 0.0809\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.4519 - acc: 0.0928 - val_loss: 4.3928 - val_acc: 0.0994\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.4365 - acc: 0.0922 - val_loss: 4.4174 - val_acc: 0.0998\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.4177 - acc: 0.0953 - val_loss: 4.4444 - val_acc: 0.0975\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.4019 - acc: 0.0971 - val_loss: 4.4145 - val_acc: 0.0989\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.3862 - acc: 0.0984 - val_loss: 4.3890 - val_acc: 0.1015\n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.3710 - acc: 0.0990 - val_loss: 4.4166 - val_acc: 0.0997\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.3532 - acc: 0.1031 - val_loss: 4.3380 - val_acc: 0.1059\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.3343 - acc: 0.1033 - val_loss: 4.3878 - val_acc: 0.1039\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.3274 - acc: 0.1056 - val_loss: 4.6702 - val_acc: 0.0877\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.3107 - acc: 0.1068 - val_loss: 4.6156 - val_acc: 0.0921\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.3008 - acc: 0.1074 - val_loss: 4.5809 - val_acc: 0.0916\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.2820 - acc: 0.1095 - val_loss: 4.3908 - val_acc: 0.1027\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.2668 - acc: 0.1134 - val_loss: 4.3746 - val_acc: 0.1075\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.2555 - acc: 0.1133 - val_loss: 4.3266 - val_acc: 0.1143\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.2433 - acc: 0.1161 - val_loss: 4.3280 - val_acc: 0.1120\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.2284 - acc: 0.1177 - val_loss: 4.3067 - val_acc: 0.1163\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.2137 - acc: 0.1188 - val_loss: 4.2950 - val_acc: 0.1119\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.2019 - acc: 0.1208 - val_loss: 4.2336 - val_acc: 0.1198\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.1931 - acc: 0.1202 - val_loss: 4.3495 - val_acc: 0.1144\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.1820 - acc: 0.1225 - val_loss: 4.2833 - val_acc: 0.1202\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.1696 - acc: 0.1235 - val_loss: 4.2484 - val_acc: 0.1270\n",
      "10000/10000 [==============================] - 3s 261us/step\n",
      "Test loss: 4.248351219940186\n",
      "Test accuracy: 0.127\n",
      "Runtime: 2237.2477552890778\n",
      "\n",
      "\n",
      "\n",
      "Training 0.001 learning rate\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 5.9138 - acc: 0.0127 - val_loss: 4.8586 - val_acc: 0.0462\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 5.4020 - acc: 0.0217 - val_loss: 4.7657 - val_acc: 0.0540\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 5.2408 - acc: 0.0270 - val_loss: 4.7263 - val_acc: 0.0588\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 5.1228 - acc: 0.0334 - val_loss: 4.7401 - val_acc: 0.0542\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 5.0259 - acc: 0.0385 - val_loss: 4.7335 - val_acc: 0.0545\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.9503 - acc: 0.0441 - val_loss: 4.6852 - val_acc: 0.0619\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.8800 - acc: 0.0502 - val_loss: 4.6313 - val_acc: 0.0673\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.8164 - acc: 0.0549 - val_loss: 4.7128 - val_acc: 0.0632\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.7611 - acc: 0.0607 - val_loss: 4.5811 - val_acc: 0.0767\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.6970 - acc: 0.0676 - val_loss: 4.5579 - val_acc: 0.0792\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.6480 - acc: 0.0711 - val_loss: 4.6700 - val_acc: 0.0702\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.5933 - acc: 0.0762 - val_loss: 4.5992 - val_acc: 0.0774\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.5563 - acc: 0.0797 - val_loss: 4.4602 - val_acc: 0.0893\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.5114 - acc: 0.0844 - val_loss: 4.5277 - val_acc: 0.0818\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.4771 - acc: 0.0891 - val_loss: 4.4942 - val_acc: 0.0879\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.4401 - acc: 0.0931 - val_loss: 4.4213 - val_acc: 0.0943\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.4096 - acc: 0.0963 - val_loss: 4.4655 - val_acc: 0.0934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.3781 - acc: 0.1000 - val_loss: 4.5054 - val_acc: 0.0894\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.3481 - acc: 0.1024 - val_loss: 4.6072 - val_acc: 0.0812\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.3195 - acc: 0.1059 - val_loss: 4.3203 - val_acc: 0.1071\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.2952 - acc: 0.1102 - val_loss: 4.4340 - val_acc: 0.1013\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.2717 - acc: 0.1127 - val_loss: 4.2663 - val_acc: 0.1131\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.2422 - acc: 0.1159 - val_loss: 4.3105 - val_acc: 0.1106\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.2267 - acc: 0.1174 - val_loss: 4.1677 - val_acc: 0.1277\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.2014 - acc: 0.1204 - val_loss: 4.1851 - val_acc: 0.1241\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.1740 - acc: 0.1259 - val_loss: 4.2447 - val_acc: 0.1161\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.1616 - acc: 0.1252 - val_loss: 4.2053 - val_acc: 0.1235\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.1355 - acc: 0.1281 - val_loss: 4.2368 - val_acc: 0.1214\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.1165 - acc: 0.1314 - val_loss: 4.1776 - val_acc: 0.1273\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.0966 - acc: 0.1345 - val_loss: 4.1686 - val_acc: 0.1301\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.0796 - acc: 0.1360 - val_loss: 4.0309 - val_acc: 0.1423\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.0659 - acc: 0.1391 - val_loss: 3.9608 - val_acc: 0.1532\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.0467 - acc: 0.1417 - val_loss: 4.0052 - val_acc: 0.1510\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.0309 - acc: 0.1439 - val_loss: 4.0704 - val_acc: 0.1427\n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.0122 - acc: 0.1460 - val_loss: 4.0991 - val_acc: 0.1397\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.9989 - acc: 0.1478 - val_loss: 3.9991 - val_acc: 0.1529\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.9758 - acc: 0.1503 - val_loss: 3.8689 - val_acc: 0.1657\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.9677 - acc: 0.1510 - val_loss: 3.9240 - val_acc: 0.1630\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.9467 - acc: 0.1551 - val_loss: 3.9399 - val_acc: 0.1607\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.9382 - acc: 0.1561 - val_loss: 3.8168 - val_acc: 0.1758\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.9205 - acc: 0.1589 - val_loss: 3.8573 - val_acc: 0.1705\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.9086 - acc: 0.1594 - val_loss: 3.8932 - val_acc: 0.1663\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.8894 - acc: 0.1635 - val_loss: 3.7455 - val_acc: 0.1866\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.8786 - acc: 0.1644 - val_loss: 3.9173 - val_acc: 0.1653\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.8652 - acc: 0.1674 - val_loss: 3.8301 - val_acc: 0.1767\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.8587 - acc: 0.1687 - val_loss: 3.7845 - val_acc: 0.1810\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.8422 - acc: 0.1706 - val_loss: 3.7892 - val_acc: 0.1818\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.8261 - acc: 0.1735 - val_loss: 3.7897 - val_acc: 0.1848\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.8118 - acc: 0.1749 - val_loss: 3.7399 - val_acc: 0.1895\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.8037 - acc: 0.1781 - val_loss: 3.6743 - val_acc: 0.1950\n",
      "10000/10000 [==============================] - 3s 261us/step\n",
      "Test loss: 3.6743210212707518\n",
      "Test accuracy: 0.195\n",
      "Runtime: 2241.5704386234283\n",
      "\n",
      "\n",
      "\n",
      "Training 0.005 learning rate\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 5.4751 - acc: 0.0210 - val_loss: 4.8527 - val_acc: 0.0465\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.9805 - acc: 0.0415 - val_loss: 4.6516 - val_acc: 0.0695\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.7311 - acc: 0.0623 - val_loss: 4.6307 - val_acc: 0.0744\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.5343 - acc: 0.0801 - val_loss: 4.5619 - val_acc: 0.0822\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.3984 - acc: 0.0971 - val_loss: 4.2473 - val_acc: 0.1088\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.2881 - acc: 0.1094 - val_loss: 4.3418 - val_acc: 0.1106\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.1883 - acc: 0.1206 - val_loss: 4.0563 - val_acc: 0.1395\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.1153 - acc: 0.1299 - val_loss: 4.3026 - val_acc: 0.1164\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.0399 - acc: 0.1398 - val_loss: 3.9318 - val_acc: 0.1557\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.9776 - acc: 0.1484 - val_loss: 3.9432 - val_acc: 0.1569\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.9161 - acc: 0.1585 - val_loss: 3.8390 - val_acc: 0.1713\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.8631 - acc: 0.1659 - val_loss: 3.9081 - val_acc: 0.1731\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.8180 - acc: 0.1720 - val_loss: 3.6761 - val_acc: 0.1949\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.7740 - acc: 0.1798 - val_loss: 3.6065 - val_acc: 0.2066\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.7250 - acc: 0.1880 - val_loss: 3.5560 - val_acc: 0.2164\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.6923 - acc: 0.1923 - val_loss: 3.5509 - val_acc: 0.2196\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.6509 - acc: 0.1987 - val_loss: 3.5224 - val_acc: 0.2235\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.6201 - acc: 0.2041 - val_loss: 3.4112 - val_acc: 0.2366\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.5757 - acc: 0.2111 - val_loss: 3.5046 - val_acc: 0.2313\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.5466 - acc: 0.2166 - val_loss: 3.3949 - val_acc: 0.2426\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.5114 - acc: 0.2231 - val_loss: 3.4751 - val_acc: 0.2330\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.4878 - acc: 0.2273 - val_loss: 3.4917 - val_acc: 0.2339\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.4491 - acc: 0.2321 - val_loss: 3.3403 - val_acc: 0.2535\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.4190 - acc: 0.2371 - val_loss: 3.3453 - val_acc: 0.2544\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.3936 - acc: 0.2435 - val_loss: 3.2610 - val_acc: 0.2709\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.3628 - acc: 0.2476 - val_loss: 3.2257 - val_acc: 0.2759\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.3404 - acc: 0.2516 - val_loss: 3.1810 - val_acc: 0.2823\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.3080 - acc: 0.2564 - val_loss: 3.1535 - val_acc: 0.2902\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.2918 - acc: 0.2613 - val_loss: 3.1487 - val_acc: 0.2914\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.2656 - acc: 0.2633 - val_loss: 3.1067 - val_acc: 0.2956\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.2433 - acc: 0.2690 - val_loss: 3.1085 - val_acc: 0.2931\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.2157 - acc: 0.2736 - val_loss: 3.1512 - val_acc: 0.2929\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.1918 - acc: 0.2770 - val_loss: 3.0916 - val_acc: 0.2986\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.1694 - acc: 0.2837 - val_loss: 3.0212 - val_acc: 0.3148\n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.1497 - acc: 0.2847 - val_loss: 3.0047 - val_acc: 0.3164\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.1345 - acc: 0.2881 - val_loss: 3.0616 - val_acc: 0.3038\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.1139 - acc: 0.2913 - val_loss: 2.9946 - val_acc: 0.3164\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.0892 - acc: 0.2973 - val_loss: 2.9854 - val_acc: 0.3216\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.0645 - acc: 0.3008 - val_loss: 2.9526 - val_acc: 0.3263\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.0481 - acc: 0.3033 - val_loss: 3.0150 - val_acc: 0.3134\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.0327 - acc: 0.3056 - val_loss: 2.9669 - val_acc: 0.3226\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.0083 - acc: 0.3112 - val_loss: 2.9310 - val_acc: 0.3299\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.9977 - acc: 0.3129 - val_loss: 2.8866 - val_acc: 0.3354\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.9684 - acc: 0.3176 - val_loss: 2.9012 - val_acc: 0.3303\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.9553 - acc: 0.3193 - val_loss: 2.8774 - val_acc: 0.3379\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.9375 - acc: 0.3236 - val_loss: 2.8589 - val_acc: 0.3389\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.9209 - acc: 0.3245 - val_loss: 2.9018 - val_acc: 0.3384\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.9089 - acc: 0.3282 - val_loss: 2.8149 - val_acc: 0.3462\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.8810 - acc: 0.3339 - val_loss: 2.8349 - val_acc: 0.3519\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.8642 - acc: 0.3370 - val_loss: 2.8527 - val_acc: 0.3438\n",
      "10000/10000 [==============================] - 3s 270us/step\n",
      "Test loss: 2.852664840698242\n",
      "Test accuracy: 0.3438\n",
      "Runtime: 2249.748162508011\n",
      "\n",
      "\n",
      "\n",
      "Training 0.01 learning rate\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 5.3118 - acc: 0.0277 - val_loss: 4.6058 - val_acc: 0.0694\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.7457 - acc: 0.0589 - val_loss: 4.4313 - val_acc: 0.0880\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.4507 - acc: 0.0886 - val_loss: 4.5142 - val_acc: 0.0882\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.2573 - acc: 0.1113 - val_loss: 4.0518 - val_acc: 0.1374\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.1147 - acc: 0.1296 - val_loss: 4.3149 - val_acc: 0.1202\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.0067 - acc: 0.1436 - val_loss: 3.8686 - val_acc: 0.1692\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.9098 - acc: 0.1594 - val_loss: 3.7801 - val_acc: 0.1781\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.8339 - acc: 0.1703 - val_loss: 3.5777 - val_acc: 0.2075\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.7532 - acc: 0.1837 - val_loss: 3.7621 - val_acc: 0.1777\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.6915 - acc: 0.1929 - val_loss: 3.5210 - val_acc: 0.2172\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.6312 - acc: 0.2031 - val_loss: 3.4926 - val_acc: 0.2227\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.5742 - acc: 0.2114 - val_loss: 3.4174 - val_acc: 0.2378\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.5213 - acc: 0.2215 - val_loss: 3.5948 - val_acc: 0.2114\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.4731 - acc: 0.2290 - val_loss: 3.3172 - val_acc: 0.2530\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.4272 - acc: 0.2363 - val_loss: 3.2970 - val_acc: 0.2590\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.3907 - acc: 0.2450 - val_loss: 3.2169 - val_acc: 0.2751\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.3401 - acc: 0.2533 - val_loss: 3.2738 - val_acc: 0.2647\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.3064 - acc: 0.2591 - val_loss: 3.2117 - val_acc: 0.2808\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.2575 - acc: 0.2675 - val_loss: 3.0672 - val_acc: 0.2995\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.2256 - acc: 0.2709 - val_loss: 3.0369 - val_acc: 0.3111\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.1895 - acc: 0.2789 - val_loss: 3.0601 - val_acc: 0.3041\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.1564 - acc: 0.2870 - val_loss: 3.2261 - val_acc: 0.2745\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.1251 - acc: 0.2896 - val_loss: 2.9698 - val_acc: 0.3222\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.0919 - acc: 0.2968 - val_loss: 2.9556 - val_acc: 0.3239\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.0617 - acc: 0.3017 - val_loss: 3.0033 - val_acc: 0.3202\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.0289 - acc: 0.3056 - val_loss: 2.9402 - val_acc: 0.3234\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.0072 - acc: 0.3121 - val_loss: 2.9189 - val_acc: 0.3327\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.9736 - acc: 0.3195 - val_loss: 2.9084 - val_acc: 0.3348\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.9440 - acc: 0.3226 - val_loss: 2.8556 - val_acc: 0.3406\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.9171 - acc: 0.3267 - val_loss: 2.9037 - val_acc: 0.3367\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.8946 - acc: 0.3326 - val_loss: 2.8941 - val_acc: 0.3426\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.8683 - acc: 0.3346 - val_loss: 2.8141 - val_acc: 0.3541\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.8377 - acc: 0.3409 - val_loss: 2.8321 - val_acc: 0.3542\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.8206 - acc: 0.3440 - val_loss: 2.8234 - val_acc: 0.3510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.7912 - acc: 0.3504 - val_loss: 3.1726 - val_acc: 0.2883\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.7712 - acc: 0.3521 - val_loss: 2.8471 - val_acc: 0.3486\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.7414 - acc: 0.3583 - val_loss: 2.8220 - val_acc: 0.3482\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.7158 - acc: 0.3632 - val_loss: 2.7881 - val_acc: 0.3589\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.7046 - acc: 0.3672 - val_loss: 2.7099 - val_acc: 0.3681\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.6777 - acc: 0.3729 - val_loss: 2.7597 - val_acc: 0.3626\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.6531 - acc: 0.3763 - val_loss: 2.7665 - val_acc: 0.3623\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.6335 - acc: 0.3811 - val_loss: 2.8033 - val_acc: 0.3555\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.6415 - acc: 0.3771 - val_loss: 2.8377 - val_acc: 0.3483\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.5914 - acc: 0.3860 - val_loss: 2.7564 - val_acc: 0.3635\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.5753 - acc: 0.3905 - val_loss: 2.6774 - val_acc: 0.3795\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.5509 - acc: 0.3947 - val_loss: 2.7696 - val_acc: 0.3680\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.5319 - acc: 0.3973 - val_loss: 2.6835 - val_acc: 0.3827\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.5091 - acc: 0.4028 - val_loss: 2.6740 - val_acc: 0.3801\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.4933 - acc: 0.4057 - val_loss: 2.6420 - val_acc: 0.3866\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.4739 - acc: 0.4102 - val_loss: 2.6846 - val_acc: 0.3820\n",
      "10000/10000 [==============================] - 3s 272us/step\n",
      "Test loss: 2.684568845748901\n",
      "Test accuracy: 0.382\n",
      "Runtime: 2251.719801425934\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rates = [.0001, .0005, .001, .005, .01]\n",
    "\n",
    "for lr in rates:\n",
    "\n",
    "    print('Training ' + str(lr) + ' learning rate')\n",
    "    epochs = 50\n",
    "    num_classes = 200\n",
    "\n",
    "    num_predictions = 20\n",
    "    batch_size = 64\n",
    "\n",
    "    save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "    logs = \"logs/lr/\" + str(lr) \n",
    "    tensorboard = TensorBoard(log_dir=logs)\n",
    "    #earlystopping = EarlyStopping(monitor='val_loss')\n",
    "\n",
    "    model_name = str(lr) + 'lr_keras_imagenet200_100base.h5'\n",
    "\n",
    "    start = time()\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', input_shape=train_images.shape[1:]))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Conv2D(128, (3, 3)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Conv2D(256, (3, 3)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Conv2D(512, (3, 3)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(1024, (3, 3), padding='same'))\n",
    "    model.add(Activation('elu'))\n",
    "    # model.add(Conv2D(1024, (3, 3)))\n",
    "    # model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # Let's train the model using RMSprop\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=SGD(lr=lr),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "                featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "                samplewise_center=False,  # set each sample mean to 0\n",
    "                featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "                samplewise_std_normalization=False,  # divide each input by its std\n",
    "                zca_whitening=False,  # apply ZCA whitening\n",
    "                rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "                height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "                horizontal_flip=True,  # randomly flip images\n",
    "                vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(train_images)\n",
    "\n",
    "    model.fit_generator(datagen.flow(train_images, y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=len(train_images)/batch_size,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(val_images, y_test),\n",
    "                        callbacks=[tensorboard])\n",
    "\n",
    "    # Save model and weights\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    model_path = os.path.join(save_dir, model_name)\n",
    "    model.save(model_path)\n",
    "\n",
    "    # Score trained model.\n",
    "    scores = model.evaluate(val_images, y_test, verbose=1)\n",
    "    end = time()\n",
    "\n",
    "    print('Test loss:', scores[0])\n",
    "    print('Test accuracy:', scores[1])\n",
    "    print('Runtime:', str(end-start))\n",
    "\n",
    "    print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 0.02 learning rate\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 5.1556 - acc: 0.0333 - val_loss: 4.5296 - val_acc: 0.0788\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.4954 - acc: 0.0809 - val_loss: 4.4585 - val_acc: 0.0868\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.2194 - acc: 0.1138 - val_loss: 4.0087 - val_acc: 0.1386\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.0383 - acc: 0.1378 - val_loss: 3.8893 - val_acc: 0.1583\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.9026 - acc: 0.1581 - val_loss: 3.7797 - val_acc: 0.1859\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.7821 - acc: 0.1763 - val_loss: 3.6965 - val_acc: 0.2019\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.6827 - acc: 0.1911 - val_loss: 3.6622 - val_acc: 0.2036\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.5974 - acc: 0.2067 - val_loss: 3.4974 - val_acc: 0.2235\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.5265 - acc: 0.2187 - val_loss: 3.4052 - val_acc: 0.2387\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.4494 - acc: 0.2319 - val_loss: 3.2412 - val_acc: 0.2644\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.4091 - acc: 0.2387 - val_loss: 3.3430 - val_acc: 0.2557\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.3281 - acc: 0.2522 - val_loss: 3.3325 - val_acc: 0.2557\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.2737 - acc: 0.2634 - val_loss: 3.0612 - val_acc: 0.3041\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.2190 - acc: 0.2724 - val_loss: 3.1288 - val_acc: 0.2850\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.1706 - acc: 0.2810 - val_loss: 3.1787 - val_acc: 0.2762\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.1307 - acc: 0.2866 - val_loss: 3.0109 - val_acc: 0.3138\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.0806 - acc: 0.2964 - val_loss: 3.0293 - val_acc: 0.3066\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.0369 - acc: 0.3060 - val_loss: 3.2298 - val_acc: 0.2740\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.9988 - acc: 0.3117 - val_loss: 2.9055 - val_acc: 0.3351\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.9728 - acc: 0.3164 - val_loss: 2.9388 - val_acc: 0.3282\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.9286 - acc: 0.3248 - val_loss: 2.8414 - val_acc: 0.3423\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.8937 - acc: 0.3294 - val_loss: 2.8020 - val_acc: 0.3551\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.8659 - acc: 0.3356 - val_loss: 3.0190 - val_acc: 0.3117\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.8248 - acc: 0.3412 - val_loss: 2.8463 - val_acc: 0.3469\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.7951 - acc: 0.3485 - val_loss: 2.8130 - val_acc: 0.3503\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.7633 - acc: 0.3534 - val_loss: 3.7630 - val_acc: 0.2197\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.7418 - acc: 0.3593 - val_loss: 2.7882 - val_acc: 0.3593\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.7030 - acc: 0.3670 - val_loss: 2.8099 - val_acc: 0.3530\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.6747 - acc: 0.3715 - val_loss: 2.8495 - val_acc: 0.3472\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.6452 - acc: 0.3749 - val_loss: 3.5637 - val_acc: 0.2382\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.6350 - acc: 0.3801 - val_loss: 2.7899 - val_acc: 0.3562\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.5988 - acc: 0.3855 - val_loss: 2.7005 - val_acc: 0.3669\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.5707 - acc: 0.3913 - val_loss: 2.6807 - val_acc: 0.3765\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.5464 - acc: 0.3956 - val_loss: 2.7290 - val_acc: 0.3748\n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.5191 - acc: 0.4017 - val_loss: 2.7807 - val_acc: 0.3595\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.4968 - acc: 0.4033 - val_loss: 2.6906 - val_acc: 0.3786\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.4746 - acc: 0.4077 - val_loss: 2.6626 - val_acc: 0.3855\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.4435 - acc: 0.4137 - val_loss: 2.6918 - val_acc: 0.3769\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.4191 - acc: 0.4179 - val_loss: 2.6392 - val_acc: 0.3923\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.3981 - acc: 0.4227 - val_loss: 2.6672 - val_acc: 0.3827\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.3811 - acc: 0.4259 - val_loss: 2.6733 - val_acc: 0.3865\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.3558 - acc: 0.4317 - val_loss: 2.6382 - val_acc: 0.3916\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.3282 - acc: 0.4359 - val_loss: 2.7298 - val_acc: 0.3780\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.3143 - acc: 0.4370 - val_loss: 2.7291 - val_acc: 0.3772\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.2965 - acc: 0.4429 - val_loss: 2.7496 - val_acc: 0.3772\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.2845 - acc: 0.4440 - val_loss: 2.6717 - val_acc: 0.3870\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.2499 - acc: 0.4503 - val_loss: 2.5946 - val_acc: 0.3974\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.2256 - acc: 0.4543 - val_loss: 2.5978 - val_acc: 0.4017\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.2197 - acc: 0.4580 - val_loss: 2.6441 - val_acc: 0.3922\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.1851 - acc: 0.4613 - val_loss: 2.6947 - val_acc: 0.3888\n",
      "10000/10000 [==============================] - 3s 275us/step\n",
      "Test loss: 2.69471021232605\n",
      "Test accuracy: 0.3888\n",
      "Runtime: 2249.9953458309174\n",
      "\n",
      "\n",
      "\n",
      "Training 0.03 learning rate\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 5.0420 - acc: 0.0403 - val_loss: 4.6011 - val_acc: 0.0742\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.3737 - acc: 0.0942 - val_loss: 4.0531 - val_acc: 0.1304\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.1034 - acc: 0.1293 - val_loss: 4.1150 - val_acc: 0.1279\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.9193 - acc: 0.1551 - val_loss: 4.2419 - val_acc: 0.1148\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.7852 - acc: 0.1767 - val_loss: 3.6252 - val_acc: 0.1985\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.6660 - acc: 0.1958 - val_loss: 3.6201 - val_acc: 0.2047\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.5996 - acc: 0.2088 - val_loss: 3.5897 - val_acc: 0.2035\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.5243 - acc: 0.2225 - val_loss: 3.3589 - val_acc: 0.2399\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.4183 - acc: 0.2368 - val_loss: 3.2645 - val_acc: 0.2591\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.3267 - acc: 0.2537 - val_loss: 3.2059 - val_acc: 0.2754\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.2735 - acc: 0.2628 - val_loss: 3.1077 - val_acc: 0.2949\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.2126 - acc: 0.2747 - val_loss: 3.1662 - val_acc: 0.2841\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.1558 - acc: 0.2844 - val_loss: 3.1305 - val_acc: 0.2894\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.0944 - acc: 0.2954 - val_loss: 3.1098 - val_acc: 0.2992\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.0526 - acc: 0.3036 - val_loss: 3.9451 - val_acc: 0.1835\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.0110 - acc: 0.3109 - val_loss: 2.9333 - val_acc: 0.3247\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.9594 - acc: 0.3189 - val_loss: 2.9679 - val_acc: 0.3227\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.9187 - acc: 0.3275 - val_loss: 2.9713 - val_acc: 0.3225\n",
      "Epoch 19/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.8827 - acc: 0.3325 - val_loss: 3.0824 - val_acc: 0.3075\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.8412 - acc: 0.3433 - val_loss: 2.8229 - val_acc: 0.3502\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.8093 - acc: 0.3455 - val_loss: 2.8546 - val_acc: 0.3479\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.7970 - acc: 0.3500 - val_loss: 2.8525 - val_acc: 0.3489\n",
      "Epoch 23/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.7442 - acc: 0.3586 - val_loss: 2.8169 - val_acc: 0.3504\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.7180 - acc: 0.3624 - val_loss: 2.8571 - val_acc: 0.3489\n",
      "Epoch 25/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.6650 - acc: 0.3716 - val_loss: 2.7134 - val_acc: 0.3722\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.6516 - acc: 0.3755 - val_loss: 2.9165 - val_acc: 0.3373\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.6176 - acc: 0.3822 - val_loss: 2.7040 - val_acc: 0.3707\n",
      "Epoch 28/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.5880 - acc: 0.3872 - val_loss: 2.7886 - val_acc: 0.3619\n",
      "Epoch 29/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.5905 - acc: 0.3872 - val_loss: 2.8159 - val_acc: 0.3549\n",
      "Epoch 30/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.5310 - acc: 0.3980 - val_loss: 2.6672 - val_acc: 0.3842\n",
      "Epoch 31/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.5084 - acc: 0.4030 - val_loss: 2.6344 - val_acc: 0.3859\n",
      "Epoch 32/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.4807 - acc: 0.4082 - val_loss: 2.6397 - val_acc: 0.3862\n",
      "Epoch 33/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.4562 - acc: 0.4122 - val_loss: 2.6999 - val_acc: 0.3792\n",
      "Epoch 34/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.4289 - acc: 0.4170 - val_loss: 2.6478 - val_acc: 0.3847\n",
      "Epoch 35/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.4158 - acc: 0.4215 - val_loss: 2.7835 - val_acc: 0.3635\n",
      "Epoch 36/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.3953 - acc: 0.4238 - val_loss: 2.6351 - val_acc: 0.3891\n",
      "Epoch 37/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.3659 - acc: 0.4288 - val_loss: 2.6818 - val_acc: 0.3872\n",
      "Epoch 38/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.3485 - acc: 0.4333 - val_loss: 2.6272 - val_acc: 0.3906\n",
      "Epoch 39/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.3208 - acc: 0.4364 - val_loss: 2.6668 - val_acc: 0.3860\n",
      "Epoch 40/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.3037 - acc: 0.4433 - val_loss: 2.6238 - val_acc: 0.3993\n",
      "Epoch 41/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.2851 - acc: 0.4445 - val_loss: 2.5852 - val_acc: 0.4045\n",
      "Epoch 42/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.2616 - acc: 0.4496 - val_loss: 2.5889 - val_acc: 0.4010\n",
      "Epoch 43/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.2318 - acc: 0.4545 - val_loss: 2.6973 - val_acc: 0.3809\n",
      "Epoch 44/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.2063 - acc: 0.4614 - val_loss: 2.5813 - val_acc: 0.4082\n",
      "Epoch 45/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.1906 - acc: 0.4627 - val_loss: 2.6440 - val_acc: 0.3951\n",
      "Epoch 46/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.1714 - acc: 0.4668 - val_loss: 2.6236 - val_acc: 0.4035\n",
      "Epoch 47/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.1443 - acc: 0.4723 - val_loss: 2.6873 - val_acc: 0.3911\n",
      "Epoch 48/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.1278 - acc: 0.4760 - val_loss: 2.6107 - val_acc: 0.4050\n",
      "Epoch 49/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.1043 - acc: 0.4782 - val_loss: 2.6327 - val_acc: 0.4058\n",
      "Epoch 50/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 2.0957 - acc: 0.4811 - val_loss: 2.6565 - val_acc: 0.3981\n",
      "10000/10000 [==============================] - 3s 276us/step\n",
      "Test loss: 2.656517375946045\n",
      "Test accuracy: 0.3981\n",
      "Runtime: 2262.6054220199585\n",
      "\n",
      "\n",
      "\n",
      "Training 0.04 learning rate\n",
      "Epoch 1/50\n",
      "1563/1562 [==============================] - 46s 29ms/step - loss: 5.0231 - acc: 0.0424 - val_loss: 4.4551 - val_acc: 0.0797\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.3343 - acc: 0.0994 - val_loss: 4.2619 - val_acc: 0.1053\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 4.0547 - acc: 0.1341 - val_loss: 3.8000 - val_acc: 0.1732\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.8641 - acc: 0.1626 - val_loss: 3.6730 - val_acc: 0.1929\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.7253 - acc: 0.1843 - val_loss: 3.8873 - val_acc: 0.1610\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.6228 - acc: 0.2028 - val_loss: 3.4966 - val_acc: 0.2190\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.5074 - acc: 0.2230 - val_loss: 3.3104 - val_acc: 0.2516\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 3.4160 - acc: 0.2382 - val_loss: 3.3223 - val_acc: 0.2584\n",
      "Epoch 9/50\n",
      " 369/1562 [======>.......................] - ETA: 32s - loss: 3.3303 - acc: 0.2530"
     ]
    }
   ],
   "source": [
    "rates = [.02, .03, .04, .05]\n",
    "\n",
    "for lr in rates:\n",
    "\n",
    "    print('Training ' + str(lr) + ' learning rate')\n",
    "    epochs = 50\n",
    "    num_classes = 200\n",
    "\n",
    "    num_predictions = 20\n",
    "    batch_size = 64\n",
    "\n",
    "    save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "    logs = \"logs/lr/\" + str(lr) \n",
    "    tensorboard = TensorBoard(log_dir=logs)\n",
    "    #earlystopping = EarlyStopping(monitor='val_loss')\n",
    "\n",
    "    model_name = str(lr) + 'lr_keras_imagenet200_100base.h5'\n",
    "\n",
    "    start = time()\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', input_shape=train_images.shape[1:]))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Conv2D(128, (3, 3)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Conv2D(256, (3, 3)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Conv2D(512, (3, 3)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(1024, (3, 3), padding='same'))\n",
    "    model.add(Activation('elu'))\n",
    "    # model.add(Conv2D(1024, (3, 3)))\n",
    "    # model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # Let's train the model using RMSprop\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=SGD(lr=lr),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "                featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "                samplewise_center=False,  # set each sample mean to 0\n",
    "                featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "                samplewise_std_normalization=False,  # divide each input by its std\n",
    "                zca_whitening=False,  # apply ZCA whitening\n",
    "                rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "                height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "                horizontal_flip=True,  # randomly flip images\n",
    "                vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(train_images)\n",
    "\n",
    "    model.fit_generator(datagen.flow(train_images, y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=len(train_images)/batch_size,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(val_images, y_test),\n",
    "                        callbacks=[tensorboard])\n",
    "\n",
    "    # Save model and weights\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    model_path = os.path.join(save_dir, model_name)\n",
    "    model.save(model_path)\n",
    "\n",
    "    # Score trained model.\n",
    "    scores = model.evaluate(val_images, y_test, verbose=1)\n",
    "    end = time()\n",
    "\n",
    "    print('Test loss:', scores[0])\n",
    "    print('Test accuracy:', scores[1])\n",
    "    print('Runtime:', str(end-start))\n",
    "\n",
    "    print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training More Epochs\n",
      "Epoch 1/200\n",
      "1563/1562 [==============================] - 45s 29ms/step - loss: 5.2946 - acc: 0.0274 - val_loss: 4.7185 - val_acc: 0.0518\n",
      "Epoch 2/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 4.7171 - acc: 0.0594 - val_loss: 4.4492 - val_acc: 0.0876\n",
      "Epoch 3/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 4.4363 - acc: 0.0884 - val_loss: 4.5214 - val_acc: 0.0885\n",
      "Epoch 4/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 4.2532 - acc: 0.1093 - val_loss: 4.5071 - val_acc: 0.1028\n",
      "Epoch 5/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 4.1108 - acc: 0.1282 - val_loss: 3.9497 - val_acc: 0.1505\n",
      "Epoch 6/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.9991 - acc: 0.1436 - val_loss: 3.8062 - val_acc: 0.1735\n",
      "Epoch 7/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.9057 - acc: 0.1562 - val_loss: 3.8883 - val_acc: 0.1665\n",
      "Epoch 8/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.8198 - acc: 0.1691 - val_loss: 3.6301 - val_acc: 0.2006\n",
      "Epoch 9/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.7486 - acc: 0.1821 - val_loss: 3.8029 - val_acc: 0.1740\n",
      "Epoch 10/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.6818 - acc: 0.1918 - val_loss: 3.5736 - val_acc: 0.2063\n",
      "Epoch 11/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.6226 - acc: 0.2029 - val_loss: 3.6433 - val_acc: 0.2039\n",
      "Epoch 12/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.5644 - acc: 0.2135 - val_loss: 3.3260 - val_acc: 0.2518\n",
      "Epoch 13/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.5164 - acc: 0.2198 - val_loss: 3.3417 - val_acc: 0.2469\n",
      "Epoch 14/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.4600 - acc: 0.2292 - val_loss: 3.3596 - val_acc: 0.2483\n",
      "Epoch 15/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.4141 - acc: 0.2376 - val_loss: 3.1903 - val_acc: 0.2794\n",
      "Epoch 16/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.3711 - acc: 0.2446 - val_loss: 3.2487 - val_acc: 0.2648\n",
      "Epoch 17/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.3322 - acc: 0.2522 - val_loss: 3.1700 - val_acc: 0.2854\n",
      "Epoch 18/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.2830 - acc: 0.2581 - val_loss: 3.1435 - val_acc: 0.2844\n",
      "Epoch 19/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.2560 - acc: 0.2650 - val_loss: 3.1210 - val_acc: 0.2885\n",
      "Epoch 20/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.2068 - acc: 0.2745 - val_loss: 3.1746 - val_acc: 0.2852\n",
      "Epoch 21/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.1810 - acc: 0.2769 - val_loss: 3.1095 - val_acc: 0.2955\n",
      "Epoch 22/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.1427 - acc: 0.2847 - val_loss: 6.8043 - val_acc: 0.0057\n",
      "Epoch 23/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.1946 - acc: 0.2766 - val_loss: 3.1077 - val_acc: 0.2963\n",
      "Epoch 24/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.0921 - acc: 0.2936 - val_loss: 2.9100 - val_acc: 0.3352\n",
      "Epoch 25/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.0470 - acc: 0.3015 - val_loss: 2.8964 - val_acc: 0.3365\n",
      "Epoch 26/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 3.0249 - acc: 0.3050 - val_loss: 2.9647 - val_acc: 0.3235\n",
      "Epoch 27/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.9937 - acc: 0.3098 - val_loss: 2.8956 - val_acc: 0.3368\n",
      "Epoch 28/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.9625 - acc: 0.3186 - val_loss: 2.9050 - val_acc: 0.3367\n",
      "Epoch 29/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.9316 - acc: 0.3231 - val_loss: 2.8092 - val_acc: 0.3531\n",
      "Epoch 30/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.9093 - acc: 0.3258 - val_loss: 2.8379 - val_acc: 0.3468\n",
      "Epoch 31/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.8768 - acc: 0.3320 - val_loss: 2.8149 - val_acc: 0.3563\n",
      "Epoch 32/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.8562 - acc: 0.3357 - val_loss: 2.8489 - val_acc: 0.3457\n",
      "Epoch 33/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.8241 - acc: 0.3435 - val_loss: 2.8395 - val_acc: 0.3462\n",
      "Epoch 34/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.8032 - acc: 0.3454 - val_loss: 2.7816 - val_acc: 0.3575\n",
      "Epoch 35/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.7802 - acc: 0.3517 - val_loss: 2.7510 - val_acc: 0.3640\n",
      "Epoch 36/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.7558 - acc: 0.3537 - val_loss: 2.7728 - val_acc: 0.3610\n",
      "Epoch 37/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.7367 - acc: 0.3592 - val_loss: 2.7919 - val_acc: 0.3566\n",
      "Epoch 38/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.7087 - acc: 0.3621 - val_loss: 2.8125 - val_acc: 0.3541\n",
      "Epoch 39/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.6954 - acc: 0.3663 - val_loss: 2.7226 - val_acc: 0.3673\n",
      "Epoch 40/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.6624 - acc: 0.3699 - val_loss: 2.7849 - val_acc: 0.3556\n",
      "Epoch 41/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.6412 - acc: 0.3764 - val_loss: 2.7443 - val_acc: 0.3674\n",
      "Epoch 42/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.6181 - acc: 0.3814 - val_loss: 2.8882 - val_acc: 0.3433\n",
      "Epoch 43/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.6015 - acc: 0.3836 - val_loss: 2.7050 - val_acc: 0.3770\n",
      "Epoch 44/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.5844 - acc: 0.3868 - val_loss: 2.6683 - val_acc: 0.3831\n",
      "Epoch 45/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.5622 - acc: 0.3900 - val_loss: 2.7432 - val_acc: 0.3728\n",
      "Epoch 46/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.5407 - acc: 0.3944 - val_loss: 2.6527 - val_acc: 0.3845\n",
      "Epoch 47/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.5165 - acc: 0.3992 - val_loss: 2.6572 - val_acc: 0.3842\n",
      "Epoch 48/200\n",
      "1563/1562 [==============================] - 45s 28ms/step - loss: 2.4975 - acc: 0.4026 - val_loss: 2.6835 - val_acc: 0.3781\n",
      "Epoch 49/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.4748 - acc: 0.4065 - val_loss: 2.6701 - val_acc: 0.3853\n",
      "Epoch 50/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.4583 - acc: 0.4098 - val_loss: 2.6638 - val_acc: 0.3844\n",
      "Epoch 51/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.4422 - acc: 0.4140 - val_loss: 2.6339 - val_acc: 0.3883\n",
      "Epoch 52/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.4254 - acc: 0.4167 - val_loss: 2.6600 - val_acc: 0.3860\n",
      "Epoch 53/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.4056 - acc: 0.4201 - val_loss: 2.6772 - val_acc: 0.3850\n",
      "Epoch 54/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.3847 - acc: 0.4243 - val_loss: 2.6449 - val_acc: 0.3893\n",
      "Epoch 55/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.3689 - acc: 0.4287 - val_loss: 2.7373 - val_acc: 0.3763\n",
      "Epoch 56/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.3545 - acc: 0.4279 - val_loss: 2.6603 - val_acc: 0.3882\n",
      "Epoch 57/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.3244 - acc: 0.4361 - val_loss: 2.6413 - val_acc: 0.3906\n",
      "Epoch 58/200\n",
      "1563/1562 [==============================] - 45s 28ms/step - loss: 2.3114 - acc: 0.4379 - val_loss: 2.6543 - val_acc: 0.3888\n",
      "Epoch 59/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.2998 - acc: 0.4404 - val_loss: 2.6672 - val_acc: 0.3867\n",
      "Epoch 60/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.2787 - acc: 0.4448 - val_loss: 2.5980 - val_acc: 0.3970\n",
      "Epoch 61/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.2717 - acc: 0.4471 - val_loss: 2.6402 - val_acc: 0.3924\n",
      "Epoch 62/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.2484 - acc: 0.4485 - val_loss: 2.6550 - val_acc: 0.3919\n",
      "Epoch 63/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.2317 - acc: 0.4546 - val_loss: 2.6176 - val_acc: 0.3994\n",
      "Epoch 64/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.2014 - acc: 0.4593 - val_loss: 2.6249 - val_acc: 0.3963\n",
      "Epoch 65/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.1948 - acc: 0.4618 - val_loss: 2.6208 - val_acc: 0.4009\n",
      "Epoch 66/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.1813 - acc: 0.4636 - val_loss: 2.6616 - val_acc: 0.3912\n",
      "Epoch 67/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.1721 - acc: 0.4623 - val_loss: 2.6924 - val_acc: 0.3856\n",
      "Epoch 68/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.1447 - acc: 0.4689 - val_loss: 2.6370 - val_acc: 0.3930\n",
      "Epoch 69/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.1270 - acc: 0.4734 - val_loss: 2.6465 - val_acc: 0.3938\n",
      "Epoch 70/200\n",
      "1563/1562 [==============================] - 44s 28ms/step - loss: 2.1093 - acc: 0.4761 - val_loss: 2.6169 - val_acc: 0.4003\n",
      "10000/10000 [==============================] - 3s 258us/step\n",
      "Test loss: 2.6169245193481445\n",
      "Test accuracy: 0.4003\n",
      "Runtime: 3118.0301518440247\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training More Epochs')\n",
    "epochs = 200\n",
    "num_classes = 200\n",
    "\n",
    "num_predictions = 20\n",
    "batch_size = 64\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "logs = 'logs/epochs/200'\n",
    "tensorboard = TensorBoard(log_dir=logs)\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "model_name = '200epochs_keras_imagenet200_100base.h5'\n",
    "\n",
    "start = time()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', input_shape=train_images.shape[1:]))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "# model.add(Conv2D(256, (3, 3)))\n",
    "# model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(512, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "#model.add(Conv2D(512, (3, 3)))\n",
    "#model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(1024, (3, 3), padding='same'))\n",
    "model.add(Activation('elu'))\n",
    "#model.add(Conv2D(1024, (3, 3)))\n",
    "#model.add(Activation('elu'))\n",
    "# model.add(Conv2D(1024, (3, 3)))\n",
    "# model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=.01),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False)  # randomly flip images\n",
    "\n",
    "# Compute quantities required for feature-wise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(train_images)\n",
    "\n",
    "model.fit_generator(datagen.flow(train_images, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(train_images)/batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(val_images, y_test),\n",
    "                    callbacks=[tensorboard, earlystopping])\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(val_images, y_test, verbose=1)\n",
    "end = time()\n",
    "\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "print('Runtime:', str(end-start))\n",
    "\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training More Epochs\n",
      "Epoch 1/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 5.1605 - acc: 0.0330 - val_loss: 4.6125 - val_acc: 0.0633\n",
      "Epoch 2/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 4.5399 - acc: 0.0773 - val_loss: 4.3246 - val_acc: 0.1002\n",
      "Epoch 3/200\n",
      "3125/3125 [==============================] - 62s 20ms/step - loss: 4.2726 - acc: 0.1088 - val_loss: 4.0742 - val_acc: 0.1333\n",
      "Epoch 4/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 4.1024 - acc: 0.1311 - val_loss: 3.8159 - val_acc: 0.1673\n",
      "Epoch 5/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.9676 - acc: 0.1510 - val_loss: 3.6710 - val_acc: 0.1899\n",
      "Epoch 6/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.8537 - acc: 0.1676 - val_loss: 3.5717 - val_acc: 0.2079\n",
      "Epoch 7/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.7649 - acc: 0.1814 - val_loss: 3.4457 - val_acc: 0.2275\n",
      "Epoch 8/200\n",
      "3125/3125 [==============================] - 62s 20ms/step - loss: 3.6779 - acc: 0.1949 - val_loss: 3.4822 - val_acc: 0.2234\n",
      "Epoch 9/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.6118 - acc: 0.2079 - val_loss: 3.5896 - val_acc: 0.2069\n",
      "Epoch 10/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.5494 - acc: 0.2178 - val_loss: 3.3220 - val_acc: 0.2513\n",
      "Epoch 11/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.4967 - acc: 0.2287 - val_loss: 3.3005 - val_acc: 0.2597\n",
      "Epoch 12/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.4310 - acc: 0.2384 - val_loss: 3.1814 - val_acc: 0.2773\n",
      "Epoch 13/200\n",
      "3125/3125 [==============================] - 62s 20ms/step - loss: 3.3729 - acc: 0.2477 - val_loss: 3.6837 - val_acc: 0.2064\n",
      "Epoch 14/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.3270 - acc: 0.2550 - val_loss: 3.1426 - val_acc: 0.2865\n",
      "Epoch 15/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.2812 - acc: 0.2644 - val_loss: 3.1921 - val_acc: 0.2802\n",
      "Epoch 16/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.2384 - acc: 0.2727 - val_loss: 3.0188 - val_acc: 0.3081\n",
      "Epoch 17/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.1930 - acc: 0.2772 - val_loss: 2.9618 - val_acc: 0.3200\n",
      "Epoch 18/200\n",
      "3125/3125 [==============================] - 62s 20ms/step - loss: 3.1521 - acc: 0.2869 - val_loss: 2.9610 - val_acc: 0.3214\n",
      "Epoch 19/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.1180 - acc: 0.2940 - val_loss: 3.0398 - val_acc: 0.3095\n",
      "Epoch 20/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.0907 - acc: 0.2974 - val_loss: 2.9153 - val_acc: 0.3293\n",
      "Epoch 21/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.0391 - acc: 0.3057 - val_loss: 2.8722 - val_acc: 0.3398\n",
      "Epoch 22/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.0213 - acc: 0.3095 - val_loss: 2.8808 - val_acc: 0.3384\n",
      "Epoch 23/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.9914 - acc: 0.3145 - val_loss: 2.8545 - val_acc: 0.3394\n",
      "Epoch 24/200\n",
      "3125/3125 [==============================] - 62s 20ms/step - loss: 2.9500 - acc: 0.3230 - val_loss: 2.8739 - val_acc: 0.3357\n",
      "Epoch 25/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.9306 - acc: 0.3286 - val_loss: 2.8648 - val_acc: 0.3426\n",
      "Epoch 26/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.8953 - acc: 0.3335 - val_loss: 2.8084 - val_acc: 0.3496\n",
      "Epoch 27/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.8625 - acc: 0.3380 - val_loss: 2.7498 - val_acc: 0.3657\n",
      "Epoch 28/200\n",
      "3125/3125 [==============================] - 62s 20ms/step - loss: 2.8306 - acc: 0.3438 - val_loss: 2.8269 - val_acc: 0.3478\n",
      "Epoch 29/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.8073 - acc: 0.3488 - val_loss: 2.7388 - val_acc: 0.3660\n",
      "Epoch 30/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.7904 - acc: 0.3516 - val_loss: 2.8032 - val_acc: 0.3551\n",
      "Epoch 31/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.7577 - acc: 0.3558 - val_loss: 2.7528 - val_acc: 0.3577\n",
      "Epoch 32/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.7345 - acc: 0.3626 - val_loss: 2.7013 - val_acc: 0.3727\n",
      "Epoch 33/200\n",
      "3125/3125 [==============================] - 62s 20ms/step - loss: 2.7114 - acc: 0.3657 - val_loss: 2.7096 - val_acc: 0.3741\n",
      "Epoch 34/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.6844 - acc: 0.3723 - val_loss: 2.7316 - val_acc: 0.3643\n",
      "Epoch 35/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.6611 - acc: 0.3748 - val_loss: 2.7044 - val_acc: 0.3705\n",
      "Epoch 36/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.6416 - acc: 0.3778 - val_loss: 2.7544 - val_acc: 0.3623\n",
      "Epoch 37/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.6206 - acc: 0.3837 - val_loss: 2.6802 - val_acc: 0.3754\n",
      "Epoch 38/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.6010 - acc: 0.3878 - val_loss: 2.6633 - val_acc: 0.3802\n",
      "Epoch 39/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.5719 - acc: 0.3916 - val_loss: 2.6848 - val_acc: 0.3823\n",
      "Epoch 40/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.5606 - acc: 0.3940 - val_loss: 2.6395 - val_acc: 0.3895\n",
      "Epoch 41/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.5359 - acc: 0.3993 - val_loss: 2.6958 - val_acc: 0.3743\n",
      "Epoch 42/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.5175 - acc: 0.4026 - val_loss: 2.5991 - val_acc: 0.3951\n",
      "Epoch 43/200\n",
      "3125/3125 [==============================] - 62s 20ms/step - loss: 2.5010 - acc: 0.4066 - val_loss: 2.6426 - val_acc: 0.3946\n",
      "Epoch 44/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.4804 - acc: 0.4115 - val_loss: 2.6306 - val_acc: 0.3927\n",
      "Epoch 45/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.4472 - acc: 0.4164 - val_loss: 2.6195 - val_acc: 0.3945\n",
      "Epoch 46/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.4380 - acc: 0.4170 - val_loss: 2.6689 - val_acc: 0.3911\n",
      "Epoch 47/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.4126 - acc: 0.4215 - val_loss: 2.5953 - val_acc: 0.3994\n",
      "Epoch 48/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.3927 - acc: 0.4262 - val_loss: 2.5568 - val_acc: 0.4040\n",
      "Epoch 49/200\n",
      "3125/3125 [==============================] - 62s 20ms/step - loss: 2.3809 - acc: 0.4287 - val_loss: 2.6126 - val_acc: 0.3969\n",
      "Epoch 50/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.3592 - acc: 0.4321 - val_loss: 2.6106 - val_acc: 0.3988\n",
      "Epoch 51/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.3422 - acc: 0.4374 - val_loss: 2.6055 - val_acc: 0.3975\n",
      "Epoch 52/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.3194 - acc: 0.4381 - val_loss: 2.6356 - val_acc: 0.3935\n",
      "Epoch 53/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.3234 - acc: 0.4382 - val_loss: 2.6242 - val_acc: 0.3934\n",
      "Epoch 54/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.2918 - acc: 0.4452 - val_loss: 2.6033 - val_acc: 0.4017\n",
      "Epoch 55/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.2694 - acc: 0.4505 - val_loss: 2.6391 - val_acc: 0.3955\n",
      "Epoch 56/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.2574 - acc: 0.4518 - val_loss: 2.5822 - val_acc: 0.4026\n",
      "Epoch 57/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.2374 - acc: 0.4551 - val_loss: 2.5832 - val_acc: 0.4059\n",
      "Epoch 58/200\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.2227 - acc: 0.4582 - val_loss: 2.6129 - val_acc: 0.4017\n",
      "10000/10000 [==============================] - 3s 269us/step\n",
      "Test loss: 2.6129240924835204\n",
      "Test accuracy: 0.4017\n",
      "Runtime: 3639.710782766342\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training More Epochs')\n",
    "epochs = 200\n",
    "num_classes = 200\n",
    "\n",
    "num_predictions = 20\n",
    "batch_size = 32\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "logs = 'logs/epochs/200_32'\n",
    "tensorboard = TensorBoard(log_dir=logs)\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "model_name = '200_32_epochs_keras_imagenet200_100base.h5'\n",
    "\n",
    "start = time()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', input_shape=train_images.shape[1:]))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "# model.add(Conv2D(256, (3, 3)))\n",
    "# model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(512, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "#model.add(Conv2D(512, (3, 3)))\n",
    "#model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(1024, (3, 3), padding='same'))\n",
    "model.add(Activation('elu'))\n",
    "#model.add(Conv2D(1024, (3, 3)))\n",
    "#model.add(Activation('elu'))\n",
    "# model.add(Conv2D(1024, (3, 3)))\n",
    "# model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=.01),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False)  # randomly flip images\n",
    "\n",
    "# Compute quantities required for feature-wise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(train_images)\n",
    "\n",
    "model.fit_generator(datagen.flow(train_images, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(train_images)/batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(val_images, y_test),\n",
    "                    callbacks=[tensorboard, earlystopping])\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(val_images, y_test, verbose=1)\n",
    "end = time()\n",
    "\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "print('Runtime:', str(end-start))\n",
    "\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training More Epochs\n",
      "Epoch 1/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 5.2142 - acc: 0.0318 - val_loss: 4.6701 - val_acc: 0.0613\n",
      "Epoch 2/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 4.5766 - acc: 0.0726 - val_loss: 4.3757 - val_acc: 0.0916\n",
      "Epoch 3/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 4.3015 - acc: 0.1032 - val_loss: 4.0707 - val_acc: 0.1318\n",
      "Epoch 4/50\n",
      "3125/3125 [==============================] - 62s 20ms/step - loss: 4.1237 - acc: 0.1273 - val_loss: 3.9392 - val_acc: 0.1518\n",
      "Epoch 5/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.9863 - acc: 0.1472 - val_loss: 4.3864 - val_acc: 0.1090\n",
      "Epoch 6/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.8739 - acc: 0.1652 - val_loss: 3.5823 - val_acc: 0.2091\n",
      "Epoch 7/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.7779 - acc: 0.1792 - val_loss: 3.5759 - val_acc: 0.2090\n",
      "Epoch 8/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.7064 - acc: 0.1920 - val_loss: 3.4155 - val_acc: 0.2314\n",
      "Epoch 9/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.6189 - acc: 0.2063 - val_loss: 3.3828 - val_acc: 0.2403\n",
      "Epoch 10/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.5709 - acc: 0.2167 - val_loss: 3.3268 - val_acc: 0.2507\n",
      "Epoch 11/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.4956 - acc: 0.2263 - val_loss: 3.2341 - val_acc: 0.2726\n",
      "Epoch 12/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.4357 - acc: 0.2367 - val_loss: 3.1775 - val_acc: 0.2762\n",
      "Epoch 13/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.3782 - acc: 0.2461 - val_loss: 3.1976 - val_acc: 0.2755\n",
      "Epoch 14/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.3222 - acc: 0.2580 - val_loss: 3.0796 - val_acc: 0.2924\n",
      "Epoch 15/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.2801 - acc: 0.2644 - val_loss: 3.0610 - val_acc: 0.3020\n",
      "Epoch 16/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.2348 - acc: 0.2723 - val_loss: 2.9932 - val_acc: 0.3121\n",
      "Epoch 17/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.1957 - acc: 0.2789 - val_loss: 2.9901 - val_acc: 0.3132\n",
      "Epoch 18/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.1575 - acc: 0.2842 - val_loss: 2.9910 - val_acc: 0.3156\n",
      "Epoch 19/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.1162 - acc: 0.2936 - val_loss: 2.9422 - val_acc: 0.3234\n",
      "Epoch 20/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.0824 - acc: 0.2994 - val_loss: 2.8986 - val_acc: 0.3312\n",
      "Epoch 21/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.0444 - acc: 0.3047 - val_loss: 2.9208 - val_acc: 0.3268\n",
      "Epoch 22/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 3.0275 - acc: 0.3093 - val_loss: 2.9214 - val_acc: 0.3309\n",
      "Epoch 23/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.9855 - acc: 0.3160 - val_loss: 2.9627 - val_acc: 0.3235\n",
      "Epoch 24/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.9622 - acc: 0.3219 - val_loss: 2.8168 - val_acc: 0.3521\n",
      "Epoch 25/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.9287 - acc: 0.3276 - val_loss: 3.6308 - val_acc: 0.2143\n",
      "Epoch 26/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.8933 - acc: 0.3333 - val_loss: 2.7504 - val_acc: 0.3621\n",
      "Epoch 27/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.8625 - acc: 0.3384 - val_loss: 2.8197 - val_acc: 0.3520\n",
      "Epoch 28/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.8525 - acc: 0.3395 - val_loss: 2.7986 - val_acc: 0.3583\n",
      "Epoch 29/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.8207 - acc: 0.3477 - val_loss: 2.7316 - val_acc: 0.3673\n",
      "Epoch 30/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.8029 - acc: 0.3512 - val_loss: 2.7584 - val_acc: 0.3600\n",
      "Epoch 31/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.7509 - acc: 0.3598 - val_loss: 2.8582 - val_acc: 0.3467\n",
      "Epoch 32/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.7311 - acc: 0.3628 - val_loss: 2.7359 - val_acc: 0.3676\n",
      "Epoch 33/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.7101 - acc: 0.3670 - val_loss: 2.7201 - val_acc: 0.3716\n",
      "Epoch 34/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.6775 - acc: 0.3722 - val_loss: 2.6943 - val_acc: 0.3759\n",
      "Epoch 35/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.6560 - acc: 0.3776 - val_loss: 2.6577 - val_acc: 0.3900\n",
      "Epoch 36/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.6414 - acc: 0.3797 - val_loss: 2.6625 - val_acc: 0.3820\n",
      "Epoch 37/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.6118 - acc: 0.3844 - val_loss: 2.7459 - val_acc: 0.3726\n",
      "Epoch 38/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.5939 - acc: 0.3877 - val_loss: 2.6908 - val_acc: 0.3745\n",
      "Epoch 39/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.5702 - acc: 0.3926 - val_loss: 2.7341 - val_acc: 0.3741\n",
      "Epoch 40/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.5488 - acc: 0.3976 - val_loss: 2.6188 - val_acc: 0.3923\n",
      "Epoch 41/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.5901 - acc: 0.3919 - val_loss: 2.6668 - val_acc: 0.3865\n",
      "Epoch 42/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.5775 - acc: 0.3948 - val_loss: 2.6756 - val_acc: 0.3867\n",
      "Epoch 43/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.5383 - acc: 0.4033 - val_loss: 2.6076 - val_acc: 0.3925\n",
      "Epoch 44/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.4811 - acc: 0.4097 - val_loss: 2.6423 - val_acc: 0.3842\n",
      "Epoch 45/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.4635 - acc: 0.4150 - val_loss: 2.6611 - val_acc: 0.3917\n",
      "Epoch 46/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.4429 - acc: 0.4173 - val_loss: 2.6897 - val_acc: 0.3870\n",
      "Epoch 47/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.4189 - acc: 0.4221 - val_loss: 2.6335 - val_acc: 0.3974\n",
      "Epoch 48/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.3951 - acc: 0.4239 - val_loss: 2.6607 - val_acc: 0.3906\n",
      "Epoch 49/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.3950 - acc: 0.4262 - val_loss: 2.6017 - val_acc: 0.4021\n",
      "Epoch 50/50\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 2.3651 - acc: 0.4320 - val_loss: 2.6525 - val_acc: 0.3916\n",
      "10000/10000 [==============================] - 3s 271us/step\n",
      "Test loss: 2.6525143802642823\n",
      "Test accuracy: 0.3916\n",
      "Runtime: 3147.4733967781067\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training More Epochs')\n",
    "epochs = 50\n",
    "num_classes = 200\n",
    "\n",
    "num_predictions = 20\n",
    "batch_size = 32\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "logs = 'logs/final'\n",
    "tensorboard = TensorBoard(log_dir=logs)\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "model_name = 'final_keras_imagenet200.h5'\n",
    "\n",
    "start = time()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', input_shape=train_images.shape[1:]))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "# model.add(Conv2D(256, (3, 3)))\n",
    "# model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(512, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "#model.add(Conv2D(512, (3, 3)))\n",
    "#model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(1024, (3, 3), padding='same'))\n",
    "model.add(Activation('elu'))\n",
    "#model.add(Conv2D(1024, (3, 3)))\n",
    "#model.add(Activation('elu'))\n",
    "# model.add(Conv2D(1024, (3, 3)))\n",
    "# model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=.01),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False)  # randomly flip images\n",
    "\n",
    "# Compute quantities required for feature-wise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(train_images)\n",
    "\n",
    "model.fit_generator(datagen.flow(train_images, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(train_images)/batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(val_images, y_test),\n",
    "                    callbacks=[tensorboard])\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(val_images, y_test, verbose=1)\n",
    "end = time()\n",
    "\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "print('Runtime:', str(end-start))\n",
    "\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
